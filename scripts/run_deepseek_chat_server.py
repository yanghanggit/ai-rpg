#!/usr/bin/env python3
"""
DeepSeek Chat Serverå¯åŠ¨è„šæœ¬

åŠŸèƒ½ï¼š
1. åŸºäºFastAPIæ„å»ºçš„DeepSeekèŠå¤©æœåŠ¡å™¨
2. æä¾›RESTful APIæ¥å£
3. æ”¯æŒèŠå¤©å†å²å’Œä¸Šä¸‹æ–‡è®°å¿†
4. å¼‚æ­¥å¤„ç†èŠå¤©è¯·æ±‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/run_deepseek_chat_server.py

æˆ–è€…åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼š
    python -m scripts.run_deepseek_chat_server

APIç«¯ç‚¹ï¼š
    GET  /                    - å¥åº·æ£€æŸ¥
    POST /api/chat/v1/        - æ ‡å‡†èŠå¤©
    POST /api/chat/rag/v1/    - RAGèŠå¤©
    POST /api/chat/undefined/v1/ - æœªå®šä¹‰ç±»å‹èŠå¤©
    POST /api/chat/mcp/v1/    - MCPèŠå¤©
"""

import os
from pathlib import Path
import sys
import asyncio
from typing import Any, Dict

# å°† src ç›®å½•æ·»åŠ åˆ°æ¨¡å—æœç´¢è·¯å¾„
sys.path.insert(
    0, os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "src")
)

from fastapi import FastAPI
from loguru import logger

from multi_agents_game.chat_services.protocol import ChatRequest, ChatResponse
from multi_agents_game.deepseek import (
    State,
    create_compiled_stage_graph,
    stream_graph_updates,
    create_deepseek_llm,
    create_rag_compiled_graph,
    stream_rag_graph_updates,
    create_unified_chat_graph,
    stream_unified_graph_updates,
    UnifiedState,
)

from multi_agents_game.settings import (
    initialize_server_settings_instance,
)

# å¯¼å…¥è·¯ç”±ç®¡ç†å™¨ç›¸å…³æ¨¡å—
from multi_agents_game.rag.routing import (
    KeywordRouteStrategy,
    SemanticRouteStrategy,
    RouteDecisionManager,
    FallbackRouteStrategy,
    RouteConfigBuilder,
)
from multi_agents_game.demo.campaign_setting import (
    FANTASY_WORLD_RPG_TEST_ROUTE_KEYWORDS,
    FANTASY_WORLD_RPG_TEST_RAG_TOPICS,
)


##################################################################################################################
# è·¯ç”±ç®¡ç†å™¨åˆ›å»ºå‡½æ•°
def create_alphania_keyword_strategy() -> KeywordRouteStrategy:
    """åˆ›å»ºè‰¾å°”æ³•å°¼äºšä¸–ç•Œä¸“ç”¨çš„å…³é”®è¯ç­–ç•¥"""
    alphania_keywords = FANTASY_WORLD_RPG_TEST_ROUTE_KEYWORDS
    config = {
        "keywords": alphania_keywords,
        "threshold": 0.1,  # è¾ƒä½é˜ˆå€¼ï¼Œåªè¦åŒ¹é…åˆ°å…³é”®è¯å°±å¯ç”¨RAG
        "case_sensitive": False,
    }
    return KeywordRouteStrategy(config)


def create_game_semantic_strategy() -> SemanticRouteStrategy:
    """åˆ›å»ºæ¸¸æˆä¸“ç”¨çš„è¯­ä¹‰è·¯ç”±ç­–ç•¥"""
    config = {
        "similarity_threshold": 0.5,  # ä¸­ç­‰ç›¸ä¼¼åº¦é˜ˆå€¼
        "use_multilingual": True,  # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹æ”¯æŒä¸­æ–‡
        "rag_topics": FANTASY_WORLD_RPG_TEST_RAG_TOPICS,
    }
    return SemanticRouteStrategy(config)


def create_default_route_manager() -> RouteDecisionManager:
    """åˆ›å»ºé»˜è®¤çš„è·¯ç”±å†³ç­–ç®¡ç†å™¨"""
    # åˆ›å»ºç­–ç•¥å®ä¾‹
    keyword_strategy = create_alphania_keyword_strategy()
    semantic_strategy = create_game_semantic_strategy()

    # ä½¿ç”¨æ„å»ºå™¨åˆ›å»ºç®¡ç†å™¨
    builder = RouteConfigBuilder()
    builder.add_strategy(keyword_strategy, 0.4)
    builder.add_strategy(semantic_strategy, 0.6)
    builder.set_fallback(FallbackRouteStrategy(default_to_rag=False))

    return builder.build()


##################################################################################################################
# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="DeepSeek Chat Server",
    description="åŸºäºDeepSeekçš„èŠå¤©æœåŠ¡å™¨",
    version="1.0.0",
)


##################################################################################################################
# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/")
async def health_check() -> Dict[str, Any]:
    """
    æœåŠ¡å™¨å¥åº·æ£€æŸ¥ç«¯ç‚¹

    Returns:
        dict: åŒ…å«æœåŠ¡å™¨çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
    """
    from datetime import datetime

    return {
        "service": "DeepSeek Chat Server",
        "version": "1.0.0",
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "available_endpoints": [
            "GET /",
            "POST /api/chat/v1/",
            "POST /api/chat/rag/v1/",
            "POST /api/chat/undefined/v1/",
            "POST /api/chat/mcp/v1/",
        ],
        "description": "åŸºäºDeepSeekçš„èŠå¤©æœåŠ¡å™¨æ­£åœ¨æ­£å¸¸è¿è¡Œ",
    }


##################################################################################################################
# å®šä¹‰ POST è¯·æ±‚å¤„ç†é€»è¾‘
@app.post(
    path="/api/chat/v1/",
    response_model=ChatResponse,
)
async def process_chat_request(request: ChatRequest) -> ChatResponse:
    """
    å¤„ç†èŠå¤©è¯·æ±‚

    Args:
        request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

    Returns:
        ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
    """
    try:
        logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: {request.message.content}")

        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„LLMå®ä¾‹
        llm = create_deepseek_llm()

        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„çŠ¶æ€å›¾å®ä¾‹
        compiled_state_graph = create_compiled_stage_graph("deepseek_chatbot_node")

        # èŠå¤©å†å²ï¼ˆåŒ…å«LLMå®ä¾‹ï¼‰
        chat_history_state: State = {
            "messages": [message for message in request.chat_history],
            "llm": llm,
        }

        # ç”¨æˆ·è¾“å…¥
        user_input_state: State = {"messages": [request.message], "llm": llm}

        # è·å–å›å¤ - ä½¿ç”¨ asyncio.to_thread å°†é˜»å¡è°ƒç”¨åŒ…è£…ä¸ºå¼‚æ­¥
        update_messages = await asyncio.to_thread(
            stream_graph_updates,
            state_compiled_graph=compiled_state_graph,
            chat_history_state=chat_history_state,
            user_input_state=user_input_state,
        )

        logger.success(f"ç”Ÿæˆå›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

        # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
        for i, message in enumerate(update_messages):
            logger.success(f"æ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

        # è¿”å›
        return ChatResponse(messages=update_messages)

    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # è¿”å›é”™è¯¯æ¶ˆæ¯
        from langchain.schema import AIMessage

        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return ChatResponse(messages=[error_message])


##################################################################################################################
@app.post(
    path="/api/chat/rag/v1/",
    response_model=ChatResponse,
)
async def process_chat_rag_request(request: ChatRequest) -> ChatResponse:
    """
    å¤„ç†RAGèŠå¤©è¯·æ±‚

    Args:
        request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

    Returns:
        ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
    """
    try:
        logger.info(f"æ”¶åˆ°RAGèŠå¤©è¯·æ±‚: {request.message.content}")

        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„LLMå®ä¾‹
        llm = create_deepseek_llm()

        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„RAGçŠ¶æ€å›¾å®ä¾‹
        rag_compiled_graph = create_rag_compiled_graph()

        # èŠå¤©å†å²ï¼ˆåŒ…å«LLMå®ä¾‹ï¼‰
        chat_history_state: State = {
            "messages": [message for message in request.chat_history],
            "llm": llm,
        }

        # ç”¨æˆ·è¾“å…¥
        user_input_state: State = {"messages": [request.message], "llm": llm}

        # è·å–RAGå›å¤ - ä½¿ç”¨ asyncio.to_thread å°†é˜»å¡è°ƒç”¨åŒ…è£…ä¸ºå¼‚æ­¥
        update_messages = await asyncio.to_thread(
            stream_rag_graph_updates,
            rag_compiled_graph=rag_compiled_graph,
            chat_history_state=chat_history_state,
            user_input_state=user_input_state,
        )

        logger.success(f"ç”ŸæˆRAGå›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

        # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
        for i, message in enumerate(update_messages):
            logger.success(f"RAGæ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

        # è¿”å›
        return ChatResponse(messages=update_messages)

    except Exception as e:
        logger.error(f"å¤„ç†RAGèŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # è¿”å›é”™è¯¯æ¶ˆæ¯
        from langchain.schema import AIMessage

        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„RAGè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return ChatResponse(messages=[error_message])


##################################################################################################################
@app.post(
    path="/api/chat/undefined/v1/",
    response_model=ChatResponse,
)
async def process_chat_undefined_request(request: ChatRequest) -> ChatResponse:
    """
    å¤„ç†ç»Ÿä¸€èŠå¤©è¯·æ±‚ï¼ˆæ™ºèƒ½è·¯ç”±ï¼‰

    åŠŸèƒ½ç‰¹æ€§ï¼š
    1. ğŸš¦ æ™ºèƒ½è·¯ç”±ï¼šè‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€ä½³å¤„ç†æ¨¡å¼
    2. ğŸ’¬ ç›´æ¥å¯¹è¯ï¼šä¸€èˆ¬æ€§èŠå¤©ä½¿ç”¨DeepSeekç›´æ¥å›ç­”
    3. ğŸ” RAGå¢å¼ºï¼šè‰¾å°”æ³•å°¼äºšä¸–ç•Œç›¸å…³é—®é¢˜ä½¿ç”¨çŸ¥è¯†åº“å¢å¼º
    4. ğŸ¯ æ— ç¼åˆ‡æ¢ï¼šç”¨æˆ·æ— éœ€æ‰‹åŠ¨é€‰æ‹©æ¨¡å¼

    Args:
        request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

    Returns:
        ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
    """
    try:
        logger.info(f"æ”¶åˆ°ç»Ÿä¸€èŠå¤©è¯·æ±‚: {request.message.content}")

        # åˆ›å»ºç»Ÿä¸€èŠå¤©å›¾
        unified_graph = create_unified_chat_graph()

        # åˆ›å»ºè·¯ç”±ç®¡ç†å™¨å®ä¾‹
        route_manager = create_default_route_manager()

        # èŠå¤©å†å²çŠ¶æ€ï¼ˆä½¿ç”¨å­—å…¸æ ¼å¼ï¼Œç¬¦åˆç»Ÿä¸€å›¾çš„è¦æ±‚ï¼‰
        chat_history_state = {"messages": [message for message in request.chat_history]}

        # ç”¨æˆ·è¾“å…¥çŠ¶æ€
        user_input_state = {"messages": [request.message]}

        # æ‰§è¡Œç»Ÿä¸€èŠå¤©æµç¨‹ - ä½¿ç”¨ asyncio.to_thread å°†é˜»å¡è°ƒç”¨åŒ…è£…ä¸ºå¼‚æ­¥
        update_messages = await asyncio.to_thread(
            stream_unified_graph_updates,
            unified_compiled_graph=unified_graph,
            chat_history_state=chat_history_state,
            user_input_state=user_input_state,
            route_manager=route_manager,
        )

        logger.success(f"ç”Ÿæˆç»Ÿä¸€èŠå¤©å›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

        # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
        for i, message in enumerate(update_messages):
            logger.success(f"ç»Ÿä¸€èŠå¤©æ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

        # è¿”å›
        return ChatResponse(messages=update_messages)

    except Exception as e:
        logger.error(f"å¤„ç†ç»Ÿä¸€èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # è¿”å›é”™è¯¯æ¶ˆæ¯
        from langchain.schema import AIMessage

        error_message = AIMessage(
            content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„ç»Ÿä¸€èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        )
        return ChatResponse(messages=[error_message])


##################################################################################################################
@app.post(
    path="/api/chat/mcp/v1/",
    response_model=ChatResponse,
)
async def process_chat_mcp_request(request: ChatRequest) -> ChatResponse:
    """
    å¤„ç†MCPèŠå¤©è¯·æ±‚

    Args:
        request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

    Returns:
        ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
    """
    # TODO: å®ç°MCPèŠå¤©é€»è¾‘
    return ChatResponse(messages=[])


##################################################################################################################
def main() -> None:
    """
    DeepSeekèŠå¤©æœåŠ¡å™¨ä¸»å‡½æ•°

    åŠŸèƒ½ï¼š
    1. å¯åŠ¨FastAPIæœåŠ¡å™¨
    2. é…ç½®æœåŠ¡å™¨å‚æ•°
    3. æä¾›èŠå¤©APIæœåŠ¡
    """
    logger.info("ğŸš€ å¯åŠ¨DeepSeekèŠå¤©æœåŠ¡å™¨...")

    # åŠ è½½æœåŠ¡å™¨é…ç½®
    server_config = initialize_server_settings_instance(Path("server_settings.json"))

    try:
        import uvicorn

        # å¯åŠ¨æœåŠ¡å™¨
        uvicorn.run(
            app,
            host="localhost",
            port=server_config.deepseek_chat_server_port,
            log_level="debug",
        )

    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨æœåŠ¡å™¨å¤±è´¥: {e}")
        raise


##################################################################################################################
if __name__ == "__main__":
    main()
