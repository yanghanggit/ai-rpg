"""
pgvector ç»¼åˆæµ‹è¯•å’Œæ¼”ç¤ºæ–‡ä»¶
åˆå¹¶äº†åŸºç¡€æµ‹è¯•ã€å®Œæ•´åŠŸèƒ½æµ‹è¯•å’Œå®é™…ä½¿ç”¨æ¼”ç¤º
åŒ…å«ï¼šåŸºç¡€SQLæ“ä½œæµ‹è¯•ã€ORMå‘é‡æ“ä½œæµ‹è¯•ã€å®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º
"""

import pytest
import numpy as np
from typing import List, Dict, Any, cast
from sqlalchemy import create_engine, text
from loguru import logger
import sys
import os
import hashlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥é…ç½®
from multi_agents_game.config.db_config import POSTGRES_DATABASE_URL

# å¯¼å…¥æ¨¡å‹ç±»å‹ä»¥æ”¯æŒç±»å‹æ£€æŸ¥
from multi_agents_game.db.pgsql_vector import (
    ConversationVectorDB,
    GameKnowledgeVectorDB,
)


# ================================
# pytest fixtures
# ================================


@pytest.fixture(scope="session", autouse=True)
def setup_database_tables() -> Any:
    """è®¾ç½®æ•°æ®åº“è¡¨çš„ fixture"""
    try:
        from multi_agents_game.db.pgsql_client import engine
        from multi_agents_game.db.pgsql_client import Base  # type: ignore[attr-defined]

        Base.metadata.create_all(bind=engine)
        logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ª")
        yield
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¡¨è®¾ç½®å¤±è´¥: {e}")
        raise e


# ================================
# åµŒå…¥å‘é‡ç”Ÿæˆå‡½æ•° (æ¨¡æ‹ŸOpenAI API)
# ================================


def mock_get_embedding(text: str) -> List[float]:
    """
    æ¨¡æ‹Ÿè·å–æ–‡æœ¬åµŒå…¥å‘é‡çš„å‡½æ•° (1536ç»´)
    å®é™…ä½¿ç”¨æ—¶åº”è¯¥è°ƒç”¨OpenAIæˆ–å…¶ä»–åµŒå…¥API

    å‚æ•°:
        text: è¾“å…¥æ–‡æœ¬

    è¿”å›:
        List[float]: 1536ç»´çš„å‘é‡
    """
    # ä½¿ç”¨æ–‡æœ¬å“ˆå¸Œç”Ÿæˆç¡®å®šæ€§çš„å‘é‡ (ä»…ç”¨äºæµ‹è¯•)
    np.random.seed(hash(text) % 2**32)
    vector = np.random.randn(1536).astype(float)
    # å½’ä¸€åŒ–å‘é‡
    vector = vector / np.linalg.norm(vector)
    return cast(List[float], list(vector))


def mock_openai_embedding(text: str) -> List[float]:
    """
    å¦ä¸€ç§æ¨¡æ‹ŸOpenAIåµŒå…¥APIçš„å®ç°
    ä½¿ç”¨MD5å“ˆå¸Œç”Ÿæˆæ›´ç¨³å®šçš„å‘é‡
    """
    hash_obj = hashlib.md5(text.encode())
    seed = int(hash_obj.hexdigest(), 16) % (2**32)

    np.random.seed(seed)
    vector = np.random.randn(1536).astype(float)
    vector = vector / np.linalg.norm(vector)  # å½’ä¸€åŒ–
    return cast(List[float], vector.tolist())


# ================================
# pgvector æµ‹è¯•ç±»
# ================================


class TestPgvectorIntegration:
    """pgvector é›†æˆæµ‹è¯•ç±»"""

    def setup_method(self) -> None:
        """åœ¨æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰è¿è¡Œ"""
        logger.info("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")

    def teardown_method(self) -> None:
        """åœ¨æ¯ä¸ªæµ‹è¯•æ–¹æ³•åè¿è¡Œ"""
        logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")


# ================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€SQLå‘é‡æ“ä½œæµ‹è¯•
# ================================


@pytest.mark.integration
@pytest.mark.database
def test_basic_vector_operations() -> None:
    """æµ‹è¯•åŸºæœ¬çš„å‘é‡æ“ä½œ - ç›´æ¥SQLæ“ä½œ"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•åŸºæœ¬å‘é‡æ“ä½œ...")

    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    engine = create_engine(POSTGRES_DATABASE_URL)

    try:
        with engine.connect() as conn:
            # 1. ç¡®ä¿pgvectoræ‰©å±•å·²å®‰è£…
            logger.info("ğŸ”§ æ£€æŸ¥pgvectoræ‰©å±•...")
            result = conn.execute(
                text("SELECT extname FROM pg_extension WHERE extname = 'vector'")
            ).fetchone()
            if result:
                logger.info(f"âœ… pgvectoræ‰©å±•å·²å®‰è£…: {result[0]}")
            else:
                logger.error("âŒ pgvectoræ‰©å±•æœªå®‰è£…")
                return

            # 2. æµ‹è¯•åˆ›å»ºç®€å•å‘é‡è¡¨
            logger.info("ğŸ“ åˆ›å»ºæµ‹è¯•å‘é‡è¡¨...")
            conn.execute(
                text(
                    """
                DROP TABLE IF EXISTS test_vectors;
                CREATE TABLE test_vectors (
                    id SERIAL PRIMARY KEY,
                    content TEXT,
                    embedding vector(3)
                );
            """
                )
            )

            # 3. æ’å…¥æµ‹è¯•æ•°æ®
            logger.info("ğŸ’¾ æ’å…¥æµ‹è¯•å‘é‡æ•°æ®...")
            test_vectors = [
                ("æ–‡æ¡£1ï¼šå…³äºæœºå™¨å­¦ä¹ çš„ä»‹ç»", [1.0, 2.0, 3.0]),
                ("æ–‡æ¡£2ï¼šæ·±åº¦å­¦ä¹ æ•™ç¨‹", [1.1, 2.1, 3.1]),
                ("æ–‡æ¡£3ï¼šPythonç¼–ç¨‹æŒ‡å—", [4.0, 5.0, 6.0]),
            ]

            for content, vector in test_vectors:
                conn.execute(
                    text(
                        """
                    INSERT INTO test_vectors (content, embedding) 
                    VALUES (:content, :vector)
                """
                    ),
                    {"content": content, "vector": vector},
                )

            # 4. æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦æœç´¢
            logger.info("ğŸ” æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦æœç´¢...")
            query_vector = "[1.05, 2.05, 3.05]"  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼

            results = conn.execute(
                text(
                    """
                SELECT content, embedding, (embedding <=> :query_vector) as distance
                FROM test_vectors
                ORDER BY embedding <=> :query_vector
                LIMIT 3
            """
                ),
                {"query_vector": query_vector},
            ).fetchall()

            logger.info("ğŸ“‹ æœç´¢ç»“æœ:")
            for i, row in enumerate(results):
                logger.info(f"  {i+1}. {row.content}")
                logger.info(f"     å‘é‡: {row.embedding}")
                logger.info(f"     è·ç¦»: {row.distance:.4f}")

            # 5. æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦
            logger.info("ğŸ“ æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦...")
            similarity_results = conn.execute(
                text(
                    """
                SELECT content, (1 - (embedding <=> :query_vector)) as similarity
                FROM test_vectors
                ORDER BY embedding <=> :query_vector
                LIMIT 3
            """
                ),
                {"query_vector": query_vector},
            ).fetchall()

            logger.info("ğŸ“Š ç›¸ä¼¼åº¦ç»“æœ:")
            for i, row in enumerate(similarity_results):
                logger.info(f"  {i+1}. {row.content}: ç›¸ä¼¼åº¦ {row.similarity:.4f}")

            # 6. æ¸…ç†æµ‹è¯•è¡¨
            conn.execute(text("DROP TABLE test_vectors"))
            conn.commit()

            logger.info("âœ… åŸºæœ¬å‘é‡æ“ä½œæµ‹è¯•å®Œæˆ!")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise e


@pytest.mark.integration
@pytest.mark.database
def test_high_dimension_vectors() -> None:
    """æµ‹è¯•é«˜ç»´å‘é‡ï¼ˆ1536ç»´ï¼‰- ç›´æ¥SQLæ“ä½œ"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•é«˜ç»´å‘é‡æ“ä½œ...")

    engine = create_engine(POSTGRES_DATABASE_URL)

    try:
        with engine.connect() as conn:
            # åˆ›å»º1536ç»´å‘é‡è¡¨
            logger.info("ğŸ“ åˆ›å»º1536ç»´å‘é‡è¡¨...")
            conn.execute(
                text(
                    """
                DROP TABLE IF EXISTS test_vectors_1536;
                CREATE TABLE test_vectors_1536 (
                    id SERIAL PRIMARY KEY,
                    content TEXT,
                    embedding vector(1536)
                );
            """
                )
            )

            # ç”Ÿæˆæµ‹è¯•å‘é‡
            logger.info("ğŸ² ç”Ÿæˆæµ‹è¯•å‘é‡...")
            np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
            test_embedding = np.random.randn(1536).astype(float).tolist()
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            vector_str = "[" + ",".join(map(str, test_embedding)) + "]"

            # æ’å…¥æ•°æ®
            conn.execute(
                text(
                    """
                INSERT INTO test_vectors_1536 (content, embedding) 
                VALUES (:content, :vector)
            """
                ),
                {
                    "content": "æµ‹è¯•æ–‡æ¡£ï¼šè¿™æ˜¯ä¸€ä¸ª1536ç»´å‘é‡çš„æµ‹è¯•æ–‡æ¡£",
                    "vector": vector_str,
                },
            )

            # æµ‹è¯•æœç´¢
            query_vector = vector_str  # ä½¿ç”¨ç›¸åŒå‘é‡åº”è¯¥å¾—åˆ°å®Œç¾åŒ¹é…

            result = conn.execute(
                text(
                    """
                SELECT content, (1 - (embedding <=> :query_vector)) as similarity
                FROM test_vectors_1536
                WHERE embedding IS NOT NULL
                ORDER BY embedding <=> :query_vector
                LIMIT 1
            """
                ),
                {"query_vector": query_vector},
            ).fetchone()

            if result:
                logger.info(f"âœ… é«˜ç»´å‘é‡æœç´¢æˆåŠŸ!")
                logger.info(f"   å†…å®¹: {result.content}")
                logger.info(f"   ç›¸ä¼¼åº¦: {result.similarity:.6f}")
            else:
                logger.error("âŒ é«˜ç»´å‘é‡æœç´¢å¤±è´¥")

            # æ¸…ç†
            conn.execute(text("DROP TABLE test_vectors_1536"))
            conn.commit()

            logger.info("âœ… é«˜ç»´å‘é‡æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        logger.error(f"âŒ é«˜ç»´å‘é‡æµ‹è¯•å¤±è´¥: {e}")
        raise e


# ================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šORMå‘é‡æ“ä½œæµ‹è¯•
# ================================


@pytest.mark.integration
@pytest.mark.database
def test_vector_document_operations() -> None:
    """æµ‹è¯•å‘é‡æ–‡æ¡£æ“ä½œ - ä½¿ç”¨ORM"""
    from multi_agents_game.db.pgsql_vector_ops import (
        save_vector_document,
        search_similar_documents,
        get_database_vector_stats,
    )

    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•å‘é‡æ–‡æ¡£æ“ä½œ...")

    # 1. ä¿å­˜ä¸€äº›æµ‹è¯•æ–‡æ¡£
    test_documents = [
        {
            "content": "è¿™æ˜¯ä¸€ä¸ªå…³äºæœºå™¨å­¦ä¹ çš„åŸºç¡€æ•™ç¨‹ï¼Œä»‹ç»äº†ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€‚",
            "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
            "doc_type": "tutorial",
            "source": "ml_guide.md",
        },
        {
            "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚",
            "title": "æ·±åº¦å­¦ä¹ ä»‹ç»",
            "doc_type": "tutorial",
            "source": "dl_intro.md",
        },
        {
            "content": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’ŒWebå¼€å‘ã€‚",
            "title": "Pythonç¼–ç¨‹å…¥é—¨",
            "doc_type": "programming",
            "source": "python_basics.md",
        },
        {
            "content": "æ•°æ®åº“è®¾è®¡æ˜¯è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦ç¯èŠ‚ï¼Œéœ€è¦è€ƒè™‘æ•°æ®çš„ç»“æ„åŒ–å­˜å‚¨å’ŒæŸ¥è¯¢æ•ˆç‡ã€‚",
            "title": "æ•°æ®åº“è®¾è®¡åŸåˆ™",
            "doc_type": "database",
            "source": "db_design.md",
        },
    ]

    saved_docs = []
    for doc_data in test_documents:
        try:
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = mock_get_embedding(doc_data["content"])

            # ä¿å­˜åˆ°æ•°æ®åº“
            doc = save_vector_document(
                content=doc_data["content"],
                embedding=embedding,
                title=doc_data["title"],
                doc_type=doc_data["doc_type"],
                source=doc_data["source"],
                metadata={"test": True, "category": doc_data["doc_type"]},
            )
            saved_docs.append(doc)
            logger.info(f"âœ… å·²ä¿å­˜æ–‡æ¡£: {doc.title}")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ–‡æ¡£å¤±è´¥: {e}")

    # 2. æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢
    try:
        query_text = "æˆ‘æƒ³å­¦ä¹ äººå·¥æ™ºèƒ½å’Œç¥ç»ç½‘ç»œ"
        query_embedding = mock_get_embedding(query_text)

        logger.info(f"ğŸ” æœç´¢æŸ¥è¯¢: {query_text}")

        # æœç´¢ç›¸ä¼¼æ–‡æ¡£
        similar_docs = search_similar_documents(
            query_embedding=query_embedding,
            limit=3,
            similarity_threshold=0.0,  # é™ä½é˜ˆå€¼ä»¥ä¾¿çœ‹åˆ°ç»“æœ
        )

        logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(similar_docs)} ä¸ªç›¸ä¼¼æ–‡æ¡£:")
        for doc, similarity in similar_docs:
            logger.info(f"  - {doc.title}: ç›¸ä¼¼åº¦ {similarity:.4f}")
            logger.info(f"    å†…å®¹: {doc.content[:50]}...")

        # æŒ‰ç±»å‹è¿‡æ»¤æœç´¢
        tutorial_docs = search_similar_documents(
            query_embedding=query_embedding,
            limit=3,
            doc_type_filter="tutorial",
            similarity_threshold=0.0,
        )

        logger.info(f"ğŸ“š æ•™ç¨‹ç±»æ–‡æ¡£æœç´¢ç»“æœ ({len(tutorial_docs)} ä¸ª):")
        for doc, similarity in tutorial_docs:
            logger.info(f"  - {doc.title}: ç›¸ä¼¼åº¦ {similarity:.4f}")

    except Exception as e:
        logger.error(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {e}")

    # 3. è·å–ç»Ÿè®¡ä¿¡æ¯
    try:
        stats = get_database_vector_stats()
        logger.info(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡: {stats}")
    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {e}")


@pytest.mark.integration
@pytest.mark.database
def test_conversation_vector_operations() -> None:
    """æµ‹è¯•å¯¹è¯å‘é‡æ“ä½œ - ä½¿ç”¨ORM"""
    from multi_agents_game.db.pgsql_vector_ops import (
        save_conversation_vector,
        search_similar_conversations,
    )
    from uuid import uuid4

    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•å¯¹è¯å‘é‡æ“ä½œ...")

    # æ¨¡æ‹Ÿæ¸¸æˆä¼šè¯ID
    game_session_id = uuid4()

    # 1. ä¿å­˜ä¸€äº›æµ‹è¯•å¯¹è¯
    test_conversations = [
        {
            "content": "ç©å®¶è¯·æ±‚æŸ¥çœ‹å½“å‰çš„æ¸¸æˆçŠ¶æ€å’Œå¯ç”¨è¡ŒåŠ¨",
            "sender": "player_1",
            "receiver": "game_master",
            "message_type": "player_request",
        },
        {
            "content": "æ¸¸æˆä¸»æŒå›åº”ï¼šä½ ç°åœ¨åœ¨æ£®æ—ä¸­ï¼Œå¯ä»¥é€‰æ‹©å‘åŒ—ã€å‘å—æˆ–è€…åœç•™",
            "sender": "game_master",
            "receiver": "player_1",
            "message_type": "game_response",
        },
        {
            "content": "ç©å®¶å†³å®šå‘åŒ—å‰è¿›æ¢ç´¢æ–°åŒºåŸŸ",
            "sender": "player_1",
            "receiver": "game_master",
            "message_type": "player_action",
        },
        {
            "content": "é‡åˆ°äº†ä¸€ç¾¤å‹å–„çš„ç²¾çµï¼Œä»–ä»¬æ„¿æ„æä¾›å¸®åŠ©",
            "sender": "game_master",
            "receiver": "player_1",
            "message_type": "game_event",
        },
    ]

    saved_conversations = []
    for conv_data in test_conversations:
        try:
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = mock_get_embedding(conv_data["content"])

            # ä¿å­˜åˆ°æ•°æ®åº“
            conv = save_conversation_vector(
                message_content=conv_data["content"],
                embedding=embedding,
                sender=conv_data["sender"],
                receiver=conv_data["receiver"],
                message_type=conv_data["message_type"],
                game_session_id=game_session_id,
            )
            saved_conversations.append(conv)
            logger.info(f"âœ… å·²ä¿å­˜å¯¹è¯: {conv_data['message_type']}")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¯¹è¯å¤±è´¥: {e}")

    # 2. æµ‹è¯•å¯¹è¯æœç´¢
    try:
        query_text = "ç©å®¶æƒ³è¦æ¢ç´¢å’Œç§»åŠ¨"
        query_embedding = mock_get_embedding(query_text)

        logger.info(f"ğŸ” æœç´¢ç›¸ä¼¼å¯¹è¯: {query_text}")

        # æœç´¢ç›¸ä¼¼å¯¹è¯
        similar_convs = search_similar_conversations(
            query_embedding=query_embedding,
            limit=3,
            game_session_id=game_session_id,
            similarity_threshold=0.0,
        )

        logger.info(f"ğŸ’¬ æ‰¾åˆ° {len(similar_convs)} ä¸ªç›¸ä¼¼å¯¹è¯:")
        for conv, similarity in similar_convs:
            logger.info(f"  - {conv.message_type}: ç›¸ä¼¼åº¦ {similarity:.4f}")
            logger.info(f"    å†…å®¹: {conv.message_content[:50]}...")

    except Exception as e:
        logger.error(f"âŒ å¯¹è¯æœç´¢å¤±è´¥: {e}")


@pytest.mark.integration
@pytest.mark.database
def test_game_knowledge_operations() -> None:
    """æµ‹è¯•æ¸¸æˆçŸ¥è¯†å‘é‡æ“ä½œ - ä½¿ç”¨ORM"""
    from multi_agents_game.db.pgsql_vector_ops import (
        save_game_knowledge_vector,
        search_game_knowledge,
    )

    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•æ¸¸æˆçŸ¥è¯†å‘é‡æ“ä½œ...")

    # 1. ä¿å­˜ä¸€äº›æµ‹è¯•æ¸¸æˆçŸ¥è¯†
    test_knowledge: List[Dict[str, Any]] = [
        {
            "content": "åœ¨RPGæ¸¸æˆä¸­ï¼Œè§’è‰²å±æ€§åŒ…æ‹¬åŠ›é‡ã€æ•æ·ã€æ™ºåŠ›å’Œä½“åŠ›ï¼Œè¿™äº›å±æ€§å½±å“æˆ˜æ–—èƒ½åŠ›",
            "title": "RPGè§’è‰²å±æ€§ç³»ç»Ÿ",
            "category": "game_mechanics",
            "game_type": "rpg",
            "difficulty": 1,
            "tags": ["å±æ€§", "è§’è‰²", "æˆ˜æ–—"],
        },
        {
            "content": "å¡ç‰Œæ¸¸æˆçš„åŸºæœ¬ç­–ç•¥æ˜¯å¹³è¡¡èµ„æºç®¡ç†å’Œæ”»å‡»æ—¶æœºï¼Œéœ€è¦è€ƒè™‘æ‰‹ç‰Œæ•°é‡å’Œæ³•åŠ›å€¼",
            "title": "å¡ç‰Œæ¸¸æˆåŸºç¡€ç­–ç•¥",
            "category": "strategy",
            "game_type": "card_game",
            "difficulty": 2,
            "tags": ["ç­–ç•¥", "èµ„æº", "æ—¶æœº"],
        },
        {
            "content": "å¤šäººåˆä½œæ¸¸æˆä¸­ï¼Œå›¢é˜Ÿæ²Ÿé€šå’Œè§’è‰²åˆ†å·¥æ˜¯è·èƒœçš„å…³é”®è¦ç´ ",
            "title": "å¤šäººåˆä½œæŠ€å·§",
            "category": "teamwork",
            "game_type": "multiplayer",
            "difficulty": 3,
            "tags": ["åˆä½œ", "æ²Ÿé€š", "å›¢é˜Ÿ"],
        },
    ]

    saved_knowledge = []
    for knowledge_data in test_knowledge:
        try:
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = mock_get_embedding(cast(str, knowledge_data["content"]))

            # ä¿å­˜åˆ°æ•°æ®åº“
            knowledge = save_game_knowledge_vector(
                knowledge_content=cast(str, knowledge_data["content"]),
                embedding=embedding,
                title=cast(str, knowledge_data["title"]),
                knowledge_category=cast(str, knowledge_data["category"]),
                game_type=cast(str, knowledge_data["game_type"]),
                difficulty_level=cast(int, knowledge_data["difficulty"]),
                tags=cast(List[str], knowledge_data["tags"]),
                priority=cast(int, knowledge_data["difficulty"]),  # éš¾åº¦è¶Šé«˜ä¼˜å…ˆçº§è¶Šé«˜
            )
            saved_knowledge.append(knowledge)
            logger.info(f"âœ… å·²ä¿å­˜æ¸¸æˆçŸ¥è¯†: {knowledge.title}")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ¸¸æˆçŸ¥è¯†å¤±è´¥: {e}")

    # 2. æµ‹è¯•çŸ¥è¯†æœç´¢
    try:
        query_text = "å¦‚ä½•åœ¨æ¸¸æˆä¸­æå‡è§’è‰²æˆ˜æ–—åŠ›"
        query_embedding = mock_get_embedding(query_text)

        logger.info(f"ğŸ” æœç´¢æ¸¸æˆçŸ¥è¯†: {query_text}")

        # æœç´¢ç›¸å…³çŸ¥è¯†
        relevant_knowledge = search_game_knowledge(
            query_embedding=query_embedding,
            limit=3,
            max_difficulty=2,  # åªæœç´¢éš¾åº¦2çº§ä»¥ä¸‹çš„çŸ¥è¯†
            similarity_threshold=0.0,
        )

        logger.info(f"ğŸ® æ‰¾åˆ° {len(relevant_knowledge)} ä¸ªç›¸å…³çŸ¥è¯†:")
        for knowledge, similarity in relevant_knowledge:
            logger.info(
                f"  - {knowledge.title}: ç›¸ä¼¼åº¦ {similarity:.4f}, éš¾åº¦ {knowledge.difficulty_level}"
            )
            logger.info(f"    å†…å®¹: {knowledge.knowledge_content[:50]}...")

    except Exception as e:
        logger.error(f"âŒ æ¸¸æˆçŸ¥è¯†æœç´¢å¤±è´¥: {e}")


# ================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º
# ================================


@pytest.mark.integration
@pytest.mark.demo
def demo_document_rag_system() -> None:
    """æ¼”ç¤ºåŸºäºæ–‡æ¡£çš„RAGç³»ç»Ÿ"""
    from multi_agents_game.db.pgsql_vector_ops import (
        save_vector_document,
        search_similar_documents,
    )

    logger.info("ğŸ¤– æ¼”ç¤ºæ–‡æ¡£RAGç³»ç»Ÿ...")

    # 1. ä¿å­˜ä¸€äº›çŸ¥è¯†æ–‡æ¡£
    documents = [
        {
            "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
            "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè®©è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ ã€‚ä¸»è¦åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰ç§ç±»å‹ã€‚",
            "doc_type": "knowledge",
            "source": "ml_textbook.pdf",
        },
        {
            "title": "æ·±åº¦å­¦ä¹ åŸç†",
            "content": "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚å®ƒåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚",
            "doc_type": "knowledge",
            "source": "dl_guide.pdf",
        },
        {
            "title": "Pythonæ•°æ®ç§‘å­¦",
            "content": "Pythonæ˜¯æ•°æ®ç§‘å­¦é¢†åŸŸæœ€æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ã€‚ä¸»è¦åº“åŒ…æ‹¬NumPyã€Pandasã€Matplotlibå’ŒScikit-learnç­‰ã€‚",
            "doc_type": "tutorial",
            "source": "python_ds.md",
        },
        {
            "title": "å‘é‡æ•°æ®åº“åº”ç”¨",
            "content": "å‘é‡æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡æ•°æ®ï¼Œç‰¹åˆ«é€‚ç”¨äºç›¸ä¼¼æ€§æœç´¢ã€æ¨èç³»ç»Ÿå’ŒRAGåº”ç”¨ã€‚",
            "doc_type": "knowledge",
            "source": "vector_db.pdf",
        },
    ]

    logger.info("ğŸ“š ä¿å­˜çŸ¥è¯†æ–‡æ¡£...")
    for doc_data in documents:
        embedding = mock_openai_embedding(doc_data["content"])
        save_vector_document(
            content=doc_data["content"],
            embedding=embedding,
            title=doc_data["title"],
            doc_type=doc_data["doc_type"],
            source=doc_data["source"],
            metadata={"category": "knowledge_base"},
        )

    # 2. æ¨¡æ‹Ÿç”¨æˆ·æŸ¥è¯¢
    queries = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "å¦‚ä½•ä½¿ç”¨Pythonè¿›è¡Œæ•°æ®åˆ†æï¼Ÿ",
        "å‘é‡æ•°æ®åº“æœ‰ä»€ä¹ˆç”¨é€”ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
    ]

    logger.info("ğŸ” å¤„ç†ç”¨æˆ·æŸ¥è¯¢...")
    for query in queries:
        logger.info(f"\nâ“ ç”¨æˆ·é—®é¢˜: {query}")

        # è·å–æŸ¥è¯¢çš„åµŒå…¥å‘é‡
        query_embedding = mock_openai_embedding(query)

        # æœç´¢ç›¸å…³æ–‡æ¡£
        results = search_similar_documents(
            query_embedding=query_embedding, limit=2, similarity_threshold=0.1
        )

        logger.info("ğŸ“– ç›¸å…³æ–‡æ¡£:")
        for doc, similarity in results:
            logger.info(f"   - {doc.title} (ç›¸ä¼¼åº¦: {similarity:.3f})")
            logger.info(f"     å†…å®¹ç‰‡æ®µ: {doc.content[:100]}...")


@pytest.mark.integration
@pytest.mark.demo
def demo_conversation_memory() -> None:
    """æ¼”ç¤ºå¯¹è¯è®°å¿†ç³»ç»Ÿ"""
    from multi_agents_game.db.pgsql_vector_ops import (
        save_conversation_vector,
        search_similar_conversations,
    )
    from uuid import uuid4

    logger.info("ğŸ’¬ æ¼”ç¤ºå¯¹è¯è®°å¿†ç³»ç»Ÿ...")

    # æ¨¡æ‹Ÿæ¸¸æˆä¼šè¯
    session_id = uuid4()

    # ä¿å­˜ä¸€äº›å¯¹è¯å†å²
    conversations: List[Dict[str, str]] = [
        {
            "content": "æˆ‘æƒ³å­¦ä¹ å¦‚ä½•åœ¨æ¸¸æˆä¸­æå‡è§’è‰²çš„æˆ˜æ–—èƒ½åŠ›",
            "sender": "player_001",
            "message_type": "player_question",
        },
        {
            "content": "ä½ å¯ä»¥é€šè¿‡å‡çº§è£…å¤‡ã€æé«˜å±æ€§ç‚¹å’Œå­¦ä¹ æ–°æŠ€èƒ½æ¥å¢å¼ºæˆ˜æ–—åŠ›",
            "sender": "ai_assistant",
            "message_type": "assistant_response",
        },
        {
            "content": "è¯·å¸®æˆ‘åˆ¶å®šä¸€ä¸ªè§’è‰²å‘å±•ç­–ç•¥",
            "sender": "player_001",
            "message_type": "player_request",
        },
        {
            "content": "å»ºè®®ä¼˜å…ˆæå‡æ ¸å¿ƒå±æ€§ï¼Œç„¶åè·å–é€‚åˆä½ èŒä¸šçš„è£…å¤‡å’ŒæŠ€èƒ½",
            "sender": "ai_assistant",
            "message_type": "assistant_advice",
        },
    ]

    logger.info("ğŸ’¾ ä¿å­˜å¯¹è¯å†å²...")
    for conv in conversations:
        embedding = mock_openai_embedding(conv["content"])
        save_conversation_vector(
            message_content=conv["content"],
            embedding=embedding,
            sender=conv["sender"],
            message_type=conv["message_type"],
            game_session_id=session_id,
        )

    # æŸ¥è¯¢ç›¸ä¼¼å¯¹è¯
    query = "å¦‚ä½•æå‡æ¸¸æˆè§’è‰²å®åŠ›ï¼Ÿ"
    logger.info(f"\nğŸ” æŸ¥è¯¢ç›¸ä¼¼å¯¹è¯: {query}")

    query_embedding = mock_openai_embedding(query)
    similar_convs = search_similar_conversations(
        query_embedding=query_embedding,
        limit=3,
        game_session_id=session_id,
        similarity_threshold=0.1,
    )

    logger.info("ğŸ—¨ï¸ ç›¸ä¼¼çš„å†å²å¯¹è¯:")
    result_conv: ConversationVectorDB
    result_similarity: float
    for result_conv, result_similarity in similar_convs:
        # result_conv æ˜¯ ConversationVectorDB å¯¹è±¡ï¼Œä¸æ˜¯å­—å…¸
        logger.info(
            f"   - {result_conv.sender}: {result_conv.message_content[:50]}... (ç›¸ä¼¼åº¦: {result_similarity:.3f})"
        )


@pytest.mark.integration
@pytest.mark.demo
def demo_game_knowledge_system() -> None:
    """æ¼”ç¤ºæ¸¸æˆçŸ¥è¯†ç³»ç»Ÿ"""
    from multi_agents_game.db.pgsql_vector_ops import (
        save_game_knowledge_vector,
        search_game_knowledge,
    )

    logger.info("ğŸ® æ¼”ç¤ºæ¸¸æˆçŸ¥è¯†ç³»ç»Ÿ...")

    # ä¿å­˜æ¸¸æˆçŸ¥è¯†
    knowledge_items: List[Dict[str, Any]] = [
        {
            "title": "RPGè§’è‰²å±æ€§ç³»ç»Ÿ",
            "content": "RPGæ¸¸æˆä¸­ï¼Œè§’è‰²é€šå¸¸æœ‰åŠ›é‡ã€æ•æ·ã€æ™ºåŠ›ã€ä½“åŠ›ç­‰åŸºç¡€å±æ€§ã€‚åŠ›é‡å½±å“ç‰©ç†æ”»å‡»ï¼Œæ•æ·å½±å“é€Ÿåº¦å’Œæš´å‡»ï¼Œæ™ºåŠ›å½±å“é­”æ³•å¨åŠ›ï¼Œä½“åŠ›å½±å“ç”Ÿå‘½å€¼ã€‚",
            "category": "game_mechanics",
            "game_type": "rpg",
            "difficulty": 1,
            "tags": ["å±æ€§", "è§’è‰²", "åŸºç¡€"],
        },
        {
            "title": "æˆ˜æ–—ç­–ç•¥åŸºç¡€",
            "content": "æœ‰æ•ˆçš„æˆ˜æ–—ç­–ç•¥åŒ…æ‹¬ï¼šäº†è§£æ•Œäººå¼±ç‚¹ã€åˆç†ä½¿ç”¨æŠ€èƒ½å†·å´ã€ä¿æŒè·ç¦»æ§åˆ¶ã€å›¢é˜Ÿé…åˆç­‰ã€‚éœ€è¦æ ¹æ®ä¸åŒæ•Œäººç±»å‹è°ƒæ•´æˆ˜æœ¯ã€‚",
            "category": "strategy",
            "game_type": "rpg",
            "difficulty": 2,
            "tags": ["æˆ˜æ–—", "ç­–ç•¥", "æŠ€å·§"],
        },
        {
            "title": "è£…å¤‡å¼ºåŒ–ç³»ç»Ÿ",
            "content": "è£…å¤‡å¼ºåŒ–å¯ä»¥æå‡è£…å¤‡çš„åŸºç¡€å±æ€§ã€‚é€šå¸¸éœ€è¦æ¶ˆè€—å¼ºåŒ–çŸ³å’Œé‡‘å¸ã€‚å¼ºåŒ–ç­‰çº§è¶Šé«˜ï¼ŒæˆåŠŸç‡è¶Šä½ï¼Œä½†å±æ€§æå‡è¶Šæ˜æ˜¾ã€‚",
            "category": "equipment",
            "game_type": "rpg",
            "difficulty": 2,
            "tags": ["è£…å¤‡", "å¼ºåŒ–", "å±æ€§"],
        },
    ]

    logger.info("ğŸ“– ä¿å­˜æ¸¸æˆçŸ¥è¯†...")
    for knowledge in knowledge_items:
        embedding = mock_openai_embedding(cast(str, knowledge["content"]))
        save_game_knowledge_vector(
            knowledge_content=cast(str, knowledge["content"]),
            embedding=embedding,
            title=cast(str, knowledge["title"]),
            knowledge_category=cast(str, knowledge["category"]),
            game_type=cast(str, knowledge["game_type"]),
            difficulty_level=cast(int, knowledge["difficulty"]),
            tags=cast(List[str], knowledge["tags"]),
            priority=cast(int, knowledge["difficulty"]),
        )

    # æŸ¥è¯¢æ¸¸æˆçŸ¥è¯†
    queries = ["å¦‚ä½•æå‡è§’è‰²çš„æ”»å‡»åŠ›ï¼Ÿ", "æˆ˜æ–—ä¸­éœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ", "è£…å¤‡è¦æ€ä¹ˆå¼ºåŒ–ï¼Ÿ"]

    for query in queries:
        logger.info(f"\nâ“ ç©å®¶é—®é¢˜: {query}")
        query_embedding = mock_openai_embedding(query)

        knowledge_results = search_game_knowledge(
            query_embedding=query_embedding,
            limit=2,
            game_type_filter="rpg",
            max_difficulty=2,
            similarity_threshold=0.1,
        )

        logger.info("ğŸ’¡ ç›¸å…³çŸ¥è¯†:")
        result_knowledge: GameKnowledgeVectorDB
        result_similarity: float
        for result_knowledge, result_similarity in knowledge_results:
            # result_knowledge æ˜¯ GameKnowledgeVectorDB å¯¹è±¡ï¼Œä¸æ˜¯å­—å…¸
            logger.info(
                f"   - {result_knowledge.title} (ç›¸ä¼¼åº¦: {result_similarity:.3f})"
            )
            logger.info(f"     çŸ¥è¯†: {result_knowledge.knowledge_content[:80]}...")


# ================================
# ä¸»å‡½æ•°å’Œæµ‹è¯•è¿è¡Œå™¨
# ================================


def run_all_vector_tests() -> None:
    """è¿è¡Œæ‰€æœ‰å‘é‡åŠŸèƒ½æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œ pgvector åŠŸèƒ½æµ‹è¯•...")

    try:
        # ç¡®ä¿æ•°æ®åº“è¡¨å·²åˆ›å»º
        from multi_agents_game.db.pgsql_client import engine
        from multi_agents_game.db.pgsql_client import Base  # type: ignore[attr-defined]

        Base.metadata.create_all(bind=engine)
        logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ª")

        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_vector_document_operations()
        test_conversation_vector_operations()
        test_game_knowledge_operations()

        # è·å–æœ€ç»ˆç»Ÿè®¡
        from multi_agents_game.db.pgsql_vector_ops import get_database_vector_stats

        final_stats = get_database_vector_stats()
        logger.info(f"ğŸ æµ‹è¯•å®Œæˆï¼Œæœ€ç»ˆç»Ÿè®¡: {final_stats}")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        raise e


def run_all_demos() -> None:
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    logger.info("ğŸš€ pgvectoré›†æˆæ¼”ç¤ºå¼€å§‹...")

    try:
        # ç¡®ä¿æ•°æ®åº“è¡¨å·²åˆ›å»º
        from multi_agents_game.db.pgsql_client import engine
        from multi_agents_game.db.pgsql_client import Base  # type: ignore[attr-defined]

        Base.metadata.create_all(bind=engine)

        # è¿è¡Œå„ç§æ¼”ç¤º
        demo_document_rag_system()
        demo_conversation_memory()
        demo_game_knowledge_system()

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        from multi_agents_game.db.pgsql_vector_ops import get_database_vector_stats

        logger.info("\nğŸ“Š æœ€ç»ˆæ•°æ®åº“ç»Ÿè®¡:")
        stats = get_database_vector_stats()
        for table_name, table_stats in stats.items():
            logger.info(f"   {table_name}: {table_stats['with_embeddings']} æ¡å‘é‡è®°å½•")

        logger.info("\nâœ… pgvectoré›†æˆæ¼”ç¤ºå®Œæˆï¼")
        logger.info("ğŸ‰ æ‚¨ç°åœ¨å¯ä»¥åœ¨é¡¹ç›®ä¸­ä½¿ç”¨å‘é‡æ•°æ®åº“åŠŸèƒ½äº†ï¼")

    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


@pytest.mark.integration
@pytest.mark.comprehensive
def test_comprehensive_pgvector_integration(setup_database_tables: Any) -> None:
    """è¿è¡Œå®Œæ•´çš„ pgvector é›†æˆæµ‹è¯•"""
    logger.info("ğŸŒŸ å¼€å§‹ pgvector ç»¼åˆæµ‹è¯•å’Œæ¼”ç¤º...")

    try:
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€SQLæµ‹è¯•
        logger.info("\n" + "=" * 50)
        logger.info("ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€SQLå‘é‡æ“ä½œæµ‹è¯•")
        logger.info("=" * 50)
        test_basic_vector_operations()
        test_high_dimension_vectors()

        # ç¬¬äºŒéƒ¨åˆ†ï¼šORMæµ‹è¯•
        logger.info("\n" + "=" * 50)
        logger.info("ç¬¬äºŒéƒ¨åˆ†ï¼šORMå‘é‡æ“ä½œæµ‹è¯•")
        logger.info("=" * 50)
        test_vector_document_operations()
        test_conversation_vector_operations()
        test_game_knowledge_operations()

        # æœ€ç»ˆæ€»ç»“
        logger.info("\n" + "=" * 50)
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        logger.info("âœ… pgvector åŠŸèƒ½é›†æˆéªŒè¯æˆåŠŸï¼")
        logger.info("ğŸ’¡ æ‚¨ç°åœ¨å¯ä»¥åœ¨é¡¹ç›®ä¸­ä½¿ç”¨å®Œæ•´çš„å‘é‡æ•°æ®åº“åŠŸèƒ½äº†ï¼")
        logger.info("=" * 50)

    except Exception as e:
        logger.error(f"âŒ ç»¼åˆæµ‹è¯•å¤±è´¥: {e}")
        raise e


@pytest.mark.integration
@pytest.mark.demo
@pytest.mark.slow
def test_comprehensive_pgvector_demos(setup_database_tables: Any) -> None:
    """è¿è¡Œå®Œæ•´çš„ pgvector æ¼”ç¤º"""
    logger.info("ğŸš€ pgvectoré›†æˆæ¼”ç¤ºå¼€å§‹...")

    try:
        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®é™…åº”ç”¨æ¼”ç¤º
        logger.info("\n" + "=" * 50)
        logger.info("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º")
        logger.info("=" * 50)
        demo_document_rag_system()
        demo_conversation_memory()
        demo_game_knowledge_system()

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        from multi_agents_game.db.pgsql_vector_ops import get_database_vector_stats

        logger.info("\nğŸ“Š æœ€ç»ˆæ•°æ®åº“ç»Ÿè®¡:")
        stats = get_database_vector_stats()
        for table_name, table_stats in stats.items():
            logger.info(f"   {table_name}: {table_stats['with_embeddings']} æ¡å‘é‡è®°å½•")

        logger.info("\nâœ… pgvectoré›†æˆæ¼”ç¤ºå®Œæˆï¼")
        logger.info("ğŸ‰ æ‚¨ç°åœ¨å¯ä»¥åœ¨é¡¹ç›®ä¸­ä½¿ç”¨å‘é‡æ•°æ®åº“åŠŸèƒ½äº†ï¼")

    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        raise e


if __name__ == "__main__":
    # å½“ç›´æ¥è¿è¡Œè„šæœ¬æ—¶ï¼Œæ‰§è¡Œå®Œæ•´æµ‹è¯•
    import pytest

    # å¯ä»¥é€‰æ‹©è¿è¡Œä¸åŒçš„æµ‹è¯•æ¨¡å—
    import argparse

    parser = argparse.ArgumentParser(description="pgvector ç»¼åˆæµ‹è¯•å’Œæ¼”ç¤º")
    parser.add_argument(
        "--mode",
        choices=["all", "basic", "orm", "demo"],
        default="all",
        help="é€‰æ‹©è¿è¡Œæ¨¡å¼",
    )

    args = parser.parse_args()

    if args.mode == "all":
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        pytest.main([__file__, "-v", "-s"])
    elif args.mode == "basic":
        logger.info("ğŸ§ª åªè¿è¡ŒåŸºç¡€SQLæµ‹è¯•...")
        pytest.main(
            [
                __file__ + "::test_basic_vector_operations",
                __file__ + "::test_high_dimension_vectors",
                "-v",
                "-s",
            ]
        )
    elif args.mode == "orm":
        logger.info("ğŸ§ª åªè¿è¡ŒORMæµ‹è¯•...")
        pytest.main(
            [
                __file__ + "::test_vector_document_operations",
                __file__ + "::test_conversation_vector_operations",
                __file__ + "::test_game_knowledge_operations",
                "-v",
                "-s",
            ]
        )
    elif args.mode == "demo":
        logger.info("ğŸ§ª åªè¿è¡Œæ¼”ç¤º...")
        pytest.main([__file__ + "::test_comprehensive_pgvector_demos", "-v", "-s"])
