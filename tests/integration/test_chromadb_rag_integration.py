#!/usr/bin/env python3
"""
ChromaDB RAGç³»ç»Ÿé›†æˆæµ‹è¯•

ç”¨äºéªŒè¯æ”¹é€ åçš„RAGç³»ç»Ÿæ˜¯å¦èƒ½æ­£å¸¸åˆå§‹åŒ–å’Œè¿è¡Œ

æµ‹è¯•ç­–ç•¥ï¼š
1. åˆ›å»ºç‹¬ç«‹çš„æµ‹è¯•çŸ¥è¯†åº“ï¼ˆä¸ä¸»ç³»ç»Ÿéš”ç¦»ï¼‰
2. ä½¿ç”¨ç‹¬ç«‹çš„ ChromaDB collectionï¼ˆä¸å½±å“ä¸»ç³»ç»Ÿï¼‰
3. æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒ RAG åŠŸèƒ½
"""

from typing import Dict, List, Generator, cast
import pytest
import asyncio
import time
from loguru import logger
from chromadb.api.models.Collection import Collection

from src.ai_rpg.chroma import chroma_client
from src.ai_rpg.rag import add_documents, search_documents
from src.ai_rpg.embedding_model import multilingual_model


# ============================================================================
# æµ‹è¯•ä¸“ç”¨çŸ¥è¯†åº“ï¼ˆç‹¬ç«‹äºæ¸¸æˆä¸»ç³»ç»Ÿï¼‰
# ============================================================================
TEST_KNOWLEDGE_BASE: Dict[str, List[str]] = {
    "ç¼–ç¨‹è¯­è¨€": [
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„æ ‡å‡†åº“è€Œé—»å",
        "JavaScriptæ˜¯Webå¼€å‘çš„æ ¸å¿ƒè¯­è¨€ï¼Œå¯ä»¥åœ¨æµè§ˆå™¨å’ŒæœåŠ¡å™¨ç«¯è¿è¡Œ",
        "Rustæ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œå¼ºè°ƒå†…å­˜å®‰å…¨å’Œå¹¶å‘æ€§èƒ½",
        "Goè¯­è¨€ç”±Googleå¼€å‘ï¼Œä¸“æ³¨äºç®€æ´æ€§å’Œé«˜æ•ˆçš„å¹¶å‘å¤„ç†",
    ],
    "æ•°æ®åº“": [
        "PostgreSQLæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„å¼€æºå…³ç³»å‹æ•°æ®åº“ç³»ç»Ÿ",
        "MongoDBæ˜¯ä¸€ä¸ªæµè¡Œçš„NoSQLæ–‡æ¡£æ•°æ®åº“ï¼Œä½¿ç”¨JSONæ ¼å¼å­˜å‚¨æ•°æ®",
        "Redisæ˜¯ä¸€ä¸ªå†…å­˜æ•°æ®åº“ï¼Œå¸¸ç”¨äºç¼“å­˜å’Œæ¶ˆæ¯é˜Ÿåˆ—",
        "ChromaDBæ˜¯ä¸€ä¸ªå‘é‡æ•°æ®åº“ï¼Œä¸“é—¨ç”¨äºå­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡",
    ],
    "AIæŠ€æœ¯": [
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šè¿‡æ•°æ®è®­ç»ƒæ¨¡å‹æ¥åšå‡ºé¢„æµ‹",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹",
        "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€",
        "RAGç³»ç»Ÿç»“åˆæ£€ç´¢å’Œç”ŸæˆæŠ€æœ¯ï¼Œæä¾›æ›´å‡†ç¡®çš„AIå“åº”",
    ],
}

# æµ‹è¯•ä¸“ç”¨ collection åç§°
TEST_COLLECTION_NAME = "test_rag_collection"


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================
def _get_test_collection() -> Collection:
    """è·å–æˆ–åˆ›å»ºæµ‹è¯•ä¸“ç”¨çš„ collection"""
    return chroma_client.get_or_create_collection(
        name=TEST_COLLECTION_NAME,
        metadata={
            "description": "RAGé›†æˆæµ‹è¯•ä¸“ç”¨é›†åˆ",
            "hnsw:space": "cosine",
        },
    )


def _init_test_rag_system() -> bool:
    """åˆå§‹åŒ–æµ‹è¯•ä¸“ç”¨çš„ RAG ç³»ç»Ÿ"""
    collection = _get_test_collection()

    # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå§‹åŒ–
    if collection.count() > 0:
        logger.info(f"æµ‹è¯•collectionå·²æœ‰æ•°æ®ï¼Œè·³è¿‡åˆå§‹åŒ–")
        return True

    # å‡†å¤‡æ–‡æ¡£æ•°æ®ï¼šå°† Dict[str, List[str]] å±•å¼€ä¸º flat lists
    documents_list: List[str] = []
    metadatas_list: List[Dict[str, str]] = []
    ids_list: List[str] = []

    doc_index = 0
    for category, docs in TEST_KNOWLEDGE_BASE.items():
        for doc in docs:
            documents_list.append(doc)
            metadatas_list.append({"category": category})
            ids_list.append(f"test_{category}_{doc_index}")
            doc_index += 1

    # è°ƒç”¨ add_documents
    logger.info(f"å¼€å§‹åŠ è½½æµ‹è¯•çŸ¥è¯†åº“ï¼Œå…± {len(documents_list)} ä¸ªæ–‡æ¡£")
    return add_documents(
        collection=collection,
        embedding_model=multilingual_model,
        documents=documents_list,
        metadatas=metadatas_list,
        ids=ids_list,
    )


def _test_search(query: str, top_k: int = 5) -> tuple[list[str], list[float]]:
    """æµ‹è¯•ä¸“ç”¨çš„è¯­ä¹‰æœç´¢å‡½æ•°"""
    collection = _get_test_collection()
    return search_documents(query, collection, multilingual_model, top_k)


class TestChromaDBRAGIntegration:
    """ChromaDB RAGç³»ç»Ÿé›†æˆæµ‹è¯•ç±»"""

    _test_collection_initialized = False  # ç±»çº§åˆ«æ ‡å¿—ï¼Œç¡®ä¿åªåˆå§‹åŒ–ä¸€æ¬¡

    def test_chromadb_initialization(self) -> None:
        """æµ‹è¯•ChromaDBåˆå§‹åŒ–"""
        logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•ChromaDB RAGç³»ç»Ÿåˆå§‹åŒ–...")

        # æµ‹è¯• ChromaDB collection åˆ›å»º
        collection = _get_test_collection()
        assert collection is not None, "ChromaDB collectionåˆ›å»ºå¤±è´¥"
        logger.info(f"âœ… ChromaDB collectionåˆ›å»ºæˆåŠŸ: {type(collection)}")

        # è·å–åµŒå…¥æ¨¡å‹
        assert multilingual_model is not None, "é¢„åŠ è½½çš„å¤šè¯­è¨€æ¨¡å‹ä¸å¯ç”¨"

        # æµ‹è¯•å®Œæ•´åˆå§‹åŒ–
        success = _init_test_rag_system()
        assert success, "ChromaDB RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"

        # éªŒè¯æ•°æ®å·²åŠ è½½
        doc_count = collection.count()
        expected_count = sum(len(docs) for docs in TEST_KNOWLEDGE_BASE.values())
        assert (
            doc_count == expected_count
        ), f"æ–‡æ¡£æ•°é‡ä¸ç¬¦: æœŸæœ›{expected_count}, å®é™…{doc_count}"

        logger.success(f"ğŸ‰ ChromaDB RAGç³»ç»Ÿåˆå§‹åŒ–æµ‹è¯•é€šè¿‡ï¼æ–‡æ¡£æ•°é‡: {doc_count}")

    def test_semantic_search(self) -> None:
        """æµ‹è¯•è¯­ä¹‰æœç´¢åŠŸèƒ½"""
        logger.info("ğŸ” å¼€å§‹æµ‹è¯•è¯­ä¹‰æœç´¢åŠŸèƒ½...")

        # ç¡®ä¿æµ‹è¯•æ•°æ®å·²åŠ è½½
        collection = _get_test_collection()
        if collection.count() == 0:
            success = _init_test_rag_system()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"

        # æµ‹è¯•è¯­ä¹‰æœç´¢
        test_queries = [
            "Pythonç¼–ç¨‹",
            "å‘é‡æ•°æ®åº“",
            "æ·±åº¦å­¦ä¹ æŠ€æœ¯",
            "NoSQLæ•°æ®åº“",
            "å†…å­˜ç¼“å­˜",
            "å¹¶å‘ç¼–ç¨‹",
        ]

        for test_query in test_queries:
            docs, scores = _test_search(test_query, top_k=3)

            # éªŒè¯æœç´¢ç»“æœ
            assert isinstance(docs, list), f"æœç´¢ç»“æœåº”è¯¥æ˜¯åˆ—è¡¨: {test_query}"
            assert isinstance(scores, list), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯åˆ—è¡¨: {test_query}"
            assert len(docs) == len(scores), f"æ–‡æ¡£å’Œåˆ†æ•°æ•°é‡åº”è¯¥ä¸€è‡´: {test_query}"
            assert len(docs) <= 3, f"è¿”å›ç»“æœä¸åº”è¶…è¿‡top_k: {test_query}"

            logger.info(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: '{test_query}' - æ‰¾åˆ° {len(docs)} ä¸ªç»“æœ")

            for i, (doc, score) in enumerate(zip(docs, scores)):
                assert isinstance(doc, str), f"æ–‡æ¡£å†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸²: {test_query}"
                assert isinstance(
                    score, (int, float)
                ), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯æ•°å­—: {test_query}"
                assert 0 <= score <= 1, f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥åœ¨0-1ä¹‹é—´: {score}"
                logger.info(f"  [{i+1}] ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {doc[:50]}...")

        logger.success("âœ… è¯­ä¹‰æœç´¢åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")

    def test_similarity_score_improvement(self) -> None:
        """æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—ç®—æ³•çš„å‡†ç¡®æ€§"""
        logger.info("ğŸ¯ å¼€å§‹æµ‹è¯•ç›¸ä¼¼åº¦åˆ†æ•°å‡†ç¡®æ€§...")

        # ç¡®ä¿æµ‹è¯•æ•°æ®å·²åŠ è½½
        collection = _get_test_collection()
        if collection.count() == 0:
            success = _init_test_rag_system()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"

        # æµ‹è¯•é«˜ç›¸å…³åº¦æŸ¥è¯¢ï¼ˆåº”è¯¥å¾—åˆ°è¾ƒé«˜çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰
        high_relevance_queries = [
            "Python",  # ç›´æ¥åŒ¹é…çŸ¥è¯†åº“ä¸­çš„å†…å®¹
            "PostgreSQL",  # ç²¾ç¡®åŒ¹é…
            "æœºå™¨å­¦ä¹ ",  # æ ¸å¿ƒæ¦‚å¿µ
        ]

        logger.info("ğŸ“Š æµ‹è¯•é«˜ç›¸å…³åº¦æŸ¥è¯¢...")
        for query in high_relevance_queries:
            docs, scores = _test_search(query, top_k=3)

            if len(scores) > 0:
                best_score = max(scores)
                logger.info(f"ğŸ” æŸ¥è¯¢: '{query}' - æœ€é«˜ç›¸ä¼¼åº¦: {best_score:.3f}")

                # é«˜ç›¸å…³æŸ¥è¯¢åº”è¯¥å¾—åˆ°è¾ƒé«˜çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ>0.3ï¼‰
                assert (
                    best_score > 0.3
                ), f"é«˜ç›¸å…³æŸ¥è¯¢ '{query}' çš„æœ€é«˜ç›¸ä¼¼åº¦è¿‡ä½: {best_score:.3f}"

                # æ‰“å°è¯¦ç»†ç»“æœ
                for i, (doc, score) in enumerate(zip(docs[:3], scores[:3])):
                    logger.info(f"  [{i+1}] ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {doc[:60]}...")

        # æµ‹è¯•ä¸­ç­‰ç›¸å…³åº¦æŸ¥è¯¢
        medium_relevance_queries = [
            "ç¼–ç¨‹å·¥å…·",  # ç›¸å…³ä½†ä¸ç²¾ç¡®åŒ¹é…
            "æ•°æ®å­˜å‚¨",  # ä¸»é¢˜ç›¸å…³
        ]

        logger.info("ğŸ“Š æµ‹è¯•ä¸­ç­‰ç›¸å…³åº¦æŸ¥è¯¢...")
        for query in medium_relevance_queries:
            docs, scores = _test_search(query, top_k=3)

            if len(scores) > 0:
                best_score = max(scores)
                logger.info(f"ğŸ” æŸ¥è¯¢: '{query}' - æœ€é«˜ç›¸ä¼¼åº¦: {best_score:.3f}")

                # ä¸­ç­‰ç›¸å…³æŸ¥è¯¢åº”è¯¥æœ‰åˆç†çš„åˆ†æ•°
                assert (
                    best_score > 0.1
                ), f"ä¸­ç­‰ç›¸å…³æŸ¥è¯¢ '{query}' çš„ç›¸ä¼¼åº¦åˆ†æ•°è¿‡ä½: {best_score:.3f}"

        # æµ‹è¯•ç›¸ä¼¼åº¦åˆ†æ•°çš„åŒºåˆ†åº¦
        logger.info("ğŸ“Š æµ‹è¯•ç›¸ä¼¼åº¦åˆ†æ•°çš„åŒºåˆ†åº¦...")
        high_query = "Python"
        medium_query = "ç¼–ç¨‹å·¥å…·"

        docs_high, scores_high = _test_search(high_query, top_k=1)
        docs_medium, scores_medium = _test_search(medium_query, top_k=1)

        if len(scores_high) > 0 and len(scores_medium) > 0:
            logger.info(f"ğŸ” é«˜ç›¸å…³æŸ¥è¯¢ '{high_query}': {scores_high[0]:.3f}")
            logger.info(f"ğŸ” ä¸­ç­‰ç›¸å…³æŸ¥è¯¢ '{medium_query}': {scores_medium[0]:.3f}")

            # é«˜ç›¸å…³æŸ¥è¯¢çš„åˆ†æ•°åº”è¯¥ä¸ä½äºä¸­ç­‰ç›¸å…³æŸ¥è¯¢
            assert (
                scores_high[0] >= scores_medium[0] * 0.8
            ), f"ç›¸ä¼¼åº¦åˆ†æ•°æ’åºä¸åˆç†: é«˜ç›¸å…³({scores_high[0]:.3f}) < ä¸­ç­‰ç›¸å…³({scores_medium[0]:.3f})"

        logger.success("âœ… ç›¸ä¼¼åº¦åˆ†æ•°å‡†ç¡®æ€§æµ‹è¯•é€šè¿‡ï¼")

    def test_database_state(self) -> None:
        """æµ‹è¯•æ•°æ®åº“çŠ¶æ€"""
        logger.info("ğŸ“Š å¼€å§‹æµ‹è¯•æ•°æ®åº“çŠ¶æ€...")

        # è·å–æµ‹è¯•collection
        collection = _get_test_collection()
        assert collection is not None, "ChromaDBé›†åˆåº”è¯¥å·²åˆ›å»º"
        assert chroma_client is not None, "ChromaDBå®¢æˆ·ç«¯åº”è¯¥å·²åˆ›å»º"

        # ç¡®ä¿æ•°æ®åº“ä¸­æœ‰æ•°æ®
        collection_count = collection.count()
        if collection_count == 0:
            success = _init_test_rag_system()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
            collection_count = collection.count()

        # éªŒè¯å…¨å±€åµŒå…¥æ¨¡å‹å·²åŠ è½½
        assert multilingual_model is not None, "é¢„åŠ è½½çš„å¤šè¯­è¨€æ¨¡å‹ä¸å¯ç”¨"

        # éªŒè¯é›†åˆä¸­æœ‰æ•°æ®
        expected_count = sum(len(docs) for docs in TEST_KNOWLEDGE_BASE.values())
        assert (
            collection_count == expected_count
        ), f"é›†åˆä¸­æ–‡æ¡£æ•°é‡ä¸ç¬¦: æœŸæœ›{expected_count}, å®é™…{collection_count}"
        logger.info(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€æ­£å¸¸ï¼Œæ–‡æ¡£æ•°é‡: {collection_count}")
        logger.success("âœ… æ•°æ®åº“çŠ¶æ€æµ‹è¯•é€šè¿‡ï¼")

    def test_error_handling(self) -> None:
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        logger.info("âš ï¸ å¼€å§‹æµ‹è¯•é”™è¯¯å¤„ç†...")

        # ç¡®ä¿æ•°æ®åº“ä¸­æœ‰æ•°æ®
        collection = _get_test_collection()
        if collection.count() == 0:
            success = _init_test_rag_system()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"

        # æµ‹è¯•ç©ºæŸ¥è¯¢
        docs, scores = _test_search("", top_k=3)
        assert isinstance(docs, list), "ç©ºæŸ¥è¯¢åº”è¯¥è¿”å›åˆ—è¡¨"
        assert isinstance(scores, list), "ç©ºæŸ¥è¯¢åº”è¯¥è¿”å›åˆ†æ•°åˆ—è¡¨"
        logger.info(f"ç©ºæŸ¥è¯¢è¿”å›: {len(docs)} ä¸ªç»“æœ")

        # æµ‹è¯•å¼‚å¸¸æŸ¥è¯¢å‚æ•°
        docs, scores = _test_search("æµ‹è¯•æŸ¥è¯¢", top_k=0)
        assert isinstance(docs, list), "å¼‚å¸¸å‚æ•°åº”è¯¥è¿”å›åˆ—è¡¨"
        assert isinstance(scores, list), "å¼‚å¸¸å‚æ•°åº”è¯¥è¿”å›åˆ†æ•°åˆ—è¡¨"
        logger.info(f"top_k=0æŸ¥è¯¢è¿”å›: {len(docs)} ä¸ªç»“æœ")

        logger.success("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡ï¼")

    async def test_parallel_semantic_search(self) -> None:
        """æµ‹è¯•å¹¶è¡Œè¯­ä¹‰æœç´¢åŠŸèƒ½"""
        logger.info("ğŸš€ å¼€å§‹æµ‹è¯•å¹¶è¡Œè¯­ä¹‰æœç´¢åŠŸèƒ½...")

        # ç¡®ä¿æµ‹è¯•æ•°æ®å·²åŠ è½½
        collection = _get_test_collection()
        if collection.count() == 0:
            success = _init_test_rag_system()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"

        # å®šä¹‰å¤šä¸ªæµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "Pythonç¼–ç¨‹",
            "æ•°æ®åº“ç³»ç»Ÿ",
            "æœºå™¨å­¦ä¹ ",
            "å‘é‡æ•°æ®åº“",
            "å¹¶å‘ç¼–ç¨‹",
            "è‡ªç„¶è¯­è¨€å¤„ç†",
        ]

        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡åŒ…è£…å™¨
        async def async_search(query: str) -> tuple[str, list[str], list[float]]:
            """å¼‚æ­¥æœç´¢åŒ…è£…å™¨"""
            docs, scores = await asyncio.to_thread(
                _test_search,
                query,
                3,
            )
            return query, docs, scores

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æœç´¢æŸ¥è¯¢
        logger.info(f"ğŸ” å¹¶è¡Œæ‰§è¡Œ {len(test_queries)} ä¸ªæœç´¢æŸ¥è¯¢...")
        results = await asyncio.gather(
            *[async_search(query) for query in test_queries], return_exceptions=True
        )

        # è®°å½•ç»“æŸæ—¶é—´
        parallel_time = time.time() - start_time
        logger.info(f"âš¡ å¹¶è¡Œæœç´¢è€—æ—¶: {parallel_time:.2f}ç§’")

        # éªŒè¯å¹¶è¡Œæœç´¢ç»“æœ
        successful_results: list[tuple[str, list[str], list[float]]] = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"æœç´¢å¤±è´¥: {result}")
                pytest.fail(f"å¹¶è¡Œæœç´¢ä¸­å‡ºç°å¼‚å¸¸: {result}")
            else:
                successful_results.append(
                    cast(tuple[str, list[str], list[float]], result)
                )

        assert len(successful_results) == len(test_queries), "æ‰€æœ‰æŸ¥è¯¢éƒ½åº”è¯¥æˆåŠŸ"

        # éªŒè¯æ¯ä¸ªæœç´¢ç»“æœ
        for query, docs, scores in successful_results:
            assert isinstance(docs, list), f"æœç´¢ç»“æœåº”è¯¥æ˜¯åˆ—è¡¨: {query}"
            assert isinstance(scores, list), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯åˆ—è¡¨: {query}"
            assert len(docs) == len(scores), f"æ–‡æ¡£å’Œåˆ†æ•°æ•°é‡åº”è¯¥ä¸€è‡´: {query}"

            logger.info(f"ğŸ” å¹¶è¡ŒæŸ¥è¯¢: '{query}' - æ‰¾åˆ° {len(docs)} ä¸ªç»“æœ")

            for doc, score in zip(docs, scores):
                assert isinstance(doc, str), f"æ–‡æ¡£å†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸²: {query}"
                assert isinstance(score, (int, float)), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯æ•°å­—: {query}"
                assert 0 <= score <= 1, f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥åœ¨0-1ä¹‹é—´: {score}"

        # æ¯”è¾ƒä¸²è¡Œæ‰§è¡Œæ—¶é—´ï¼ˆå¯é€‰ï¼‰
        logger.info("â±ï¸ å¼€å§‹ä¸²è¡Œæ‰§è¡Œå¯¹æ¯”æµ‹è¯•...")
        start_time = time.time()

        for query in test_queries:
            docs, scores = _test_search(query, top_k=3)
            assert isinstance(docs, list) and isinstance(scores, list)

        serial_time = time.time() - start_time
        logger.info(f"â±ï¸ ä¸²è¡Œæœç´¢è€—æ—¶: {serial_time:.2f}ç§’")

        # è®¡ç®—æ€§èƒ½æå‡
        if serial_time > 0 and parallel_time > 0:
            speedup = serial_time / parallel_time
            logger.success(f"ğŸš€ å¹¶è¡Œæœç´¢æ€§èƒ½æå‡: {speedup:.2f}x")

        logger.success("âœ… å¹¶è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•é€šè¿‡ï¼")

    def test_parallel_semantic_search_sync(self) -> None:
        """åŒæ­¥è°ƒç”¨å¹¶è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•çš„åŒ…è£…å™¨"""
        logger.info("ğŸ”„ å¯åŠ¨å¹¶è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•...")
        asyncio.run(self.test_parallel_semantic_search())

    @pytest.fixture(autouse=True)
    def setup_and_teardown(self) -> Generator[None, None, None]:
        """æµ‹è¯•å‰åçš„è®¾ç½®å’Œæ¸…ç†"""
        logger.info("ğŸ”§ æµ‹è¯•ç¯å¢ƒè®¾ç½®...")

        # åªåœ¨ç¬¬ä¸€æ¬¡æµ‹è¯•æ—¶åˆå§‹åŒ–æ•°æ®
        if not TestChromaDBRAGIntegration._test_collection_initialized:
            logger.info("ğŸš€ é¦–æ¬¡æµ‹è¯•ï¼šåˆå§‹åŒ–æµ‹è¯•ä¸“ç”¨collection...")
            success = _init_test_rag_system()
            if success:
                TestChromaDBRAGIntegration._test_collection_initialized = True
                logger.success("âœ… æµ‹è¯•æ•°æ®åˆå§‹åŒ–å®Œæˆ")
            else:
                logger.error("âŒ æµ‹è¯•æ•°æ®åˆå§‹åŒ–å¤±è´¥")
        else:
            logger.info("ğŸ”„ åç»­æµ‹è¯•ï¼šå¤ç”¨ç°æœ‰æµ‹è¯•æ•°æ®")

        yield

        # æµ‹è¯•ç»“æŸåä¿ç•™æµ‹è¯•æ•°æ®
        logger.info("ğŸ§¹ æµ‹è¯•ç»“æŸï¼šä¿ç•™æµ‹è¯•æ•°æ®ä¾›åç»­ä½¿ç”¨")


# ============================================================================
# æ¸…ç†å‡½æ•°ï¼ˆå¯æ‰‹åŠ¨è°ƒç”¨ï¼‰
# ============================================================================
def cleanup_test_collection() -> None:
    """æ¸…ç†æµ‹è¯•ä¸“ç”¨çš„ collectionï¼ˆå¯é€‰ï¼Œæ‰‹åŠ¨è°ƒç”¨ï¼‰"""
    try:
        chroma_client.delete_collection(name=TEST_COLLECTION_NAME)
        logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æµ‹è¯•collection: {TEST_COLLECTION_NAME}")
    except Exception as e:
        logger.warning(f"âš ï¸ åˆ é™¤æµ‹è¯•collectionå¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")


# ç‹¬ç«‹è¿è¡Œæ—¶çš„å…¥å£
if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
