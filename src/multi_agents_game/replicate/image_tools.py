#!/usr/bin/env python3
"""
Replicate å›¾åƒç”Ÿæˆå·¥å…·æ¨¡å—
åŒ…å«å¼‚æ­¥å›¾åƒç”Ÿæˆå’Œä¸‹è½½å·¥å…·
"""

import asyncio
import time
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional

import aiohttp
import replicate
from loguru import logger


def get_default_generation_params() -> Dict[str, Any]:
    """
    è·å–é»˜è®¤çš„å›¾ç‰‡ç”Ÿæˆå‚æ•°

    Returns:
        åŒ…å«é»˜è®¤å‚æ•°çš„å­—å…¸
    """
    return {
        "model_name": "sdxl-lightning",
        "negative_prompt": "worst quality, low quality, blurry",
        "width": 768,
        "height": 768,
        "num_inference_steps": 4,
        "guidance_scale": 7.5,
    }


async def generate_image(
    prompt: str,
    model_name: str,
    negative_prompt: str,
    width: int,
    height: int,
    num_inference_steps: int,
    guidance_scale: float,
    models_config: Dict[str, Dict[str, str]],
) -> str:
    """
    å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡

    Args:
        prompt: æ–‡æœ¬æç¤ºè¯
        model_name: æ¨¡å‹åç§°
        negative_prompt: è´Ÿå‘æç¤ºè¯
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        num_inference_steps: æ¨ç†æ­¥æ•°
        guidance_scale: å¼•å¯¼æ¯”ä¾‹
        models_config: æ¨¡å‹é…ç½®å­—å…¸

    Returns:
        å›¾ç‰‡ URL

    Raises:
        ValueError: ä¸æ”¯æŒçš„æ¨¡å‹åç§°
        Exception: å›¾ç‰‡ç”Ÿæˆå¤±è´¥
    """
    if model_name not in models_config:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}. å¯ç”¨æ¨¡å‹: {list(models_config.keys())}"
        )

    model_info = models_config[model_name]
    model_version = model_info["version"]
    cost_estimate = model_info["cost_estimate"]

    logger.info(f"ğŸ¨ ä½¿ç”¨æ¨¡å‹: {model_name}")
    logger.info(f"ğŸ’° é¢„ä¼°æˆæœ¬: {cost_estimate}")
    logger.info(f"ğŸ“ æç¤ºè¯: {prompt}")
    logger.info(f"âš™ï¸  å‚æ•°: {width}x{height}, {num_inference_steps} æ­¥")
    logger.info("ğŸ”„ å¼‚æ­¥ç”Ÿæˆä¸­...")

    start_time = time.time()

    try:
        # æ ¹æ®ä¸åŒæ¨¡å‹è°ƒæ•´å‚æ•°
        if model_name == "sdxl-lightning":
            # Lightning æ¨¡å‹ä½¿ç”¨è¾ƒå°‘çš„æ­¥æ•°
            num_inference_steps = min(4, num_inference_steps)

        # ä½¿ç”¨å¼‚æ­¥ç‰ˆæœ¬
        output = await replicate.async_run(
            model_version,
            input={
                "prompt": prompt,
                "negative_prompt": negative_prompt,
                "width": width,
                "height": height,
                "num_outputs": 1,
                "num_inference_steps": num_inference_steps,
                "guidance_scale": guidance_scale,
                "scheduler": "K_EULER",
            },
        )

        # è·å–å›¾ç‰‡ URL
        image_url: str = output[0] if isinstance(output, list) else str(output)

        elapsed_time = time.time() - start_time
        logger.info(f"âœ… å¼‚æ­¥ç”Ÿæˆå®Œæˆ! è€—æ—¶: {elapsed_time:.2f}ç§’")
        logger.info(f"ğŸ”— å›¾ç‰‡ URL: {image_url}")

        return image_url

    except Exception as e:
        logger.error(f"âŒ å¼‚æ­¥ç”Ÿæˆå¤±è´¥: {e}")
        raise


async def download_image(image_url: str, save_path: str) -> str:
    """
    å¼‚æ­¥ä¸‹è½½å›¾ç‰‡

    Args:
        image_url: å›¾ç‰‡ URL
        save_path: ä¿å­˜è·¯å¾„

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„

    Raises:
        Exception: ä¸‹è½½å¤±è´¥
    """
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    save_dir = Path(save_path).parent
    save_dir.mkdir(parents=True, exist_ok=True)

    try:
        logger.info(f"ğŸ“¥ å¼‚æ­¥ä¸‹è½½å›¾ç‰‡åˆ°: {save_path}")

        # å¼‚æ­¥ä¸‹è½½å›¾ç‰‡
        async with aiohttp.ClientSession() as session:
            async with session.get(image_url) as response:
                response.raise_for_status()
                content = await response.read()

        # ä¿å­˜å›¾ç‰‡
        with open(save_path, "wb") as f:
            f.write(content)

        file_size = len(content) / 1024  # KB
        logger.info(f"âœ… å¼‚æ­¥ä¸‹è½½å®Œæˆ! æ–‡ä»¶å¤§å°: {file_size:.1f} KB")

        return save_path

    except Exception as e:
        logger.error(f"âŒ å¼‚æ­¥ä¸‹è½½å¤±è´¥: {e}")
        raise


async def generate_and_download(
    prompt: str,
    model_name: str,
    negative_prompt: str,
    width: int,
    height: int,
    num_inference_steps: int,
    guidance_scale: float,
    output_dir: str,
    models_config: Dict[str, Dict[str, str]],
    filename: Optional[str] = None,
) -> str:
    """
    å¼‚æ­¥ç”Ÿæˆå¹¶ä¸‹è½½å›¾ç‰‡çš„ä¾¿æ·æ–¹æ³•

    Args:
        prompt: æ–‡æœ¬æç¤ºè¯
        model_name: æ¨¡å‹åç§°
        negative_prompt: è´Ÿå‘æç¤ºè¯
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        num_inference_steps: æ¨ç†æ­¥æ•°
        guidance_scale: å¼•å¯¼æ¯”ä¾‹
        output_dir: è¾“å‡ºç›®å½•
        models_config: æ¨¡å‹é…ç½®å­—å…¸
        filename: å¯é€‰çš„æ–‡ä»¶åï¼Œä¸åŒ…å«æ‰©å±•åã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨é»˜è®¤å‘½åè§„åˆ™

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡
    image_url = await generate_image(
        prompt=prompt,
        model_name=model_name,
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        num_inference_steps=num_inference_steps,
        guidance_scale=guidance_scale,
        models_config=models_config,
    )

    # å‡†å¤‡ä¿å­˜è·¯å¾„
    if filename is None:
        # ä½¿ç”¨é»˜è®¤å‘½åè§„åˆ™
        timestamp = str(uuid.uuid4())
        final_filename = f"{model_name}_{timestamp}.png"
    else:
        # ä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„æ–‡ä»¶åï¼Œç¡®ä¿æœ‰ .png æ‰©å±•å
        if not filename.endswith(".png"):
            final_filename = f"{filename}.png"
        else:
            final_filename = filename

    save_path = Path(output_dir) / final_filename

    # å¼‚æ­¥ä¸‹è½½å›¾ç‰‡
    downloaded_path = await download_image(image_url, str(save_path))

    return downloaded_path


async def generate_multiple_images(
    prompts: List[str],
    model_name: str,
    negative_prompt: str,
    width: int,
    height: int,
    num_inference_steps: int,
    guidance_scale: float,
    output_dir: str,
    models_config: Dict[str, Dict[str, str]],
    filenames: Optional[List[str]] = None,
) -> List[str]:
    """
    å¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡

    Args:
        prompts: æç¤ºè¯åˆ—è¡¨
        model_name: æ¨¡å‹åç§°
        negative_prompt: è´Ÿå‘æç¤ºè¯
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        num_inference_steps: æ¨ç†æ­¥æ•°
        guidance_scale: å¼•å¯¼æ¯”ä¾‹
        output_dir: è¾“å‡ºç›®å½•
        models_config: æ¨¡å‹é…ç½®å­—å…¸
        filenames: å¯é€‰çš„æ–‡ä»¶ååˆ—è¡¨ï¼Œä¸åŒ…å«æ‰©å±•åã€‚å¦‚æœä¸º None æˆ–é•¿åº¦ä¸åŒ¹é…ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å‘½åè§„åˆ™

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘ç”Ÿæˆ {len(prompts)} å¼ å›¾ç‰‡...")

    # ç¡®ä¿ filenames é•¿åº¦åŒ¹é…ï¼Œå¦‚æœä¸åŒ¹é…åˆ™ä½¿ç”¨ None
    if filenames is not None and len(filenames) != len(prompts):
        logger.warning(
            f"æ–‡ä»¶ååˆ—è¡¨é•¿åº¦ ({len(filenames)}) ä¸æç¤ºè¯åˆ—è¡¨é•¿åº¦ ({len(prompts)}) ä¸åŒ¹é…ï¼Œå°†ä½¿ç”¨é»˜è®¤å‘½å"
        )
        filenames = None

    # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    for i, prompt in enumerate(prompts):
        # è·å–å¯¹åº”çš„æ–‡ä»¶åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸º None
        current_filename = filenames[i] if filenames is not None else None

        task = generate_and_download(
            prompt=prompt,
            model_name=model_name,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            output_dir=output_dir,
            models_config=models_config,
            filename=current_filename,
        )
        tasks.append(task)

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    start_time = time.time()
    try:
        results = await asyncio.gather(*tasks)
        elapsed_time = time.time() - start_time
        logger.info(f"ğŸ‰ å¹¶å‘ç”Ÿæˆå®Œæˆ! æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
        logger.info(f"ğŸ“Š å¹³å‡æ¯å¼ å›¾ç‰‡: {elapsed_time/len(prompts):.2f}ç§’")
        return results
    except Exception as e:
        logger.error(f"âŒ å¹¶å‘ç”Ÿæˆå¤±è´¥: {e}")
        raise
