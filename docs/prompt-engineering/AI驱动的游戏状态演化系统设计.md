# AI驱动的游戏状态演化系统设计

## 核心设计理念

这是一个**基于AI认知能力的游戏引擎**，而非传统的规则引擎。系统让AI自己管理游戏状态，通过AI之间的语义通信实现战斗逻辑，无需硬编码buff/debuff系统。

## 架构原则

### 1. 叙事与数值天然统一

- **combat_log**：唯一的数值真相源，包含所有数值变化
- **narrative**：叙事演出，感官描写战斗过程
- 两者都由AI生成，天然保持一致性

### 2. 状态效果是语义信息

- **status_effects** 不是代码执行的指令
- 而是**AI之间传递的语义信息**，描述角色当前处境
- 场景AI通过阅读这些描述来理解角色状态并应用到计算中

### 3. AI负责因果推理

- 角色AI阅读 combat_log 理解发生了什么
- 推理出当前状态（如"我冲锋了，现在应该有后遗症"）
- 生成新的状态效果描述自己的处境
- 场景AI理解这些状态并在仲裁时应用

---

## 战斗回合循环

```text
┌─────────────────────────────────────────────────────────────┐
│ 回合 N（卡牌生成阶段）                                         │
├─────────────────────────────────────────────────────────────┤
│ 1. 角色读取上回合的 combat_log + narrative（通过聊天历史）     │
│ 2. 角色从 combat_log 中自行提取 HP 数值 → update_hp          │
│ 3. 角色理解当前处境，生成 status_effects 描述自己的状态        │
│    - 第1回合：初始状态（固有特性/被动能力）                     │
│    - 后续回合：战斗后果（上回合行动的持续影响）                 │
│ 4. 角色基于理解生成 2 张 cards（行动计划）                     │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│ 回合 N（仲裁阶段）                                             │
├─────────────────────────────────────────────────────────────┤
│ 1. 场景AI收到所有角色的 cards + status_effects                │
│ 2. 场景AI阅读并理解这些状态效果（通过 status_effects_prompt） │
│ 3. 场景AI执行战斗计算，应用状态效果到数值                      │
│ 4. 场景AI生成：                                               │
│    - combat_log：数据真相（含所有数值变化）                    │
│    - narrative：叙事演出                                      │
│ 5. 广播 combat_log + narrative 给所有角色                     │
└─────────────────────────────────────────────────────────────┘
                            ↓
                    进入回合 N+1
```

---

## 状态效果的双重来源

### 第1回合：初始状态

- **提示词**："生成你的初始状态效果"
- **含义**：角色的固有特性、被动能力、装备赋予的永久特性
- **示例**：

  ```json
  {
    "name": "战场警觉",
    "description": "长期角斗场训练形成的本能，防御提升2点",
    "duration": 3
  }
  ```

### 后续回合：战斗后果

- **提示词**："从战斗历史中回顾战斗过程，识别并生成你**新增**的状态效果"
- **含义**：上回合行动产生的持续影响、卡牌使用的副作用
- **示例**：

  ```json
  {
    "name": "重甲冲锋后遗症",
    "description": "重甲冲锋后动作变得沉重，防御降低3点",
    "duration": 2
  }
  ```

---

## AI驱动的因果推理链

```text
回合 N-1 结束
    ↓ [场景AI生成]
combat_log: "卡恩:重甲冲锋 → 卡恩代价[防御-3]"
    ↓ [角色AI阅读combat_log]
回合 N 开始
    ↓ [角色AI推理]
"我上回合使用了重甲冲锋，消耗了体力，现在应该有后遗症"
    ↓ [角色AI生成增量状态]
status_effects: [{
  "name": "重甲冲锋后遗症",
  "description": "防御降低3点",
  "duration": 2
}]
    ↓ [系统累积状态]
角色当前完整状态 = 旧状态 + 新状态
    ↓ [提交给场景AI]
场景AI看到完整状态列表
    ↓ [场景AI应用到战斗计算]
"卡恩有战场警觉(+2防御)和重甲冲锋后遗症(-3防御)"
    ↓ [生成新的combat_log]
回合 N 结束 → 循环继续
```

---

## 核心系统职责

### 1. DrawCardsActionSystem（卡牌生成系统）

**职责**：让角色AI基于战斗历史生成参战信息

**第1回合提示词** (`_generate_first_round_prompt`)：

- 不包含 `update_hp` 字段
- 要求生成初始 `status_effects`（固有特性）
- 生成 `cards`（行动计划）

**后续回合提示词** (`_generate_subsequent_round_prompt`)：

- 要求从战斗历史中提取 `update_hp`
- 要求生成**新增**的 `status_effects`（战斗后果）
- 要求"不要重复生成已存在的状态效果"

**增量状态机制**：

- 系统通过 `_append_status_effects` 累积所有状态
- 通过 `_format_status_effects_message` 通知角色完整的状态列表
- AI下次只需返回本回合新增的增量状态

### 2. ArbitrationActionSystem（战斗仲裁系统）

**职责**：让场景AI基于所有角色的参战信息进行战斗结算

**提示词构建** (`_generate_combat_arbitration_prompt3`)：

- 显示行动顺序
- 展示每个角色的：
  - 卡牌名称 + 效果描述
  - 属性（HP/攻击/防御）
  - **完整的 status_effects 列表**（通过 `status_effects_prompt`）
- 要求场景AI：
  - 严格遵循战斗公式计算
  - **注意角色拥有的状态效果**
  - 生成 `combat_log`（数值真相）+ `narrative`（叙事）

**广播机制** (`_generate_combat_arbitration_broadcast`)：

- 将 `combat_log` + `narrative` 广播给所有角色
- 提醒角色："请从上述日志中提取你的最终HP数值"

### 3. 状态效果的传递

```text
角色AI生成 status_effects
    ↓
DrawCardsActionSystem._append_status_effects()
    ↓
累积到 CombatStatsComponent.status_effects
    ↓
CombatStatsComponent.status_effects_prompt 格式化
    ↓
ArbitrationActionSystem 读取并放入仲裁提示词
    ↓
场景AI阅读并应用到战斗计算
```

---

## 关键约束与设计决策

### 1. "不要重复生成已存在的状态效果"

- **原因**：系统会累积所有状态效果
- **机制**：通过消息通知让AI看到当前完整状态列表
- **效果**：AI只需返回增量，避免重复和混乱

### 2. combat_log 是唯一真相源

- **原因**：AI可能"编造"数值，但 combat_log 记录了实际发生的事情
- **机制**：角色必须从 combat_log 中提取 HP，不能自己猜测
- **效果**：确保数值一致性

### 3. 状态效果包含具体数值

- **原因**：让场景AI能准确计算
- **示例**："防御提升2点"而非"防御增强"
- **效果**：AI能理解并应用到战斗公式

### 4. 压缩提示词设计

- **原因**：减少token消耗，提高推理速度
- **机制**：用 `compressed_prompt` 参数存储原始提示词，实际添加到上下文的是精简版
- **效果**：保持上下文简洁，但保留完整推理记录

---

## 设计优势

✅ **无需硬编码buff/debuff系统**：AI理解"冲锋会累、格挡会僵直"  
✅ **叙事与数值天然统一**：都由AI生成，自然一致  
✅ **状态效果可任意复杂**：AI的理解能力就是引擎的能力  
✅ **因果自洽**：行动→后果→新状态，完全由AI推理  
✅ **增量更新**：只返回新增状态，系统负责累积  
✅ **真相源清晰**：combat_log 是数值真相，AI从中提取并演化状态  
✅ **易于扩展**：添加新状态效果只需让AI理解新的概念

---

## 多Agent上下文结构与信息隔离

### Agent类型与职责划分

系统中有两类Agent，它们的上下文内容和职责完全不同：

#### 场景AI（如：场景.训练场）

**上下文内容**：

- **System消息**：场景设定 + **完整战斗机制公式**
- **接收的消息**：战斗仲裁指令（包含所有角色的cards + status_effects）
- **生成的内容**：combat_log + narrative

**职责**：

- 作为战斗仲裁者，精确执行数值计算
- 阅读所有角色的状态效果并应用到战斗公式
- 维护环境动态变化
- 生成数值真相（combat_log）和叙事（narrative）

#### 角色AI（如：角色.战士.卡恩）

**上下文内容**：

- **System消息**：角色设定（**不包含战斗公式**）
- **接收的消息**：
  - 压缩的回合指令
  - 战斗结算广播（combat_log + narrative）
  - 状态效果更新通知
- **生成的内容**：update_hp + cards + status_effects

**职责**：

- 从combat_log中提取HP数值（不能编造）
- 基于战斗历史推理当前处境
- 生成行动计划（cards）
- 识别新增状态效果（战斗后果）

### 信息隔离的设计意图

```text
┌─────────────────────────────────────────────────────────┐
│ 信息隔离原则                                             │
├─────────────────────────────────────────────────────────┤
│ 角色AI：                                                 │
│   ✓ 知道：自己的经历、感受、处境                         │
│   ✗ 不知道：战斗公式、精确数值计算规则                   │
│   → 结果：从叙事角度理解战斗，模拟真实认知               │
│                                                          │
│ 场景AI：                                                 │
│   ✓ 知道：战斗公式、所有角色的完整状态                   │
│   ✗ 不知道：角色的内心想法、未来计划                     │
│   → 结果：客观仲裁，只根据提交的信息进行计算             │
└─────────────────────────────────────────────────────────┘
```

**关键优势**：

- 角色AI不能"作弊"，必须从结果推理
- 场景AI保证数值精确性和一致性
- 模拟真实战斗中的"感知延迟"和"不完全信息"

---

## 状态效果的完整生命周期

### 从生成到应用的完整流程

```text
回合N开始
    ↓
【1. 角色生成阶段】
角色AI推理 → 生成新status_effects → 返回JSON
    ↓
DrawCardsActionSystem._append_status_effects()
    ↓ [累积操作]
CombatStatsComponent.status_effects = 旧状态 + 新状态
    ↓ [格式化]
_format_status_effects_message() 
    ↓ [通知角色]
"# 通知！你的状态效果已更新
- 战场警觉(3轮): ...
- 重甲冲锋后遗症(2轮): ..."
    ↓
【2. 提交仲裁阶段】
CombatStatsComponent.status_effects_prompt 
    ↓ [读取完整列表]
ArbitrationActionSystem._generate_actor_card_details()
    ↓ [构建提示词]
"【角色.战士.卡恩】
卡牌:泥泞滑步斩 → ...
属性:HP:50/50 | 攻击:10 | 防御:5
状态效果(status_effects):
- 战场警觉: ...防御提升2点
- 重甲冲锋后遗症: ...防御降低3点"
    ↓
【3. 场景仲裁阶段】
场景AI阅读提示词 → 理解状态效果
    ↓ [应用到计算]
"卡恩当前防御 = 基础5 + 战场警觉(+2) - 重甲冲锋后遗症(-3) = 4"
    ↓ [生成结果]
combat_log: "最终HP:卡恩.HP=50/50(状态:战场警觉防御+2,重甲冲锋后遗症防御-3)"
    ↓
【4. 广播阶段】
_generate_combat_arbitration_broadcast() → 发送给所有角色
    ↓
回合N+1开始 → 循环继续
```

### 增量更新机制的关键

**为什么要求"不要重复生成已存在的状态效果"？**

```python
# 回合1：角色生成
status_effects = [{"name": "战场警觉", "duration": 3}]
# 系统累积到实体
entity.status_effects = ["战场警觉"]

# 回合2：系统通知角色当前状态
"你的状态效果：
- 战场警觉(3轮)
- 重甲冲锋后遗症(2轮)"  # 包含上回合的

# 角色AI看到了完整列表，只需返回新增的
status_effects = [{"name": "新状态", "duration": 1}]  # 不再重复"战场警觉"

# 系统再次累积
entity.status_effects = ["战场警觉", "重甲冲锋后遗症", "新状态"]
```

**如果不增量更新会发生什么？**

- 角色每次都生成完整列表 → 系统累积 → 状态效果重复
- 场景AI看到重复的状态 → 可能多次应用效果 → 数值错误

---

## 压缩提示词的双层设计

### 为什么需要两个版本的提示词？

**完整提示词（用于LLM推理）**：

```python
message = _generate_subsequent_round_prompt(
    actor_name=entity.name,
    card_creation_count=2,
    action_order=["角色A", "角色B"],
    selected_skills=[技能1, 技能2, ...],  # 完整技能描述
    current_round_number=2,
)
# 内容：完整的指令、技能池、JSON格式、约束规则（约1000+ tokens）
```

**压缩提示词（存入上下文历史）**：

```python
compressed_prompt = _generate_compressd_round_prompt(
    actor_name=entity.name,
    card_creation_count=2,
    action_order=["角色A", "角色B"],
    current_round_number=2,
)
# 内容：精简指令（约100 tokens）
# "# 指令！这是第2回合，回顾战斗历史，评估当前态势，生成你的参战信息"
```

**存储方式**：

```python
self._game.add_human_message(
    entity=entity,
    message_content=compressed_prompt,  # 存入历史的是压缩版
    compressed_prompt=chat_client.prompt,  # 完整版保留用于调试
)
```

**设计目的**：

- 角色的上下文历史每回合都在增长
- 如果每次都存完整提示词，几回合后就超过token限制
- 压缩版保留核心信息，让AI知道"我在第X回合被要求生成参战信息"
- AI通过阅读combat_log和narrative获得详细信息，不需要重复看完整指令

---

## 双向信息流与包含关系

### 场景与角色的包含关系

```text
场景.训练场 (stage_entity)
    ├── 角色.战士.卡恩 (actor_entity)
    └── 角色.怪物.稻草人0号 (actor_entity)
```

- 场景是"容器"，角色在场景中活动
- `stage_entity = entities[0]` 是当前战斗发生的场景
- 场景AI使用自己的上下文进行仲裁推理

### 信息流动方向

```text
【向上流动：角色 → 场景】
角色生成参战信息 
    → HandComponent (cards)
    → CombatStatsComponent (status_effects)
    → PlayCardsAction (出牌动作)
        ↓
ArbitrationActionSystem收集
    → _collect_combat_action_info()
    → 构建仲裁提示词
        ↓
提交给场景AI进行仲裁

【向下流动：场景 → 角色】
场景AI生成战斗结果
    → combat_log + narrative
        ↓
_generate_combat_arbitration_broadcast()
    → CombatArbitrationEvent
        ↓
broadcast_to_stage()
    → 发送给场景内所有角色
        ↓
角色AI读取 → 理解 → 下回合生成新参战信息
```

### 消息类型总结

| 消息类型 | 发送者 | 接收者 | 内容 | 目的 |
| --------- | -------- | -------- | ------ | ------ |
| 回合指令 | 系统 | 角色 | 压缩的生成指令 | 触发角色生成参战信息 |
| 状态通知 | 系统 | 角色 | 完整状态效果列表 | 让角色知道当前状态 |
| 仲裁指令 | 系统 | 场景 | 所有角色的参战信息 | 触发场景进行战斗仲裁 |
| 战斗广播 | 场景 | 所有角色 | combat_log + narrative | 告知战斗结果 |

---

## 实际运行示例

### 角色AI的上下文（角色.战士.卡恩）

```text
System: [角色设定：你是战士卡恩...]

H: # 指令！这是第1回合，回顾战斗历史，评估当前态势，生成你的参战信息
AI: {"cards": [...], "status_effects": [{"name": "战场警觉", ...}]}

H: # 通知！你的状态效果已更新
   - 战场警觉(3轮): ...

H: # 通知！战斗回合结算
   战斗演出: [narrative]
   数据日志: [combat_log]

H: # 指令！这是第2回合，回顾战斗历史，评估当前态势，生成你的参战信息
AI: {"update_hp": 50, "cards": [...], "status_effects": [{"name": "重甲冲锋后遗症", ...}]}

H: # 通知！你的状态效果已更新
   - 战场警觉(3轮): ...
   - 重甲冲锋后遗症(2轮): ...
```

**关键点**：

- 没有战斗公式
- 通过combat_log理解战斗结果
- 累积的状态效果会被通知

### 场景AI的上下文（场景.训练场）

```text
System: [场景设定 + 完整战斗机制公式]

H: [场景启动描写]
AI: [描写环境]

H: # 指令！这是第1回合，战斗回合仲裁
   行动顺序：角色A → 角色B
   【角色A】
   卡牌:重甲冲锋 → ...
   属性:HP:50/50 | 攻击:10 | 防御:5
   状态效果:
   - 战场警觉: ...防御提升2点
   ...
AI: {"combat_log": "...", "narrative": "..."}
```

**关键点**：

- 有完整战斗公式
- 看到所有角色的完整状态
- 负责精确计算和叙事

---

## 重要提示

当你看到这份文档时，请理解：

1. **状态效果不是数据结构**，而是AI之间传递的**语义信息**
2. **不要试图用代码"执行"状态效果**，让AI理解并应用它们
3. **combat_log 是真相**，角色从中提取数值而非自己编造
4. **增量更新是关键**，AI只生成新增状态，系统负责累积
5. **信息隔离是设计**，角色不知道公式，场景不知道未来
6. **压缩提示词节省token**，完整版推理，精简版存储
7. **这是AI认知引擎**，不是传统规则引擎

### 调试时查看上下文

如果需要理解系统运行状态，可以查看生成的上下文文件：

- `logs/[player-id]/[game-id]/context/[entity-name]_buffer.txt`
- 每个Agent都有独立的上下文历史
- 可以看到它们各自收到的消息和生成的响应
- 这是理解"AI看到了什么"的最佳方式

如果你需要修改系统，请保持这些核心原则不变。
