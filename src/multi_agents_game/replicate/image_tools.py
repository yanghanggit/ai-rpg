#!/usr/bin/env python3
"""
Replicate å›¾åƒç”Ÿæˆå·¥å…·æ¨¡å—
åŒ…å«çº¯å‡½æ•°çš„å›¾åƒç”Ÿæˆå’Œä¸‹è½½å·¥å…·
"""

import time
import uuid
from pathlib import Path
from typing import Any, Dict

import replicate
import requests
from loguru import logger


def get_default_generation_params() -> Dict[str, Any]:
    """
    è·å–é»˜è®¤çš„å›¾ç‰‡ç”Ÿæˆå‚æ•°

    Returns:
        åŒ…å«é»˜è®¤å‚æ•°çš„å­—å…¸
    """
    return {
        "model_name": "sdxl-lightning",
        "negative_prompt": "worst quality, low quality, blurry",
        "width": 768,
        "height": 768,
        "num_inference_steps": 4,
        "guidance_scale": 7.5,
    }


def generate_image(
    prompt: str,
    model_name: str,
    negative_prompt: str,
    width: int,
    height: int,
    num_inference_steps: int,
    guidance_scale: float,
    models_config: Dict[str, Dict[str, str]],
) -> str:
    """
    ç”Ÿæˆå›¾ç‰‡

    Args:
        prompt: æ–‡æœ¬æç¤ºè¯
        model_name: æ¨¡å‹åç§°
        negative_prompt: è´Ÿå‘æç¤ºè¯
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        num_inference_steps: æ¨ç†æ­¥æ•°
        guidance_scale: å¼•å¯¼æ¯”ä¾‹
        models_config: æ¨¡å‹é…ç½®å­—å…¸

    Returns:
        å›¾ç‰‡ URL

    Raises:
        ValueError: ä¸æ”¯æŒçš„æ¨¡å‹åç§°
        Exception: å›¾ç‰‡ç”Ÿæˆå¤±è´¥
    """
    if model_name not in models_config:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}. å¯ç”¨æ¨¡å‹: {list(models_config.keys())}"
        )

    model_info = models_config[model_name]
    model_version = model_info["version"]
    cost_estimate = model_info["cost_estimate"]

    logger.info(f"ğŸ¨ ä½¿ç”¨æ¨¡å‹: {model_name}")
    logger.info(f"ğŸ’° é¢„ä¼°æˆæœ¬: {cost_estimate}")
    logger.info(f"ğŸ“ æç¤ºè¯: {prompt[:80]}{'...' if len(prompt) > 80 else ''}")
    logger.info(f"âš™ï¸  å‚æ•°: {width}x{height}, {num_inference_steps} æ­¥")
    logger.info("ğŸ”„ ç”Ÿæˆä¸­...")

    start_time = time.time()

    try:
        # æ ¹æ®ä¸åŒæ¨¡å‹è°ƒæ•´å‚æ•°
        if model_name == "sdxl-lightning":
            # Lightning æ¨¡å‹ä½¿ç”¨è¾ƒå°‘çš„æ­¥æ•°
            num_inference_steps = min(4, num_inference_steps)

        output = replicate.run(
            model_version,
            input={
                "prompt": prompt,
                "negative_prompt": negative_prompt,
                "width": width,
                "height": height,
                "num_outputs": 1,
                "num_inference_steps": num_inference_steps,
                "guidance_scale": guidance_scale,
                "scheduler": "K_EULER",
            },
        )

        # è·å–å›¾ç‰‡ URL
        image_url: str = output[0] if isinstance(output, list) else str(output)

        elapsed_time = time.time() - start_time
        logger.info(f"âœ… ç”Ÿæˆå®Œæˆ! è€—æ—¶: {elapsed_time:.2f}ç§’")
        logger.info(f"ğŸ”— å›¾ç‰‡ URL: {image_url}")

        return image_url

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        raise


def download_image(image_url: str, save_path: str) -> str:
    """
    ä¸‹è½½å›¾ç‰‡

    Args:
        image_url: å›¾ç‰‡ URL
        save_path: ä¿å­˜è·¯å¾„

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„

    Raises:
        Exception: ä¸‹è½½å¤±è´¥
    """
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    save_dir = Path(save_path).parent
    save_dir.mkdir(parents=True, exist_ok=True)

    try:
        logger.info(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡åˆ°: {save_path}")

        # ä¸‹è½½å›¾ç‰‡
        response = requests.get(image_url, timeout=30)
        response.raise_for_status()

        # ä¿å­˜å›¾ç‰‡
        with open(save_path, "wb") as f:
            f.write(response.content)

        file_size = len(response.content) / 1024  # KB
        logger.info(f"âœ… ä¸‹è½½å®Œæˆ! æ–‡ä»¶å¤§å°: {file_size:.1f} KB")

        return save_path

    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        raise


def generate_and_download(
    prompt: str,
    model_name: str,
    negative_prompt: str,
    width: int,
    height: int,
    num_inference_steps: int,
    guidance_scale: float,
    output_dir: str,
    models_config: Dict[str, Dict[str, str]],
) -> str:
    """
    ç”Ÿæˆå¹¶ä¸‹è½½å›¾ç‰‡çš„ä¾¿æ·æ–¹æ³•

    Args:
        prompt: æ–‡æœ¬æç¤ºè¯
        model_name: æ¨¡å‹åç§°
        negative_prompt: è´Ÿå‘æç¤ºè¯
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        num_inference_steps: æ¨ç†æ­¥æ•°
        guidance_scale: å¼•å¯¼æ¯”ä¾‹
        output_dir: è¾“å‡ºç›®å½•
        models_config: æ¨¡å‹é…ç½®å­—å…¸

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # ç”Ÿæˆå›¾ç‰‡
    image_url = generate_image(
        prompt=prompt,
        model_name=model_name,
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        num_inference_steps=num_inference_steps,
        guidance_scale=guidance_scale,
        models_config=models_config,
    )

    # å‡†å¤‡ä¿å­˜è·¯å¾„
    timestamp = str(uuid.uuid4())
    filename = f"{model_name}_{timestamp}.png"
    save_path = Path(output_dir) / filename

    # ä¸‹è½½å›¾ç‰‡
    downloaded_path = download_image(image_url, str(save_path))

    return downloaded_path
