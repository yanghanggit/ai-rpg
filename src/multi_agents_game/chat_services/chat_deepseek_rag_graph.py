from dotenv import load_dotenv
from loguru import logger

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

import os
import traceback
from typing import Annotated, Any, Dict, List, Optional

from langchain.schema import AIMessage, HumanMessage
from langchain_core.messages import BaseMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.graph.state import CompiledStateGraph
from pydantic import SecretStr
from typing_extensions import TypedDict
import chromadb
from chromadb.api.models.Collection import Collection
from chromadb.api import ClientAPI
from ..utils.model_loader import load_multilingual_model


############################################################################################################
class State(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]


############################################################################################################
class RAGState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    user_query: str  # ç”¨æˆ·åŸå§‹æŸ¥è¯¢
    retrieved_docs: List[str]  # æ£€ç´¢åˆ°çš„æ–‡æ¡£
    enhanced_context: str  # å¢å¼ºåçš„ä¸Šä¸‹æ–‡
    similarity_scores: List[float]  # ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰


############################################################################################################
class ChromaRAGDatabase:
    """
    ChromaDBå‘é‡æ•°æ®åº“ç®¡ç†ç±»

    è´Ÿè´£ï¼š
    1. åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯å’Œé›†åˆ
    2. å°†çŸ¥è¯†åº“æ•°æ®å‘é‡åŒ–å¹¶å­˜å‚¨
    3. æä¾›è¯­ä¹‰æœç´¢æ¥å£
    4. ç®¡ç†å‘é‡æ•°æ®åº“çš„ç”Ÿå‘½å‘¨æœŸ
    """

    def __init__(self, collection_name: str = "alfania_knowledge_base"):
        """
        åˆå§‹åŒ–ChromaDBå‘é‡æ•°æ®åº“

        Args:
            collection_name: ChromaDBé›†åˆåç§°
        """
        self.collection_name = collection_name
        self.client: Optional[ClientAPI] = None
        self.collection: Optional[Collection] = None
        self.embedding_model = None
        self.initialized = False

        logger.info(f"ğŸ—ï¸ [CHROMADB] åˆå§‹åŒ–ChromaDBç®¡ç†å™¨ï¼Œé›†åˆåç§°: {collection_name}")

    def initialize(self) -> bool:
        """
        åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯ã€åŠ è½½æ¨¡å‹å¹¶åˆ›å»ºé›†åˆ

        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("ğŸš€ [CHROMADB] å¼€å§‹åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")

            # 1. åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
            self.client = chromadb.Client()
            logger.success("âœ… [CHROMADB] ChromaDBå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")

            # 2. åŠ è½½SentenceTransformeræ¨¡å‹ï¼ˆä½¿ç”¨é¡¹ç›®ç¼“å­˜ï¼‰
            logger.info("ğŸ”„ [CHROMADB] åŠ è½½å¤šè¯­è¨€è¯­ä¹‰æ¨¡å‹...")
            self.embedding_model = load_multilingual_model()

            if self.embedding_model is None:
                logger.error("âŒ [CHROMADB] å¤šè¯­è¨€æ¨¡å‹åŠ è½½å¤±è´¥")
                return False

            logger.success("âœ… [CHROMADB] å¤šè¯­è¨€è¯­ä¹‰æ¨¡å‹åŠ è½½æˆåŠŸ")

            # 3. åˆ é™¤å¯èƒ½å­˜åœ¨çš„æ—§é›†åˆï¼ˆé‡æ–°åˆå§‹åŒ–ï¼‰
            try:
                self.client.delete_collection(self.collection_name)
                logger.info(f"ğŸ—‘ï¸ [CHROMADB] å·²åˆ é™¤æ—§é›†åˆ: {self.collection_name}")
            except Exception:
                # é›†åˆä¸å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                pass

            # 4. åˆ›å»ºæ–°çš„ChromaDBé›†åˆ
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "è‰¾å°”æ³•å°¼äºšä¸–ç•ŒçŸ¥è¯†åº“å‘é‡æ•°æ®åº“"},
            )
            logger.success(f"âœ… [CHROMADB] é›†åˆåˆ›å»ºæˆåŠŸ: {self.collection_name}")

            # 5. åŠ è½½çŸ¥è¯†åº“æ•°æ®
            success = self._load_knowledge_base()
            if not success:
                logger.error("âŒ [CHROMADB] çŸ¥è¯†åº“æ•°æ®åŠ è½½å¤±è´¥")
                return False

            self.initialized = True
            logger.success("ğŸ‰ [CHROMADB] å‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
            return True

        except Exception as e:
            logger.error(f"âŒ [CHROMADB] åˆå§‹åŒ–å¤±è´¥: {e}\n{traceback.format_exc()}")
            return False

    def _load_knowledge_base(self) -> bool:
        """
        å°†æ¨¡æ‹ŸçŸ¥è¯†åº“æ•°æ®åŠ è½½åˆ°ChromaDBä¸­

        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("ğŸ“š [CHROMADB] å¼€å§‹åŠ è½½çŸ¥è¯†åº“æ•°æ®...")

            if not self.collection or not self.embedding_model:
                logger.error("âŒ [CHROMADB] é›†åˆæˆ–æ¨¡å‹æœªåˆå§‹åŒ–")
                return False

            # å‡†å¤‡æ–‡æ¡£æ•°æ®
            documents = []
            metadatas = []
            ids = []

            doc_id = 0
            for category, docs in MOCK_KNOWLEDGE_BASE.items():
                for doc in docs:
                    documents.append(doc)
                    metadatas.append(
                        {"category": category, "source": "è‰¾å°”æ³•å°¼äºšä¸–ç•Œè®¾å®š"}
                    )
                    ids.append(f"doc_{doc_id:03d}")
                    doc_id += 1

            logger.info(f"ğŸ“Š [CHROMADB] å‡†å¤‡å‘é‡åŒ– {len(documents)} ä¸ªæ–‡æ¡£...")

            # ä½¿ç”¨SentenceTransformerè®¡ç®—å‘é‡åµŒå…¥
            logger.info("ğŸ”„ [CHROMADB] è®¡ç®—æ–‡æ¡£å‘é‡åµŒå…¥...")
            embeddings = self.embedding_model.encode(documents)

            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼ˆChromaDBè¦æ±‚ï¼‰
            embeddings_list = embeddings.tolist()

            # æ‰¹é‡æ·»åŠ åˆ°ChromaDB
            logger.info("ğŸ’¾ [CHROMADB] å­˜å‚¨å‘é‡åˆ°æ•°æ®åº“...")
            self.collection.add(
                embeddings=embeddings_list,
                documents=documents,
                metadatas=metadatas,
                ids=ids,
            )

            logger.success(
                f"âœ… [CHROMADB] æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“"
            )

            # éªŒè¯æ•°æ®åŠ è½½
            count = self.collection.count()
            logger.info(f"ğŸ“Š [CHROMADB] æ•°æ®åº“ä¸­ç°æœ‰æ–‡æ¡£æ•°é‡: {count}")

            return True

        except Exception as e:
            logger.error(f"âŒ [CHROMADB] çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}\n{traceback.format_exc()}")
            return False

    def semantic_search(
        self, query: str, top_k: int = 5
    ) -> tuple[List[str], List[float]]:
        """
        æ‰§è¡Œè¯­ä¹‰æœç´¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æœ€ç›¸ä¼¼çš„æ–‡æ¡£æ•°é‡

        Returns:
            tuple: (æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨, ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨)
        """
        try:
            if not self.initialized or not self.collection or not self.embedding_model:
                logger.error("âŒ [CHROMADB] æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")
                return [], []

            logger.info(f"ğŸ” [CHROMADB] æ‰§è¡Œè¯­ä¹‰æœç´¢: '{query}'")

            # è®¡ç®—æŸ¥è¯¢å‘é‡
            query_embedding = self.embedding_model.encode([query])

            # åœ¨ChromaDBä¸­æ‰§è¡Œå‘é‡æœç´¢
            results = self.collection.query(
                query_embeddings=query_embedding.tolist(),
                n_results=top_k,
                include=["documents", "distances", "metadatas"],
            )

            # æå–ç»“æœ
            documents = results["documents"][0] if results["documents"] else []
            distances = results["distances"][0] if results["distances"] else []
            metadatas = results["metadatas"][0] if results["metadatas"] else []

            # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
            # ç›¸ä¼¼åº¦ = 1 - æ ‡å‡†åŒ–è·ç¦»
            if distances:
                max_distance = max(distances) if distances else 1.0
                min_distance = min(distances) if distances else 0.0

                # é¿å…é™¤é›¶é”™è¯¯
                distance_range = max_distance - min_distance
                if distance_range == 0:
                    similarity_scores = [1.0] * len(distances)
                else:
                    similarity_scores = [
                        1.0 - (dist - min_distance) / distance_range
                        for dist in distances
                    ]
            else:
                similarity_scores = []

            logger.info(f"âœ… [CHROMADB] æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(documents)} ä¸ªç›¸å…³æ–‡æ¡£")

            # æ‰“å°æœç´¢ç»“æœè¯¦æƒ…ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            for i, (doc, score, metadata) in enumerate(
                zip(documents, similarity_scores, metadatas)
            ):
                category = metadata.get("category", "æœªçŸ¥") if metadata else "æœªçŸ¥"
                logger.debug(f"  ğŸ“„ [{i+1}] ç›¸ä¼¼åº¦: {score:.3f}, ç±»åˆ«: {category}")
                logger.debug(f"      å†…å®¹: {doc[:100]}...")

            return documents, similarity_scores

        except Exception as e:
            logger.error(f"âŒ [CHROMADB] è¯­ä¹‰æœç´¢å¤±è´¥: {e}\n{traceback.format_exc()}")
            return [], []

    def close(self) -> None:
        """å…³é—­æ•°æ®åº“è¿æ¥ï¼ˆæ¸…ç†èµ„æºï¼‰"""
        try:
            if self.client and self.collection_name:
                # ChromaDBå†…å­˜æ¨¡å¼æ— éœ€ç‰¹æ®Šæ¸…ç†
                logger.info("ğŸ”’ [CHROMADB] æ•°æ®åº“è¿æ¥å·²å…³é—­")
                self.initialized = False
        except Exception as e:
            logger.warning(f"âš ï¸ [CHROMADB] å…³é—­æ•°æ®åº“æ—¶å‡ºç°è­¦å‘Š: {e}")


# å…¨å±€ChromaDBå®ä¾‹
_chroma_db: Optional[ChromaRAGDatabase] = None


def get_chroma_db() -> ChromaRAGDatabase:
    """
    è·å–å…¨å±€ChromaDBå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        ChromaRAGDatabase: å…¨å±€æ•°æ®åº“å®ä¾‹
    """
    global _chroma_db
    if _chroma_db is None:
        _chroma_db = ChromaRAGDatabase()
    return _chroma_db


############################################################################################################
# æ¨¡æ‹Ÿæµ‹è¯•æ•°æ® - åŸºäºè‰¾å°”æ³•å°¼äºšä¸–ç•Œè®¾å®šçš„ä¸“æœ‰çŸ¥è¯†åº“
MOCK_KNOWLEDGE_BASE = {
    "è‰¾å°”æ³•å°¼äºš": [
        "è‰¾å°”æ³•å°¼äºšå¤§é™†åˆ†ä¸ºä¸‰å¤§ç‹å›½ï¼šäººç±»çš„é˜¿æ–¯ç‰¹æ‹‰ç‹å›½ã€ç²¾çµçš„æœˆæ¡‚æ£®æ—è”é‚¦ã€å…½äººçš„é“çˆªéƒ¨æ—è”ç›Ÿã€‚",
        "å¤§é™†ä¸­å¤®çŸ—ç«‹ç€å¤è€çš„å°å°ä¹‹å¡”ï¼Œä¼ è¯´åœ£å‰‘ã€Œæ™¨æ›¦ä¹‹åˆƒã€å°±å°å°åœ¨å¡”é¡¶ï¼Œç”¨æ¥é•‡å‹é­”ç‹çš„åŠ›é‡ã€‚",
        "è‰¾å°”æ³•å°¼äºšçš„é­”æ³•ä½“ç³»åˆ†ä¸ºäº”ä¸ªå­¦æ´¾ï¼šç«ç„°ã€å†°éœœã€é›·ç”µã€æ²»æ„ˆå’Œæš—å½±ï¼Œæ¯ä¸ªç§æ—éƒ½æœ‰å…¶æ“…é•¿çš„é­”æ³•æµæ´¾ã€‚",
    ],
    "åœ£å‰‘": [
        "æ™¨æ›¦ä¹‹åˆƒæ˜¯ä¼ è¯´ä¸­çš„åœ£å‰‘ï¼Œå‰‘èº«ç”±æ˜Ÿè¾°é’¢æ‰“é€ ï¼Œå‰‘æŸ„é•¶åµŒç€å…‰æ˜ç¥çš„çœ¼æ³ªç»“æ™¶ã€‚",
        "åªæœ‰æ‹¥æœ‰çº¯æ´ä¹‹å¿ƒçš„å‹‡è€…æ‰èƒ½æ‹”å‡ºåœ£å‰‘ï¼Œæ®è¯´ä¸Šä¸€ä½æŒå‰‘è€…æ˜¯300å¹´å‰çš„å‹‡è€…è‰è‰ä¸ã€‚",
        "åœ£å‰‘å…·æœ‰ä¸‰ç§ç¥åœ£æŠ€èƒ½ï¼šå‡€åŒ–ä¹‹å…‰ï¼ˆé©±æ•£é»‘æš—é­”æ³•ï¼‰ã€å®¡åˆ¤ä¹‹ç‚ï¼ˆå¯¹é‚ªæ¶ç”Ÿç‰©é€ æˆå·¨å¤§ä¼¤å®³ï¼‰ã€å¸Œæœ›å®ˆæŠ¤ï¼ˆä¿æŠ¤é˜Ÿå‹å…å—è‡´å‘½ä¼¤å®³ï¼‰ã€‚",
    ],
    "é­”ç‹": [
        "é»‘æš—é­”ç‹é˜¿å·´é¡¿æ›¾ç»ç»Ÿæ²»è‰¾å°”æ³•å°¼äºšå¤§é™†ï¼Œå°†å…¶å˜æˆæ­»äº¡ä¸ç»æœ›çš„åœŸåœ°ã€‚",
        "é˜¿å·´é¡¿æ‹¥æœ‰ä¸æ­»ä¹‹èº«ï¼Œå”¯ä¸€èƒ½å½»åº•æ¶ˆç­ä»–çš„æ–¹æ³•æ˜¯ç”¨åœ£å‰‘å‡»ä¸­ä»–çš„é»‘æš—ä¹‹å¿ƒã€‚",
        "æœ€è¿‘é»‘æš—æ°”æ¯å†åº¦å‡ºç°ï¼Œæ‘æ°‘æŠ¥å‘Šåœ¨æœˆåœ†ä¹‹å¤œå¬åˆ°é­”ç‹çš„å’†å“®å£°ä»å°å°ä¹‹å¡”ä¼ æ¥ã€‚",
    ],
    "ç§æ—": [
        "äººç±»ä»¥é˜¿æ–¯ç‰¹æ‹‰ç‹å›½ä¸ºä¸­å¿ƒï¼Œæ“…é•¿é”»é€ å’Œè´¸æ˜“ï¼Œä»–ä»¬çš„éª‘å£«å›¢ä»¥é‡ç”²å’Œé•¿å‰‘é—»åã€‚",
        "ç²¾çµå±…ä½åœ¨æœˆæ¡‚æ£®æ—ï¼Œå¯¿å‘½å¯è¾¾åƒå¹´ï¼Œæ˜¯æœ€ä¼˜ç§€çš„å¼“ç®­æ‰‹å’Œè‡ªç„¶é­”æ³•å¸ˆã€‚",
        "å…½äººéƒ¨æ—ç”Ÿæ´»åœ¨åŒ—æ–¹å±±è„‰ï¼Œèº«ä½“å¼ºå£®ï¼Œå´‡å°šæ­¦åŠ›ï¼Œä»–ä»¬çš„æˆ˜å£«å¯ä»¥å¾’æ‰‹æ’•è£‚é’¢é“ã€‚",
        "è¿˜æœ‰ä¼ è¯´ä¸­çš„é¾™æ—éšå±…åœ¨äº‘ç«¯ï¼Œå¶å°”ä¼šä¸å‹‡æ•¢çš„å†’é™©è€…ç­¾è®¢å¥‘çº¦ã€‚",
    ],
    "é—è¿¹": [
        "å¤±è½çš„è´¤è€…ä¹‹å¡”ï¼šå¤ä»£é­”æ³•å¸ˆçš„ç ”ç©¶æ‰€ï¼Œå†…è—å¼ºå¤§çš„é­”æ³•é“å…·å’Œç¦å¿ŒçŸ¥è¯†ã€‚",
        "æ²‰æ²¡çš„æ°´æ™¶åŸï¼šæ›¾ç»çš„çŸ®äººç‹å›½ï¼Œå› æŒ–æ˜è¿‡æ·±è§¦æ€’äº†åœ°åº•é­”ç‰©è€Œè¢«æ·¹æ²¡ã€‚",
        "æš—å½±å¢“åœ°ï¼šé­”ç‹å†›é˜Ÿçš„åŸ‹éª¨ä¹‹åœ°ï¼Œæ®è¯´å¤œæ™šä¼šæœ‰äº¡çµå£«å…µæ¸¸è¡ã€‚",
        "æ˜Ÿè¾°ç¥æ®¿ï¼šä¾›å¥‰å…‰æ˜ç¥çš„åœ£åœ°ï¼Œç¥æ®¿ä¸­çš„åœ£æ°´å¯ä»¥æ²»æ„ˆä»»ä½•è¯…å’’ã€‚",
    ],
    "å†’é™©è€…": [
        "è‰¾å°”æ³•å°¼äºšçš„å†’é™©è€…å…¬ä¼šæ€»éƒ¨ä½äºé˜¿æ–¯ç‰¹æ‹‰ç‹å›½é¦–éƒ½ï¼Œåˆ†ä¸ºé’é“œã€ç™½é“¶ã€é»„é‡‘ã€é“‚é‡‘å››ä¸ªç­‰çº§ã€‚",
        "æœ€è‘—åçš„å†’é™©è€…å°é˜Ÿæ˜¯ã€Œæš´é£é›ªå›¢ã€ï¼Œç”±äººç±»å‰‘å£«åŠ ä¼¦ã€ç²¾çµæ³•å¸ˆè‰¾è‰å¨…å’Œå…½äººæˆ˜å£«æ ¼ç½—å§†ç»„æˆã€‚",
        "å†’é™©è€…çš„åŸºæœ¬è£…å¤‡åŒ…æ‹¬ï¼šé™„é­”æ­¦å™¨ã€é­”æ³•è¯æ°´ã€æ¢æµ‹é­”ç‰©çš„æ°´æ™¶çƒå’Œç´§æ€¥ä¼ é€å·è½´ã€‚",
    ],
}


############################################################################################################
def retrieval_node(state: RAGState) -> Dict[str, Any]:
    """
    ChromaDBå‘é‡æ£€ç´¢èŠ‚ç‚¹

    åŠŸèƒ½æ”¹é€ ï¼š
    1. å°†åŸæ¥çš„å…³é”®è¯åŒ¹é…æ”¹ä¸ºChromaDBè¯­ä¹‰å‘é‡æœç´¢
    2. ä½¿ç”¨SentenceTransformerè®¡ç®—æŸ¥è¯¢å‘é‡
    3. è¿”å›æœ€ç›¸ä¼¼çš„æ–‡æ¡£å’Œç›¸ä¼¼åº¦åˆ†æ•°
    4. ä¿æŒåŸæœ‰çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
    """
    try:
        logger.info("ğŸ” [RETRIEVAL] å¼€å§‹å‘é‡è¯­ä¹‰æ£€ç´¢...")

        user_query = state.get("user_query", "")
        if not user_query:
            # ä»æœ€æ–°æ¶ˆæ¯ä¸­æå–æŸ¥è¯¢
            if state["messages"]:
                last_message = state["messages"][-1]
                if isinstance(last_message, HumanMessage):
                    # ç¡®ä¿contentæ˜¯å­—ç¬¦ä¸²ç±»å‹
                    content = last_message.content
                    user_query = content if isinstance(content, str) else str(content)

        logger.info(f"ğŸ” [RETRIEVAL] ç”¨æˆ·æŸ¥è¯¢: {user_query}")

        # è·å–ChromaDBå®ä¾‹å¹¶æ‰§è¡Œè¯­ä¹‰æœç´¢
        chroma_db = get_chroma_db()

        if not chroma_db.initialized:
            logger.warning("âš ï¸ [RETRIEVAL] ChromaDBæœªåˆå§‹åŒ–ï¼Œå›é€€åˆ°å…³é”®è¯åŒ¹é…")
            # å›é€€åˆ°åŸæ¥çš„å…³é”®è¯åŒ¹é…é€»è¾‘
            return _fallback_keyword_search(user_query)

        # æ‰§è¡Œå‘é‡è¯­ä¹‰æœç´¢
        retrieved_docs, similarity_scores = chroma_db.semantic_search(
            query=user_query, top_k=5  # è¿”å›æœ€ç›¸ä¼¼çš„5ä¸ªæ–‡æ¡£
        )

        # æ£€æŸ¥æœç´¢ç»“æœ
        if not retrieved_docs:
            logger.warning("ğŸ” [RETRIEVAL] è¯­ä¹‰æœç´¢æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨é»˜è®¤å›å¤")
            retrieved_docs = [
                "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„å…·ä½“ä¿¡æ¯ï¼Œæˆ‘ä¼šå°½åŠ›æ ¹æ®å¸¸è¯†å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
            ]
            similarity_scores = [0.0]

        # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœï¼ˆç›¸ä¼¼åº¦é˜ˆå€¼ï¼š0.3ï¼‰
        MIN_SIMILARITY = 0.3
        filtered_docs = []
        filtered_scores = []

        for doc, score in zip(retrieved_docs, similarity_scores):
            if score >= MIN_SIMILARITY:
                filtered_docs.append(doc)
                filtered_scores.append(score)

        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ–‡æ¡£ï¼Œä¿ç•™æœ€é«˜åˆ†çš„æ–‡æ¡£
        if not filtered_docs and retrieved_docs:
            filtered_docs = [retrieved_docs[0]]
            filtered_scores = [similarity_scores[0]]
            logger.info(
                f"ğŸ” [RETRIEVAL] æ‰€æœ‰ç»“æœä½äºé˜ˆå€¼ï¼Œä¿ç•™æœ€é«˜åˆ†æ–‡æ¡£ (ç›¸ä¼¼åº¦: {similarity_scores[0]:.3f})"
            )

        logger.success(
            f"ğŸ” [RETRIEVAL] è¯­ä¹‰æ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(filtered_docs)} ä¸ªç›¸å…³æ–‡æ¡£"
        )

        # è®°å½•ç›¸ä¼¼åº¦ä¿¡æ¯
        for i, (doc, score) in enumerate(zip(filtered_docs, filtered_scores)):
            logger.info(f"  ğŸ“„ [{i+1}] ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {doc[:50]}...")

        return {
            "user_query": user_query,
            "retrieved_docs": filtered_docs,
            "similarity_scores": filtered_scores,
        }

    except Exception as e:
        logger.error(f"ğŸ” [RETRIEVAL] æ£€ç´¢èŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}")
        return {
            "user_query": state.get("user_query", ""),
            "retrieved_docs": ["æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œå°†ä½¿ç”¨é»˜è®¤å›å¤ã€‚"],
            "similarity_scores": [0.0],
        }


def _fallback_keyword_search(user_query: str) -> Dict[str, Any]:
    """
    å›é€€å‡½æ•°ï¼šå½“ChromaDBä¸å¯ç”¨æ—¶ä½¿ç”¨åŸæ¥çš„å…³é”®è¯åŒ¹é…

    Args:
        user_query: ç”¨æˆ·æŸ¥è¯¢

    Returns:
        Dict: åŒ…å«æ£€ç´¢ç»“æœçš„å­—å…¸
    """
    logger.info("ğŸ”„ [RETRIEVAL] ä½¿ç”¨å…³é”®è¯åŒ¹é…å›é€€é€»è¾‘...")

    retrieved_docs = []
    query_lower = user_query.lower()

    for keyword, docs in MOCK_KNOWLEDGE_BASE.items():
        if keyword in query_lower:
            retrieved_docs.extend(docs)
            logger.info(
                f"ğŸ” [RETRIEVAL] åŒ¹é…å…³é”®è¯ '{keyword}', æ‰¾åˆ° {len(docs)} ä¸ªæ–‡æ¡£"
            )

    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å…³é”®è¯ï¼Œè¿”å›é€šç”¨ä¿¡æ¯
    if not retrieved_docs:
        retrieved_docs = [
            "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„å…·ä½“ä¿¡æ¯ï¼Œæˆ‘ä¼šå°½åŠ›æ ¹æ®å¸¸è¯†å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
        ]
        logger.warning("ğŸ” [RETRIEVAL] æœªæ‰¾åˆ°åŒ¹é…æ–‡æ¡£ï¼Œä½¿ç”¨é»˜è®¤å›å¤")

    return {
        "user_query": user_query,
        "retrieved_docs": retrieved_docs,
        "similarity_scores": [1.0] * len(retrieved_docs),  # å…³é”®è¯åŒ¹é…ç»™æ»¡åˆ†
    }


############################################################################################################
def context_enhancement_node(state: RAGState) -> Dict[str, Any]:
    """
    ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹ï¼ˆæ”¯æŒç›¸ä¼¼åº¦ä¿¡æ¯ï¼‰

    åŠŸèƒ½å¢å¼ºï¼š
    1. ä¿æŒåŸæœ‰çš„ä¸Šä¸‹æ–‡æ„å»ºé€»è¾‘
    2. æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°ä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡ä¸­
    3. æä¾›æ›´ä¸°å¯Œçš„æ£€ç´¢è´¨é‡ä¿¡æ¯
    4. ä¸ºLLMæä¾›æ›´å¥½çš„å‚è€ƒä¾æ®
    """
    try:
        logger.info("ğŸ“ [ENHANCEMENT] å¼€å§‹å¢å¼ºä¸Šä¸‹æ–‡...")

        user_query = state.get("user_query", "")
        retrieved_docs = state.get("retrieved_docs", [])
        similarity_scores = state.get("similarity_scores", [])

        logger.info(f"ğŸ“ [ENHANCEMENT] å¤„ç†æŸ¥è¯¢: {user_query}")
        logger.info(f"ğŸ“ [ENHANCEMENT] æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡: {len(retrieved_docs)}")

        if similarity_scores:
            avg_similarity = sum(similarity_scores) / len(similarity_scores)
            max_similarity = max(similarity_scores)
            logger.info(
                f"ğŸ“ [ENHANCEMENT] å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}, æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.3f}"
            )

        # æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡prompt
        context_parts = [
            "è¯·åŸºäºä»¥ä¸‹ç›¸å…³ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜:",
            "",
            "ç›¸å…³ä¿¡æ¯ (æŒ‰ç›¸ä¼¼åº¦æ’åº):",
        ]

        # å°†æ–‡æ¡£å’Œç›¸ä¼¼åº¦åˆ†æ•°é…å¯¹ï¼Œå¹¶æŒ‰ç›¸ä¼¼åº¦æ’åº
        if similarity_scores and len(similarity_scores) == len(retrieved_docs):
            doc_score_pairs = list(zip(retrieved_docs, similarity_scores))
            # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
            doc_score_pairs.sort(key=lambda x: x[1], reverse=True)

            for i, (doc, score) in enumerate(doc_score_pairs, 1):
                # æ·»åŠ ç›¸ä¼¼åº¦ä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼ˆå¸®åŠ©LLMç†è§£æ£€ç´¢è´¨é‡ï¼‰
                context_parts.append(f"{i}. [ç›¸ä¼¼åº¦: {score:.3f}] {doc}")
        else:
            # å›é€€åˆ°åŸæ¥çš„æ ¼å¼ï¼ˆæ²¡æœ‰ç›¸ä¼¼åº¦ä¿¡æ¯ï¼‰
            for i, doc in enumerate(retrieved_docs, 1):
                context_parts.append(f"{i}. {doc}")

        context_parts.extend(
            [
                "",
                f"ç”¨æˆ·é—®é¢˜: {user_query}",
                "",
                "è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”:",
                "- ä¼˜å…ˆä½¿ç”¨ç›¸ä¼¼åº¦è¾ƒé«˜çš„ä¿¡æ¯",
                "- å¦‚æœç›¸ä¼¼åº¦è¾ƒä½ï¼Œè¯·é€‚å½“æé†’ç”¨æˆ·",
                "- ä¿æŒå›ç­”çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§",
            ]
        )

        enhanced_context = "\n".join(context_parts)

        logger.info("ğŸ“ [ENHANCEMENT] ä¸Šä¸‹æ–‡å¢å¼ºå®Œæˆ")
        logger.debug(f"ğŸ“ [ENHANCEMENT] å¢å¼ºåçš„ä¸Šä¸‹æ–‡:\n{enhanced_context}")

        return {"enhanced_context": enhanced_context}

    except Exception as e:
        logger.error(
            f"ğŸ“ [ENHANCEMENT] ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}"
        )
        fallback_context = f"è¯·å›ç­”ä»¥ä¸‹é—®é¢˜: {state.get('user_query', '')}"
        return {"enhanced_context": fallback_context}


############################################################################################################
def rag_llm_node(state: RAGState) -> Dict[str, List[BaseMessage]]:
    """RAGç‰ˆæœ¬çš„LLMèŠ‚ç‚¹"""
    try:
        logger.info("ğŸ¤– [LLM] å¼€å§‹ç”Ÿæˆå›ç­”...")

        # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
        deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
        if not deepseek_api_key:
            raise ValueError("DEEPSEEK_API_KEY environment variable is not set")

        llm = ChatDeepSeek(
            api_key=SecretStr(deepseek_api_key),
            model="deepseek-chat",
            temperature=0.7,
        )

        # ä½¿ç”¨å¢å¼ºçš„ä¸Šä¸‹æ–‡æ›¿æ¢åŸå§‹æ¶ˆæ¯
        enhanced_context = state.get("enhanced_context", "")
        if enhanced_context:
            enhanced_message = HumanMessage(content=enhanced_context)
            logger.info("ğŸ¤– [LLM] ä½¿ç”¨å¢å¼ºä¸Šä¸‹æ–‡è°ƒç”¨DeepSeek")
        else:
            # å›é€€åˆ°åŸå§‹æ¶ˆæ¯ï¼Œç¡®ä¿è½¬æ¢ä¸ºHumanMessage
            if state["messages"]:
                last_msg = state["messages"][-1]
                if isinstance(last_msg, HumanMessage):
                    enhanced_message = last_msg
                else:
                    # å°†å…¶ä»–ç±»å‹çš„æ¶ˆæ¯è½¬æ¢ä¸ºHumanMessage
                    content = (
                        last_msg.content
                        if isinstance(last_msg.content, str)
                        else str(last_msg.content)
                    )
                    enhanced_message = HumanMessage(content=content)
            else:
                enhanced_message = HumanMessage(content="Hello")
            logger.warning("ğŸ¤– [LLM] å¢å¼ºä¸Šä¸‹æ–‡ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ¶ˆæ¯")

        # è°ƒç”¨LLM
        response = llm.invoke([enhanced_message])
        logger.success("ğŸ¤– [LLM] DeepSeekå›ç­”ç”Ÿæˆå®Œæˆ")

        return {"messages": [response]}

    except Exception as e:
        logger.error(f"ğŸ¤– [LLM] LLMèŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}")
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return {"messages": [error_response]}


############################################################################################################
def initialize_rag_system() -> bool:
    """
    åˆå§‹åŒ–RAGç³»ç»Ÿ

    åŠŸèƒ½ï¼š
    1. åˆå§‹åŒ–ChromaDBå‘é‡æ•°æ®åº“
    2. åŠ è½½SentenceTransformeræ¨¡å‹
    3. å°†çŸ¥è¯†åº“æ•°æ®å‘é‡åŒ–å¹¶å­˜å‚¨
    4. éªŒè¯ç³»ç»Ÿå°±ç»ªçŠ¶æ€

    Returns:
        bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    """
    logger.info("ğŸš€ [INIT] å¼€å§‹åˆå§‹åŒ–RAGç³»ç»Ÿ...")

    try:
        # è·å–ChromaDBå®ä¾‹å¹¶åˆå§‹åŒ–
        chroma_db = get_chroma_db()
        success = chroma_db.initialize()

        if success:
            logger.success("âœ… [INIT] RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            logger.info("ğŸ’¡ [INIT] ç³»ç»Ÿç°åœ¨æ”¯æŒ:")
            logger.info("   ğŸ” è¯­ä¹‰å‘é‡æœç´¢")
            logger.info("   ğŸ“Š ç›¸ä¼¼åº¦è¯„åˆ†")
            logger.info("   ğŸ¯ æ™ºèƒ½æ–‡æ¡£æ’åº")
            logger.info("   ğŸ’¾ ChromaDBå‘é‡å­˜å‚¨")
            return True
        else:
            logger.error("âŒ [INIT] RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            logger.warning("âš ï¸ [INIT] ç³»ç»Ÿå°†å›é€€åˆ°å…³é”®è¯åŒ¹é…æ¨¡å¼")
            return False

    except Exception as e:
        logger.error(f"âŒ [INIT] åˆå§‹åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}")
        logger.warning("âš ï¸ [INIT] ç³»ç»Ÿå°†å›é€€åˆ°å…³é”®è¯åŒ¹é…æ¨¡å¼")
        return False


############################################################################################################
def create_rag_compiled_graph() -> (
    CompiledStateGraph[RAGState, Any, RAGState, RAGState]
):
    """åˆ›å»ºRAGæµ‹è¯•ç‰ˆæœ¬çš„çŠ¶æ€å›¾"""
    logger.info("ğŸ—ï¸ æ„å»ºRAGçŠ¶æ€å›¾...")

    try:
        # åˆ›å»ºçŠ¶æ€å›¾
        graph_builder = StateGraph(RAGState)

        # æ·»åŠ ä¸‰ä¸ªèŠ‚ç‚¹
        graph_builder.add_node("retrieval", retrieval_node)
        graph_builder.add_node("enhancement", context_enhancement_node)
        graph_builder.add_node("llm", rag_llm_node)

        # è®¾ç½®èŠ‚ç‚¹æµç¨‹: retrieval â†’ enhancement â†’ llm
        graph_builder.add_edge("retrieval", "enhancement")
        graph_builder.add_edge("enhancement", "llm")

        # è®¾ç½®å…¥å£å’Œå‡ºå£ç‚¹
        graph_builder.set_entry_point("retrieval")
        graph_builder.set_finish_point("llm")

        compiled_graph = graph_builder.compile()
        logger.success("ğŸ—ï¸ RAGçŠ¶æ€å›¾æ„å»ºå®Œæˆ")

        # æ˜ç¡®ç±»å‹è½¬æ¢ä»¥æ»¡è¶³mypyè¦æ±‚
        return compiled_graph  # type: ignore[return-value]

    except Exception as e:
        logger.error(f"ğŸ—ï¸ æ„å»ºRAGçŠ¶æ€å›¾å¤±è´¥: {e}\n{traceback.format_exc()}")
        raise


############################################################################################################
def stream_rag_graph_updates(
    rag_compiled_graph: CompiledStateGraph[RAGState, Any, RAGState, RAGState],
    chat_history_state: State,
    user_input_state: State,
) -> List[BaseMessage]:
    """æ‰§è¡ŒRAGçŠ¶æ€å›¾å¹¶è¿”å›ç»“æœ"""

    ret: List[BaseMessage] = []

    try:
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡ŒRAGæµç¨‹...")

        # å‡†å¤‡RAGçŠ¶æ€
        user_message = (
            user_input_state["messages"][-1] if user_input_state["messages"] else None
        )
        user_query = ""
        if user_message:
            content = user_message.content
            user_query = content if isinstance(content, str) else str(content)

        rag_state: RAGState = {
            "messages": chat_history_state["messages"] + user_input_state["messages"],
            "user_query": user_query,
            "retrieved_docs": [],
            "enhanced_context": "",
            "similarity_scores": [],  # æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°å­—æ®µ
        }

        logger.info(f"ğŸš€ RAGè¾“å…¥çŠ¶æ€å‡†å¤‡å®Œæˆï¼Œç”¨æˆ·æŸ¥è¯¢: {user_query}")

        # æ‰§è¡ŒRAGæµç¨‹
        for event in rag_compiled_graph.stream(rag_state):
            logger.debug(f"ğŸš€ RAGæµç¨‹äº‹ä»¶: {list(event.keys())}")
            for node_name, node_output in event.items():
                if "messages" in node_output:
                    ret.extend(node_output["messages"])
                    logger.info(
                        f"ğŸš€ èŠ‚ç‚¹ [{node_name}] è¾“å‡ºæ¶ˆæ¯æ•°é‡: {len(node_output['messages'])}"
                    )

        logger.success("ğŸš€ RAGæµç¨‹æ‰§è¡Œå®Œæˆ")

    except Exception as e:
        logger.error(f"ğŸš€ RAGæµç¨‹æ‰§è¡Œé”™è¯¯: {e}\n{traceback.format_exc()}")
        error_response = AIMessage(content="RAGæµç¨‹æ‰§è¡Œæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        ret = [error_response]

    return ret


############################################################################################################
def main() -> None:
    pass
    # """
    # ç®€åŒ–çš„mainå‡½æ•°ï¼Œä¸»è¦ç”¨äºåº“å¯¼å…¥æµ‹è¯•

    # æ³¨æ„ï¼šå®é™…çš„å¯åŠ¨è„šæœ¬å·²ç§»è‡³ scripts/run_chromadb_rag_chat.py
    # å»ºè®®ä½¿ç”¨: python scripts/run_chromadb_rag_chat.py
    # """
    # print("ğŸ¯ ChromaDB RAG åº“å·²å°±ç»ª")
    # print("ğŸ’¡ è¦å¯åŠ¨äº¤äº’å¼èŠå¤©ç³»ç»Ÿï¼Œè¯·è¿è¡Œ:")
    # print("   python scripts/run_chromadb_rag_chat.py")
    # print("")
    # print("ğŸ”§ æˆ–è€…åœ¨ä»£ç ä¸­å¯¼å…¥ä½¿ç”¨:")
    # print("   from src.multi_agents_game.chat_services.chat_deepseek_rag_graph import (")
    # print("       initialize_rag_system, create_rag_compiled_graph")
    # print("   )")


############################################################################################################
if __name__ == "__main__":
    # æç¤ºç”¨æˆ·ä½¿ç”¨ä¸“ç”¨å¯åŠ¨è„šæœ¬
    main()
