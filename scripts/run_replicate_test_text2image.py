#!/usr/bin/env python3
"""
Replicate æ–‡ç”Ÿå›¾å·¥å…·
ä¸€ä¸ªç®€å•æ˜“ç”¨çš„æ–‡ç”Ÿå›¾è„šæœ¬ï¼ŒåŒ…å«å®Œæ•´åŠŸèƒ½å’Œä½¿ç”¨ç¤ºä¾‹


# åŸºç¡€ä½¿ç”¨
python scripts/run_replicate_text2image.py "prompt text"

# æ¼”ç¤ºåŠŸèƒ½
python scripts/run_replicate_text2image.py --demo           # è¿è¡Œæ¼”ç¤ºï¼ˆå¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼‰

# å®ç”¨åŠŸèƒ½
python scripts/run_replicate_text2image.py --test           # æµ‹è¯•è¿æ¥
"""

import argparse
import asyncio
import sys
from typing import Any, Dict, List

from ai_rpg.replicate import (
    test_replicate_api_connection,
    replicate_config,
    generate_and_download,
    generate_multiple_images,
    DEFAULT_OUTPUT_DIR,
)

# å…¨å±€å˜é‡
# API_TOKEN: str = os.getenv("REPLICATE_API_TOKEN") or ""


def _get_default_generation_params() -> Dict[str, Any]:
    """
    è·å–é»˜è®¤çš„å›¾ç‰‡ç”Ÿæˆå‚æ•°

    Returns:
        åŒ…å«é»˜è®¤å‚æ•°çš„å­—å…¸
    """
    return {
        "model_name": replicate_config.default_image_model,
        "negative_prompt": "worst quality, low quality, blurry",
        "width": 768,
        "height": 768,
        "num_inference_steps": 4,
        "guidance_scale": 7.5,
    }


async def run_concurrent_demo(prompts: List[str]) -> None:
    """è¿è¡Œå¹¶å‘ç”Ÿæˆæ¼”ç¤º"""
    print("=" * 60)
    print("ğŸš€ Replicate å¹¶å‘æ–‡ç”Ÿå›¾æ¼”ç¤º")
    print("=" * 60)

    # 1. æµ‹è¯•è¿æ¥
    if not test_replicate_api_connection():
        print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
        return

    print(f"\nğŸ¨ å¹¶å‘ç”Ÿæˆ {len(prompts)} å¼ å›¾ç‰‡...")
    print("ğŸ“ æç¤ºè¯åˆ—è¡¨:")
    for i, prompt in enumerate(prompts, 1):
        print(f"  {i}. {prompt}")

    try:
        # è·å–é»˜è®¤å‚æ•°
        default_params = _get_default_generation_params()

        # å¹¶å‘ç”Ÿæˆ
        results = await generate_multiple_images(
            prompts=prompts,
            model_name="ideogram-v3-turbo",  # ä½¿ç”¨ç›¸å¯¹ç¨³å®šçš„æ¨¡å‹
            negative_prompt=default_params["negative_prompt"],
            width=512,  # ä½¿ç”¨è¾ƒå°å°ºå¯¸åŠ å¿«æµ‹è¯•
            height=512,
            num_inference_steps=default_params["num_inference_steps"],
            guidance_scale=default_params["guidance_scale"],
            output_dir=str(DEFAULT_OUTPUT_DIR),
            models_config=replicate_config.get_available_models(),
        )

        print(f"\nğŸ‰ å¹¶å‘ç”Ÿæˆå®Œæˆ! ç”Ÿæˆäº† {len(results)} å¼ å›¾ç‰‡:")
        for i, path in enumerate(results, 1):
            print(f"  {i}. {path}")
        print("ğŸ’¡ è¿™å±•ç¤ºäº†å¼‚æ­¥å¹¶å‘çš„å¼ºå¤§èƒ½åŠ›ï¼")

    except Exception as e:
        print(f"âŒ å¹¶å‘æ¼”ç¤ºå¤±è´¥: {e}")


async def main() -> None:
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""

    # æ£€æŸ¥æ¨¡å‹é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
    if not replicate_config.get_available_models():
        print("âŒ é”™è¯¯: å›¾åƒæ¨¡å‹é…ç½®æœªæ­£ç¡®åŠ è½½")
        sys.exit(1)

    parser = argparse.ArgumentParser(description="Replicate æ–‡ç”Ÿå›¾å·¥å…·")

    # è·å–é»˜è®¤å‚æ•°
    default_params = _get_default_generation_params()

    parser.add_argument("prompt", nargs="?", help="æ–‡æœ¬æç¤ºè¯")
    parser.add_argument(
        "--negative",
        "-n",
        default=default_params["negative_prompt"],
        help="è´Ÿå‘æç¤ºè¯",
    )
    parser.add_argument(
        "--width",
        "-w",
        type=int,
        default=default_params["width"],
        help=f"å›¾ç‰‡å®½åº¦ (é»˜è®¤: {default_params['width']})",
    )
    parser.add_argument(
        "--height",
        type=int,
        default=default_params["height"],
        help=f"å›¾ç‰‡é«˜åº¦ (é»˜è®¤: {default_params['height']})",
    )
    parser.add_argument(
        "--size",
        choices=["small", "medium", "large", "wide", "tall"],
        help="é¢„è®¾å°ºå¯¸: small(512x512), medium(768x768), large(1024x1024), wide(1024x768), tall(768x1024)",
    )
    parser.add_argument(
        "--steps",
        "-s",
        type=int,
        default=default_params["num_inference_steps"],
        help="æ¨ç†æ­¥æ•°",
    )
    parser.add_argument(
        "--guidance",
        "-g",
        type=float,
        default=default_params["guidance_scale"],
        help="å¼•å¯¼æ¯”ä¾‹",
    )
    parser.add_argument("--output", "-o", default=DEFAULT_OUTPUT_DIR, help="è¾“å‡ºç›®å½•")
    parser.add_argument(
        "--demo", action="store_true", help="è¿è¡Œæ¼”ç¤ºï¼ˆå¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼‰"
    )
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•è¿æ¥")

    args = parser.parse_args()

    try:
        print("âœ… Replicate å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

        # å¤„ç†é¢„è®¾å°ºå¯¸
        if args.size:
            size_presets = {
                "small": (512, 512),
                "medium": (768, 768),
                "large": (1024, 1024),
                "wide": (1024, 768),
                "tall": (768, 1024),
            }
            args.width, args.height = size_presets[args.size]
            print(f"ğŸ“ ä½¿ç”¨é¢„è®¾å°ºå¯¸ '{args.size}': {args.width}x{args.height}")

        # å¦‚æœæ˜¯è¿è¡Œæ¼”ç¤º

        # 2. å¤šä¸ªæç¤ºè¯
        # prompts = [
        #     "peaceful mountain landscape",
        #     "ocean waves on sandy beach",
        #     "forest path in autumn",
        # ]

        if args.demo:
            await run_concurrent_demo(
                [
                    "peaceful mountain landscape",
                    "ocean waves on sandy beach",
                    "forest path in autumn",
                ]
            )
            return

        # å¦‚æœæ˜¯æµ‹è¯•è¿æ¥
        if args.test:
            test_replicate_api_connection()
            return

        # å¦‚æœæ²¡æœ‰æä¾›æç¤ºè¯ï¼Œæ˜¾ç¤ºå¸®åŠ©
        if not args.prompt:
            print("ğŸ¨ Replicate æ–‡ç”Ÿå›¾å·¥å…·")
            print("\nå¿«é€Ÿå¼€å§‹:")
            print(
                "  python run_replicate_text2image.py --demo            # è¿è¡Œæ¼”ç¤ºï¼ˆå¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼‰"
            )
            print("  python run_replicate_text2image.py --test            # æµ‹è¯•è¿æ¥")
            print('  python run_replicate_text2image.py "ç”Ÿæˆä¸€åªçŒ«"       # ç”Ÿæˆå›¾ç‰‡')
            print("\nå°ºå¯¸é€‰é¡¹:")
            print("  --size small    # 512x512  (æœ€å¿«)")
            print("  --size medium   # 768x768  (æ¨è)")
            print("  --size large    # 1024x1024 (é«˜è´¨é‡)")
            print("  --size wide     # 1024x768 (æ¨ªå‘)")
            print("  --size tall     # 768x1024 (çºµå‘)")
            print("\nè¯¦ç»†å¸®åŠ©:")
            print("  python run_replicate_text2image.py -h")
            return

        # ç”Ÿæˆå¹¶ä¸‹è½½å›¾ç‰‡
        saved_path = await generate_and_download(
            prompt=args.prompt,
            model_name=default_params["model_name"],
            negative_prompt=args.negative,
            width=args.width,
            height=args.height,
            num_inference_steps=args.steps,
            guidance_scale=args.guidance,
            output_dir=args.output,
            models_config=replicate_config.get_available_models(),
        )

        print(f"\nğŸ‰ å®Œæˆ! å›¾ç‰‡å·²ä¿å­˜åˆ°: {saved_path}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
