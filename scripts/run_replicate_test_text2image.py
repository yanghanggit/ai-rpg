#!/usr/bin/env python3
"""
Replicate æ–‡ç”Ÿå›¾å·¥å…·
ä¸€ä¸ªç®€å•æ˜“ç”¨çš„æ–‡ç”Ÿå›¾è„šæœ¬ï¼ŒåŒ…å«å®Œæ•´åŠŸèƒ½å’Œä½¿ç”¨ç¤ºä¾‹


# åŸºç¡€ä½¿ç”¨
python scripts/run_replicate_text2image.py "prompt text"

# æ¼”ç¤ºåŠŸèƒ½
python scripts/run_replicate_text2image.py --demo           # è¿è¡Œæ¼”ç¤ºï¼ˆå¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼‰

# å®ç”¨åŠŸèƒ½
python scripts/run_replicate_text2image.py --test           # æµ‹è¯•è¿æ¥
"""

import argparse
import asyncio
import sys
import uuid
from pathlib import Path
from typing import List

from ai_rpg.replicate import (
    test_replicate_api_connection,
    replicate_config,
    generate_and_download,
    execute_tasks,
    ImageGenerationTask,
    DEFAULT_OUTPUT_DIR,
)


async def run_concurrent_demo(prompts: List[str]) -> None:
    """è¿è¡Œå¹¶å‘ç”Ÿæˆæ¼”ç¤º"""
    print("=" * 60)
    print("ğŸš€ Replicate å¹¶å‘æ–‡ç”Ÿå›¾æ¼”ç¤º")
    print("=" * 60)

    # 1. æµ‹è¯•è¿æ¥
    if not test_replicate_api_connection():
        print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
        return

    print(f"\nğŸ¨ å¹¶å‘ç”Ÿæˆ {len(prompts)} å¼ å›¾ç‰‡...")
    print("ğŸ“ æç¤ºè¯åˆ—è¡¨:")
    for i, prompt in enumerate(prompts, 1):
        print(f"  {i}. {prompt}")

    try:
        # è·å–æ¨¡å‹ç‰ˆæœ¬
        model_version = replicate_config.get_model_version()

        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for i, prompt in enumerate(prompts, 1):
            # æ„å»ºæ¨¡å‹è¾“å…¥å‚æ•°
            model_input = {
                "prompt": prompt,
                "negative_prompt": "worst quality, low quality, blurry",
                "width": 512,
                "height": 512,
                "num_outputs": 1,
                "num_inference_steps": 4,
                "guidance_scale": 7.5,
                "scheduler": "K_EULER",
            }
            # å‡†å¤‡è¾“å‡ºè·¯å¾„
            output_path = str(DEFAULT_OUTPUT_DIR / f"demo_{i:02d}_{uuid.uuid4()}.png")

            # åˆ›å»ºä»»åŠ¡
            tasks.append(
                ImageGenerationTask(
                    model_version=model_version,
                    model_input=model_input,
                    output_path=output_path,
                )
            )

        # å¹¶å‘ç”Ÿæˆ
        results = await execute_tasks(tasks)

        print(f"\nğŸ‰ å¹¶å‘ç”Ÿæˆå®Œæˆ! ç”Ÿæˆäº† {len(results)} å¼ å›¾ç‰‡:")
        for i, path in enumerate(results, 1):
            print(f"  {i}. {path}")
        print("ğŸ’¡ è¿™å±•ç¤ºäº†å¼‚æ­¥å¹¶å‘çš„å¼ºå¤§èƒ½åŠ›ï¼")

    except Exception as e:
        print(f"âŒ å¹¶å‘æ¼”ç¤ºå¤±è´¥: {e}")


async def main() -> None:
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""

    # æ£€æŸ¥æ¨¡å‹é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
    if not replicate_config.get_available_models():
        print("âŒ é”™è¯¯: å›¾åƒæ¨¡å‹é…ç½®æœªæ­£ç¡®åŠ è½½")
        sys.exit(1)

    parser = argparse.ArgumentParser(description="Replicate æ–‡ç”Ÿå›¾å·¥å…·")

    parser.add_argument("prompt", nargs="?", help="æ–‡æœ¬æç¤ºè¯")
    parser.add_argument(
        "--negative",
        "-n",
        default="worst quality, low quality, blurry",
        help="è´Ÿå‘æç¤ºè¯ (é»˜è®¤: worst quality, low quality, blurry)",
    )
    parser.add_argument(
        "--width",
        "-w",
        type=int,
        default=1024,
        help="å›¾ç‰‡å®½åº¦ (é»˜è®¤: 1024)",
    )
    parser.add_argument(
        "--height",
        type=int,
        default=1024,
        help="å›¾ç‰‡é«˜åº¦ (é»˜è®¤: 1024)",
    )
    parser.add_argument(
        "--size",
        choices=["small", "medium", "large", "wide", "tall"],
        help="é¢„è®¾å°ºå¯¸: small(512x512), medium(768x768), large(1024x1024), wide(1024x768), tall(768x1024)",
    )
    parser.add_argument(
        "--steps",
        "-s",
        type=int,
        default=4,
        help="æ¨ç†æ­¥æ•° (é»˜è®¤: 4)",
    )
    parser.add_argument(
        "--guidance",
        "-g",
        type=float,
        default=7.5,
        help="å¼•å¯¼æ¯”ä¾‹ (é»˜è®¤: 7.5)",
    )
    parser.add_argument("--output", "-o", default=DEFAULT_OUTPUT_DIR, help="è¾“å‡ºç›®å½•")
    parser.add_argument(
        "--demo", action="store_true", help="è¿è¡Œæ¼”ç¤ºï¼ˆå¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼‰"
    )
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•è¿æ¥")

    args = parser.parse_args()

    try:
        print("âœ… Replicate å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

        # å¤„ç†é¢„è®¾å°ºå¯¸
        if args.size:
            size_presets = {
                "small": (512, 512),
                "medium": (768, 768),
                "large": (1024, 1024),
                "wide": (1024, 768),
                "tall": (768, 1024),
            }
            args.width, args.height = size_presets[args.size]
            print(f"ğŸ“ ä½¿ç”¨é¢„è®¾å°ºå¯¸ '{args.size}': {args.width}x{args.height}")

        # å¦‚æœæ˜¯è¿è¡Œæ¼”ç¤º
        if args.demo:
            await run_concurrent_demo(
                [
                    "peaceful mountain landscape",
                    "ocean waves on sandy beach",
                    "forest path in autumn",
                ]
            )
            return

        # å¦‚æœæ˜¯æµ‹è¯•è¿æ¥
        if args.test:
            test_replicate_api_connection()
            return

        # å¦‚æœæ²¡æœ‰æä¾›æç¤ºè¯ï¼Œæ˜¾ç¤ºå¸®åŠ©
        if not args.prompt:
            print("ğŸ¨ Replicate æ–‡ç”Ÿå›¾å·¥å…·")
            print("\nå¿«é€Ÿå¼€å§‹:")
            print(
                "  python run_replicate_text2image.py --demo            # è¿è¡Œæ¼”ç¤ºï¼ˆå¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼‰"
            )
            print("  python run_replicate_text2image.py --test            # æµ‹è¯•è¿æ¥")
            print('  python run_replicate_text2image.py "ç”Ÿæˆä¸€åªçŒ«"       # ç”Ÿæˆå›¾ç‰‡')
            print("\nå°ºå¯¸é€‰é¡¹:")
            print("  --size small    # 512x512  (æœ€å¿«)")
            print("  --size medium   # 768x768  (æ¨è)")
            print("  --size large    # 1024x1024 (é«˜è´¨é‡)")
            print("  --size wide     # 1024x768 (æ¨ªå‘)")
            print("  --size tall     # 768x1024 (çºµå‘)")
            print("\nè¯¦ç»†å¸®åŠ©:")
            print("  python run_replicate_text2image.py -h")
            return

        # è·å–æ¨¡å‹ç‰ˆæœ¬
        model_version = replicate_config.get_model_version()

        # æ„å»ºæ¨¡å‹è¾“å…¥å‚æ•°
        model_input = {
            "prompt": args.prompt,
            "negative_prompt": args.negative,
            "width": args.width,
            "height": args.height,
            "num_outputs": 1,
            "num_inference_steps": args.steps,
            "guidance_scale": args.guidance,
            "scheduler": "K_EULER",
        }

        # å‡†å¤‡è¾“å‡ºè·¯å¾„
        output_path = str(
            Path(args.output)
            / f"{replicate_config.default_image_model}_{uuid.uuid4()}.png"
        )

        # æ‰“å°ç”Ÿæˆä¿¡æ¯
        print(f"ğŸ¨ ä½¿ç”¨æ¨¡å‹: {replicate_config.default_image_model}")
        print(f"ğŸ“ æç¤ºè¯: {args.prompt}")
        print(f"âš™ï¸  å‚æ•°: {args.width}x{args.height}, {args.steps} æ­¥")

        # ç”Ÿæˆå¹¶ä¸‹è½½å›¾ç‰‡
        saved_path = await generate_and_download(
            model_version=model_version,
            model_input=model_input,
            output_path=output_path,
        )

        print(f"\nğŸ‰ å®Œæˆ! å›¾ç‰‡å·²ä¿å­˜åˆ°: {saved_path}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
