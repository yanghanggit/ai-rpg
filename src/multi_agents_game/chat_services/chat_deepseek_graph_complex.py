from dotenv import load_dotenv
from loguru import logger

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

import os
import traceback
from typing import Annotated, Any, Dict, List, Literal, Optional

from langchain.schema import AIMessage, HumanMessage
from langchain_core.messages import BaseMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.graph.state import CompiledStateGraph
from pydantic import SecretStr
from typing_extensions import TypedDict

# å¯¼å…¥ChromaDBç›¸å…³åŠŸèƒ½
from ..db.chromadb_client import get_chroma_db
from ..db.rag_ops import rag_semantic_search


############################################################################################################
class UnifiedState(TypedDict):
    """ç»Ÿä¸€çŠ¶æ€å®šä¹‰ï¼Œæ”¯æŒç›´æ¥å¯¹è¯å’ŒRAGä¸¤ç§æ¨¡å¼"""

    messages: Annotated[List[BaseMessage], add_messages]
    user_query: str  # ç”¨æˆ·åŸå§‹æŸ¥è¯¢
    route_decision: str  # è·¯ç”±å†³ç­–ç»“æœï¼š"direct" | "rag"

    # RAGä¸“ç”¨å­—æ®µï¼ˆå¯é€‰ï¼‰
    retrieved_docs: Optional[List[str]]  # æ£€ç´¢åˆ°çš„æ–‡æ¡£
    enhanced_context: Optional[str]  # å¢å¼ºåçš„ä¸Šä¸‹æ–‡
    similarity_scores: Optional[List[float]]  # ç›¸ä¼¼åº¦åˆ†æ•°

    # è·¯ç”±å…ƒä¿¡æ¯
    confidence_score: float  # è·¯ç”±å†³ç­–çš„ç½®ä¿¡åº¦
    processing_mode: str  # å¤„ç†æ¨¡å¼æè¿°


############################################################################################################
def router_node(state: UnifiedState) -> Dict[str, Any]:
    """
    è·¯ç”±å†³ç­–èŠ‚ç‚¹

    åŸºäºå…³é”®è¯çš„ç®€å•è·¯ç”±ç­–ç•¥ï¼š
    - æ£€æµ‹è‰¾å°”æ³•å°¼äºšä¸–ç•Œç›¸å…³å…³é”®è¯
    - å†³å®šä½¿ç”¨ç›´æ¥å¯¹è¯è¿˜æ˜¯RAGå¢å¼ºæ¨¡å¼
    """
    try:
        logger.info("ğŸš¦ [ROUTER] å¼€å§‹è·¯ç”±å†³ç­–...")

        user_query = state.get("user_query", "")
        if not user_query:
            # ä»æœ€æ–°æ¶ˆæ¯ä¸­æå–æŸ¥è¯¢
            if state["messages"]:
                last_message = state["messages"][-1]
                if isinstance(last_message, HumanMessage):
                    content = last_message.content
                    user_query = content if isinstance(content, str) else str(content)

        logger.info(f"ğŸš¦ [ROUTER] åˆ†æç”¨æˆ·æŸ¥è¯¢: {user_query}")

        # è‰¾å°”æ³•å°¼äºšä¸–ç•Œç›¸å…³å…³é”®è¯
        rag_keywords = [
            # åœ°åå’Œä¸–ç•Œè®¾å®š
            "è‰¾å°”æ³•å°¼äºš",
            "é˜¿æ–¯ç‰¹æ‹‰ç‹å›½",
            "æœˆæ¡‚æ£®æ—è”é‚¦",
            "é“çˆªéƒ¨æ—è”ç›Ÿ",
            "å°å°ä¹‹å¡”",
            "è´¤è€…ä¹‹å¡”",
            "æ°´æ™¶åŸ",
            "æš—å½±å¢“åœ°",
            "æ˜Ÿè¾°ç¥æ®¿",
            # é‡è¦ç‰©å“å’Œè§’è‰²
            "åœ£å‰‘",
            "æ™¨æ›¦ä¹‹åˆƒ",
            "é­”ç‹",
            "ç›æ‹‰å‡¯æ–¯",
            "é»¯èš€ä¹‹ä¸»",
            "å‹‡è€…",
            "è‰è‰ä¸",
            # ç§æ—å’ŒèŒä¸š
            "ç²¾çµ",
            "å…½äºº",
            "é¾™æ—",
            "çŸ®äºº",
            "å†’é™©è€…",
            "éª‘å£«",
            "æ³•å¸ˆ",
            "æˆ˜å£«",
            # é­”æ³•å’ŒæŠ€èƒ½
            "ç«ç„°",
            "å†°éœœ",
            "é›·ç”µ",
            "æ²»æ„ˆ",
            "æš—å½±",
            "å‡€åŒ–ä¹‹å…‰",
            "å®¡åˆ¤ä¹‹ç‚",
            "å¸Œæœ›å®ˆæŠ¤",
            # ç»„ç»‡å’Œç‰©å“
            "å†’é™©è€…å…¬ä¼š",
            "æš´é£é›ªå›¢",
            "æ—¶ä¹‹æ²™æ¼",
            "ç”Ÿå‘½ä¹‹æ³‰",
            "æ˜Ÿè¾°é’¢",
            "é­”æ³•è¯æ°´",
            # é€šç”¨æ¸¸æˆæœ¯è¯­
            "ç‹å›½",
            "è”é‚¦",
            "éƒ¨æ—",
            "é—è¿¹",
            "åœ°ä¸‹åŸ",
            "é­”æ³•",
            "æŠ€èƒ½",
            "è£…å¤‡",
            "ç­‰çº§",
        ]

        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        query_lower = user_query.lower()
        matched_keywords = [
            keyword for keyword in rag_keywords if keyword in query_lower
        ]

        # è·¯ç”±å†³ç­–é€»è¾‘
        if matched_keywords:
            route_decision = "rag"
            confidence_score = min(0.9, 0.5 + len(matched_keywords) * 0.1)
            processing_mode = f"RAGå¢å¼ºæ¨¡å¼ (åŒ¹é…å…³é”®è¯: {', '.join(matched_keywords[:3])}{'...' if len(matched_keywords) > 3 else ''})"
            logger.success(
                f"ğŸš¦ [ROUTER] é€‰æ‹©RAGæ¨¡å¼ï¼ŒåŒ¹é…åˆ° {len(matched_keywords)} ä¸ªå…³é”®è¯"
            )
        else:
            route_decision = "direct"
            confidence_score = 0.8
            processing_mode = "ç›´æ¥å¯¹è¯æ¨¡å¼"
            logger.info("ğŸš¦ [ROUTER] é€‰æ‹©ç›´æ¥å¯¹è¯æ¨¡å¼ï¼Œæœªæ£€æµ‹åˆ°ä¸“ä¸šå…³é”®è¯")

        logger.info(
            f"ğŸš¦ [ROUTER] è·¯ç”±å†³ç­–å®Œæˆ: {route_decision} (ç½®ä¿¡åº¦: {confidence_score:.2f})"
        )

        return {
            "user_query": user_query,
            "route_decision": route_decision,
            "confidence_score": confidence_score,
            "processing_mode": processing_mode,
        }

    except Exception as e:
        logger.error(f"ğŸš¦ [ROUTER] è·¯ç”±å†³ç­–é”™è¯¯: {e}\n{traceback.format_exc()}")
        # é»˜è®¤å›é€€åˆ°ç›´æ¥å¯¹è¯æ¨¡å¼
        return {
            "user_query": state.get("user_query", ""),
            "route_decision": "direct",
            "confidence_score": 0.5,
            "processing_mode": "é”™è¯¯å›é€€-ç›´æ¥å¯¹è¯æ¨¡å¼",
        }


############################################################################################################
def direct_llm_node(state: UnifiedState) -> Dict[str, List[BaseMessage]]:
    """
    ç›´æ¥LLMå¯¹è¯èŠ‚ç‚¹

    åŠŸèƒ½ï¼š
    - ç›´æ¥ä½¿ç”¨DeepSeekè¿›è¡Œå¯¹è¯ï¼Œæ— é¢å¤–ä¸Šä¸‹æ–‡å¢å¼º
    - é€‚ç”¨äºä¸€èˆ¬æ€§å¯¹è¯å’Œç®€å•é—®ç­”
    """
    try:
        logger.info("ğŸ’¬ [DIRECT_LLM] å¼€å§‹ç›´æ¥å¯¹è¯æ¨¡å¼...")

        # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
        deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
        if not deepseek_api_key:
            raise ValueError("DEEPSEEK_API_KEY environment variable is not set")

        llm = ChatDeepSeek(
            api_key=SecretStr(deepseek_api_key),
            model="deepseek-chat",
            temperature=0.7,
        )

        # ç›´æ¥ä½¿ç”¨åŸå§‹æ¶ˆæ¯è°ƒç”¨LLM
        response = llm.invoke(state["messages"])
        logger.success("ğŸ’¬ [DIRECT_LLM] ç›´æ¥å¯¹è¯å›ç­”ç”Ÿæˆå®Œæˆ")

        return {"messages": [response]}

    except Exception as e:
        logger.error(f"ğŸ’¬ [DIRECT_LLM] ç›´æ¥å¯¹è¯èŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}")
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return {"messages": [error_response]}


############################################################################################################
def retrieval_node(state: UnifiedState) -> Dict[str, Any]:
    """
    RAGæ£€ç´¢èŠ‚ç‚¹

    åŠŸèƒ½ï¼š
    - ChromaDBå‘é‡è¯­ä¹‰æœç´¢
    - è·å–ç›¸å…³æ–‡æ¡£å’Œç›¸ä¼¼åº¦åˆ†æ•°
    - ä¸ºåç»­ä¸Šä¸‹æ–‡å¢å¼ºæä¾›æ•°æ®
    """
    try:
        logger.info("ğŸ” [RETRIEVAL] å¼€å§‹RAGæ£€ç´¢...")

        user_query = state.get("user_query", "")
        logger.info(f"ğŸ” [RETRIEVAL] ç”¨æˆ·æŸ¥è¯¢: {user_query}")

        # è·å–ChromaDBå®ä¾‹å¹¶æ‰§è¡Œè¯­ä¹‰æœç´¢
        chroma_db = get_chroma_db()

        if not chroma_db.initialized:
            logger.error("âŒ [RETRIEVAL] ChromaDBæœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")
            return {
                "retrieved_docs": ["ChromaDBæ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚"],
                "similarity_scores": [0.0],
            }

        # æ‰§è¡Œå‘é‡è¯­ä¹‰æœç´¢
        retrieved_docs, similarity_scores = rag_semantic_search(
            query=user_query, top_k=5
        )

        # æ£€æŸ¥æœç´¢ç»“æœ
        if not retrieved_docs:
            logger.warning("ğŸ” [RETRIEVAL] è¯­ä¹‰æœç´¢æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨é»˜è®¤å›å¤")
            retrieved_docs = [
                "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„å…·ä½“ä¿¡æ¯ï¼Œæˆ‘ä¼šå°½åŠ›æ ¹æ®å¸¸è¯†å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
            ]
            similarity_scores = [0.0]

        # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœï¼ˆç›¸ä¼¼åº¦é˜ˆå€¼ï¼š0.3ï¼‰
        MIN_SIMILARITY = 0.3
        filtered_docs = []
        filtered_scores = []

        for doc, score in zip(retrieved_docs, similarity_scores):
            if score >= MIN_SIMILARITY:
                filtered_docs.append(doc)
                filtered_scores.append(score)

        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ–‡æ¡£ï¼Œä¿ç•™æœ€é«˜åˆ†çš„æ–‡æ¡£
        if not filtered_docs and retrieved_docs:
            filtered_docs = [retrieved_docs[0]]
            filtered_scores = [similarity_scores[0]]
            logger.info(
                f"ğŸ” [RETRIEVAL] æ‰€æœ‰ç»“æœä½äºé˜ˆå€¼ï¼Œä¿ç•™æœ€é«˜åˆ†æ–‡æ¡£ (ç›¸ä¼¼åº¦: {similarity_scores[0]:.3f})"
            )

        logger.success(
            f"ğŸ” [RETRIEVAL] è¯­ä¹‰æ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(filtered_docs)} ä¸ªç›¸å…³æ–‡æ¡£"
        )

        # è®°å½•ç›¸ä¼¼åº¦ä¿¡æ¯
        for i, (doc, score) in enumerate(zip(filtered_docs, filtered_scores)):
            logger.debug(f"  ğŸ“„ [{i+1}] ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {doc[:50]}...")

        return {
            "retrieved_docs": filtered_docs,
            "similarity_scores": filtered_scores,
        }

    except Exception as e:
        logger.error(f"ğŸ” [RETRIEVAL] æ£€ç´¢èŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}")
        return {
            "retrieved_docs": ["æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œå°†ä½¿ç”¨é»˜è®¤å›å¤ã€‚"],
            "similarity_scores": [0.0],
        }


############################################################################################################
def enhancement_node(state: UnifiedState) -> Dict[str, Any]:
    """
    ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹

    åŠŸèƒ½ï¼š
    - æ„å»ºåŒ…å«æ£€ç´¢ç»“æœçš„å¢å¼ºæç¤º
    - æ·»åŠ ç›¸ä¼¼åº¦ä¿¡æ¯å’Œå¤„ç†æŒ‡å¯¼
    - ä¸ºRAG LLMèŠ‚ç‚¹æä¾›ä¼˜åŒ–çš„ä¸Šä¸‹æ–‡
    """
    try:
        logger.info("ğŸ“ [ENHANCEMENT] å¼€å§‹ä¸Šä¸‹æ–‡å¢å¼º...")

        user_query = state.get("user_query", "")
        retrieved_docs = state.get("retrieved_docs", [])
        similarity_scores = state.get("similarity_scores", [])

        logger.info(f"ğŸ“ [ENHANCEMENT] å¤„ç†æŸ¥è¯¢: {user_query}")
        logger.info(
            f"ğŸ“ [ENHANCEMENT] æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡: {len(retrieved_docs) if retrieved_docs else 0}"
        )

        if similarity_scores:
            avg_similarity = sum(similarity_scores) / len(similarity_scores)
            max_similarity = max(similarity_scores)
            logger.info(
                f"ğŸ“ [ENHANCEMENT] å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}, æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.3f}"
            )

        # æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡prompt
        context_parts = [
            "è¯·åŸºäºä»¥ä¸‹ç›¸å…³ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜:",
            "",
            "ç›¸å…³ä¿¡æ¯ (æŒ‰ç›¸ä¼¼åº¦æ’åº):",
        ]

        # å°†æ–‡æ¡£å’Œç›¸ä¼¼åº¦åˆ†æ•°é…å¯¹ï¼Œå¹¶æŒ‰ç›¸ä¼¼åº¦æ’åº
        if (
            similarity_scores
            and retrieved_docs
            and len(similarity_scores) == len(retrieved_docs)
        ):
            doc_score_pairs = list(zip(retrieved_docs, similarity_scores))
            # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
            doc_score_pairs.sort(key=lambda x: x[1], reverse=True)

            for i, (doc, score) in enumerate(doc_score_pairs, 1):
                # æ·»åŠ ç›¸ä¼¼åº¦ä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡ä¸­
                context_parts.append(f"{i}. [ç›¸ä¼¼åº¦: {score:.3f}] {doc}")
        else:
            # å›é€€åˆ°åŸæ¥çš„æ ¼å¼ï¼ˆæ²¡æœ‰ç›¸ä¼¼åº¦ä¿¡æ¯ï¼‰
            if retrieved_docs:
                for i, doc in enumerate(retrieved_docs, 1):
                    context_parts.append(f"{i}. {doc}")

        context_parts.extend(
            [
                "",
                f"ç”¨æˆ·é—®é¢˜: {user_query}",
                "",
                "è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”:",
                "- ä¼˜å…ˆä½¿ç”¨ç›¸ä¼¼åº¦è¾ƒé«˜çš„ä¿¡æ¯",
                "- å¦‚æœç›¸ä¼¼åº¦è¾ƒä½ï¼Œè¯·é€‚å½“æé†’ç”¨æˆ·",
                "- ä¿æŒå›ç­”çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§",
                "- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜å¹¶æä¾›å¯èƒ½çš„å¸®åŠ©",
            ]
        )

        enhanced_context = "\n".join(context_parts)

        logger.info("ğŸ“ [ENHANCEMENT] ä¸Šä¸‹æ–‡å¢å¼ºå®Œæˆ")
        logger.debug(
            f"ğŸ“ [ENHANCEMENT] å¢å¼ºåçš„ä¸Šä¸‹æ–‡é•¿åº¦: {len(enhanced_context)} å­—ç¬¦"
        )

        return {"enhanced_context": enhanced_context}

    except Exception as e:
        logger.error(
            f"ğŸ“ [ENHANCEMENT] ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}"
        )
        fallback_context = f"è¯·å›ç­”ä»¥ä¸‹é—®é¢˜: {state.get('user_query', '')}"
        return {"enhanced_context": fallback_context}


############################################################################################################
def rag_llm_node(state: UnifiedState) -> Dict[str, List[BaseMessage]]:
    """
    RAGå¢å¼ºLLMèŠ‚ç‚¹

    åŠŸèƒ½ï¼š
    - ä½¿ç”¨å¢å¼ºçš„ä¸Šä¸‹æ–‡è°ƒç”¨DeepSeek
    - ç”ŸæˆåŸºäºæ£€ç´¢ä¿¡æ¯çš„ä¸“ä¸šå›ç­”
    """
    try:
        logger.info("ğŸ¤– [RAG_LLM] å¼€å§‹RAGå¢å¼ºå›ç­”ç”Ÿæˆ...")

        # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
        deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
        if not deepseek_api_key:
            raise ValueError("DEEPSEEK_API_KEY environment variable is not set")

        llm = ChatDeepSeek(
            api_key=SecretStr(deepseek_api_key),
            model="deepseek-chat",
            temperature=0.7,
        )

        # ä½¿ç”¨å¢å¼ºçš„ä¸Šä¸‹æ–‡æ›¿æ¢åŸå§‹æ¶ˆæ¯
        enhanced_context = state.get("enhanced_context", "")
        if enhanced_context:
            enhanced_message = HumanMessage(content=enhanced_context)
            logger.info("ğŸ¤– [RAG_LLM] ä½¿ç”¨å¢å¼ºä¸Šä¸‹æ–‡è°ƒç”¨DeepSeek")
        else:
            # å›é€€åˆ°åŸå§‹æ¶ˆæ¯
            if state["messages"]:
                last_msg = state["messages"][-1]
                if isinstance(last_msg, HumanMessage):
                    enhanced_message = last_msg
                else:
                    content = (
                        last_msg.content
                        if isinstance(last_msg.content, str)
                        else str(last_msg.content)
                    )
                    enhanced_message = HumanMessage(content=content)
            else:
                enhanced_message = HumanMessage(content="Hello")
            logger.warning("ğŸ¤– [RAG_LLM] å¢å¼ºä¸Šä¸‹æ–‡ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ¶ˆæ¯")

        # è°ƒç”¨LLM
        response = llm.invoke([enhanced_message])
        logger.success("ğŸ¤– [RAG_LLM] RAGå¢å¼ºå›ç­”ç”Ÿæˆå®Œæˆ")

        return {"messages": [response]}

    except Exception as e:
        logger.error(f"ğŸ¤– [RAG_LLM] RAG LLMèŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}")
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return {"messages": [error_response]}


############################################################################################################
def route_decision_function(state: UnifiedState) -> Literal["direct", "rag"]:
    """
    è·¯ç”±å†³ç­–å‡½æ•°

    ç”¨äºLangGraphçš„æ¡ä»¶è¾¹ï¼Œæ ¹æ®çŠ¶æ€ä¸­çš„route_decisionå­—æ®µè¿”å›è·¯ç”±ç›®æ ‡
    """
    route = state.get("route_decision", "direct")
    logger.info(f"ğŸš¦ [ROUTE_DECISION] æ‰§è¡Œè·¯ç”±: {route}")
    return route  # type: ignore


############################################################################################################
def create_unified_chat_graph() -> (
    CompiledStateGraph[UnifiedState, Any, UnifiedState, UnifiedState]
):
    """
    åˆ›å»ºç»Ÿä¸€çš„èŠå¤©å›¾

    å›¾ç»“æ„ï¼š
    router â†’ [æ¡ä»¶åˆ†æ”¯] â†’ direct_llm | (retrieval â†’ enhancement â†’ rag_llm)
    """
    logger.info("ğŸ—ï¸ æ„å»ºç»Ÿä¸€èŠå¤©å›¾...")

    try:
        # åˆ›å»ºçŠ¶æ€å›¾
        graph_builder = StateGraph(UnifiedState)

        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        graph_builder.add_node("router", router_node)
        graph_builder.add_node("direct_llm", direct_llm_node)
        graph_builder.add_node("retrieval", retrieval_node)
        graph_builder.add_node("enhancement", enhancement_node)
        graph_builder.add_node("rag_llm", rag_llm_node)

        # è®¾ç½®å…¥å£ç‚¹
        graph_builder.set_entry_point("router")

        # æ·»åŠ æ¡ä»¶è·¯ç”±
        graph_builder.add_conditional_edges(
            "router",
            route_decision_function,
            {"direct": "direct_llm", "rag": "retrieval"},
        )

        # RAGåˆ†æ”¯å†…éƒ¨è¿æ¥
        graph_builder.add_edge("retrieval", "enhancement")
        graph_builder.add_edge("enhancement", "rag_llm")

        # è®¾ç½®ç»ˆç‚¹
        graph_builder.set_finish_point("direct_llm")
        graph_builder.set_finish_point("rag_llm")

        compiled_graph = graph_builder.compile()
        logger.success("ğŸ—ï¸ ç»Ÿä¸€èŠå¤©å›¾æ„å»ºå®Œæˆ")

        return compiled_graph  # type: ignore[return-value]

    except Exception as e:
        logger.error(f"ğŸ—ï¸ æ„å»ºç»Ÿä¸€èŠå¤©å›¾å¤±è´¥: {e}\n{traceback.format_exc()}")
        raise


############################################################################################################
def stream_unified_graph_updates(
    unified_compiled_graph: CompiledStateGraph[
        UnifiedState, Any, UnifiedState, UnifiedState
    ],
    chat_history_state: Dict[str, List[BaseMessage]],
    user_input_state: Dict[str, List[BaseMessage]],
) -> List[BaseMessage]:
    """
    æ‰§è¡Œç»Ÿä¸€å›¾å¹¶è¿”å›ç»“æœ

    Args:
        unified_compiled_graph: ç¼–è¯‘åçš„ç»Ÿä¸€å›¾
        chat_history_state: èŠå¤©å†å²çŠ¶æ€
        user_input_state: ç”¨æˆ·è¾“å…¥çŠ¶æ€

    Returns:
        List[BaseMessage]: ç”Ÿæˆçš„å›ç­”æ¶ˆæ¯åˆ—è¡¨
    """
    ret: List[BaseMessage] = []

    try:
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œç»Ÿä¸€èŠå¤©æµç¨‹...")

        # å‡†å¤‡ç»Ÿä¸€çŠ¶æ€
        user_message = (
            user_input_state["messages"][-1] if user_input_state["messages"] else None
        )
        user_query = ""
        if user_message:
            content = user_message.content
            user_query = content if isinstance(content, str) else str(content)

        unified_state: UnifiedState = {
            "messages": chat_history_state["messages"] + user_input_state["messages"],
            "user_query": user_query,
            "route_decision": "",  # å°†ç”±router_nodeå¡«å……
            "retrieved_docs": None,
            "enhanced_context": None,
            "similarity_scores": None,
            "confidence_score": 0.0,
            "processing_mode": "",
        }

        logger.info(f"ğŸš€ ç»Ÿä¸€çŠ¶æ€å‡†å¤‡å®Œæˆï¼Œç”¨æˆ·æŸ¥è¯¢: {user_query}")

        # æ‰§è¡Œç»Ÿä¸€å›¾æµç¨‹
        for event in unified_compiled_graph.stream(unified_state):
            logger.debug(f"ğŸš€ ç»Ÿä¸€å›¾äº‹ä»¶: {list(event.keys())}")
            for node_name, node_output in event.items():
                if "messages" in node_output:
                    ret.extend(node_output["messages"])
                    logger.info(
                        f"ğŸš€ èŠ‚ç‚¹ [{node_name}] è¾“å‡ºæ¶ˆæ¯æ•°é‡: {len(node_output['messages'])}"
                    )

        logger.success("ğŸš€ ç»Ÿä¸€èŠå¤©æµç¨‹æ‰§è¡Œå®Œæˆ")

    except Exception as e:
        logger.error(f"ğŸš€ ç»Ÿä¸€èŠå¤©æµç¨‹æ‰§è¡Œé”™è¯¯: {e}\n{traceback.format_exc()}")
        error_response = AIMessage(content="ç»Ÿä¸€èŠå¤©æµç¨‹æ‰§è¡Œæ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        ret = [error_response]

    return ret


############################################################################################################
def main() -> None:
    """
    ç»Ÿä¸€èŠå¤©ç³»ç»Ÿä¸»å‡½æ•°

    åŠŸèƒ½ï¼š
    - åˆ›å»ºç»Ÿä¸€èŠå¤©å›¾
    - æä¾›äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢
    - æ”¯æŒç›´æ¥å¯¹è¯å’ŒRAGå¢å¼ºä¸¤ç§æ¨¡å¼çš„æ™ºèƒ½åˆ‡æ¢
    """
    logger.info("ğŸ¯ å¯åŠ¨ç»Ÿä¸€èŠå¤©ç³»ç»Ÿ...")

    try:
        # åˆ›å»ºç»Ÿä¸€èŠå¤©å›¾
        unified_graph = create_unified_chat_graph()

        # åˆå§‹åŒ–èŠå¤©å†å²
        chat_history_state: Dict[str, List[BaseMessage]] = {"messages": []}

        logger.success("ğŸ¯ ç»Ÿä¸€èŠå¤©ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        logger.info("ğŸ’¡ æç¤ºï¼šç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ‚¨çš„æŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€ä½³å¤„ç†æ¨¡å¼")
        logger.info("   - æ¶‰åŠè‰¾å°”æ³•å°¼äºšä¸–ç•Œçš„é—®é¢˜å°†ä½¿ç”¨RAGå¢å¼ºæ¨¡å¼")
        logger.info("   - ä¸€èˆ¬æ€§å¯¹è¯å°†ä½¿ç”¨ç›´æ¥å¯¹è¯æ¨¡å¼")
        logger.info("ğŸ’¡ è¾“å…¥ /quitã€/exit æˆ– /q é€€å‡ºç¨‹åº")

        # å¼€å§‹äº¤äº’å¾ªç¯
        while True:
            try:
                print("\n" + "=" * 60)
                user_input = input("User: ")

                if user_input.lower() in ["/quit", "/exit", "/q"]:
                    print("Goodbye!")
                    break

                # ç”¨æˆ·è¾“å…¥çŠ¶æ€
                user_input_state: Dict[str, List[BaseMessage]] = {
                    "messages": [HumanMessage(content=user_input)]
                }

                # æ‰§è¡Œç»Ÿä¸€å›¾æµç¨‹
                update_messages = stream_unified_graph_updates(
                    unified_compiled_graph=unified_graph,
                    chat_history_state=chat_history_state,
                    user_input_state=user_input_state,
                )

                # æ›´æ–°èŠå¤©å†å²
                chat_history_state["messages"].extend(user_input_state["messages"])
                chat_history_state["messages"].extend(update_messages)

                # æ˜¾ç¤ºæœ€æ–°çš„AIå›å¤
                if update_messages:
                    latest_response = update_messages[-1]
                    print(f"\nDeepSeek: {latest_response.content}")
                    logger.success(f"âœ… ç³»ç»Ÿå›ç­”: {latest_response.content}")

                logger.debug("=" * 60)

            except KeyboardInterrupt:
                logger.info("ğŸ›‘ [MAIN] ç”¨æˆ·ä¸­æ–­ç¨‹åº")
                break
            except Exception as e:
                logger.error(f"âŒ ç»Ÿä¸€èŠå¤©æµç¨‹å¤„ç†é”™è¯¯: {e}\n{traceback.format_exc()}")
                print("æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·é‡è¯•ã€‚")

    except Exception as e:
        logger.error(f"âŒ [MAIN] ç»Ÿä¸€èŠå¤©ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        print("ç³»ç»Ÿå¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")

    finally:
        logger.info("ğŸ”’ [MAIN] æ¸…ç†ç³»ç»Ÿèµ„æº...")


############################################################################################################
if __name__ == "__main__":
    main()
