"""
RAGæ“ä½œæ¨¡å—

æ­¤æ¨¡å—æä¾›RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿçš„æ ¸å¿ƒæ“ä½œåŠŸèƒ½ï¼š
1. åˆå§‹åŒ–RAGç³»ç»Ÿ - è®¾ç½®å‘é‡æ•°æ®åº“å’ŒåµŒå…¥æ¨¡å‹
2. è¯­ä¹‰æœç´¢ - åŸºäºæŸ¥è¯¢æ–‡æœ¬æ£€ç´¢ç›¸å…³æ–‡æ¡£

åŠŸèƒ½ï¼š
- initialize_rag_system: åˆå§‹åŒ–æ•´ä¸ªRAGç³»ç»Ÿï¼ŒåŒ…æ‹¬å‘é‡æ•°æ®åº“å’ŒçŸ¥è¯†åº“åŠ è½½
- semantic_search: æ‰§è¡Œè¯­ä¹‰æœç´¢ï¼Œè¿”å›æœ€ç›¸å…³çš„æ–‡æ¡£å’Œç›¸ä¼¼åº¦åˆ†æ•°
"""

import traceback
from typing import Dict, List, Mapping, Sequence, Tuple
from loguru import logger
from chromadb.api.models.Collection import Collection
from sentence_transformers import SentenceTransformer


############################################################################################################
# æœ¬é¡µçš„å†…éƒ¨å‡½æ•°ã€‚
def _prepare_documents_for_vector_storage(
    knowledge_base: Dict[str, List[str]],
    embedding_model: SentenceTransformer,  # SentenceTransformer å®ä¾‹ï¼ˆéå¯é€‰ï¼‰
) -> Tuple[
    List[Sequence[float]],
    List[str],
    List[Mapping[str, str | int | float | bool | None]],
    List[str],
]:
    """
    å‡†å¤‡çŸ¥è¯†åº“æ•°æ®ç”¨äºå‘é‡åŒ–å’Œå­˜å‚¨

    Args:
        knowledge_base: çŸ¥è¯†åº“æ•°æ®ï¼Œæ ¼å¼ä¸º {category: [documents]}
        embedding_model: SentenceTransformer åµŒå…¥æ¨¡å‹å®ä¾‹

    Returns:
        Tuple: (embeddings, documents, metadatas, ids) - collection.add()æ–¹æ³•çš„å‚æ•°
    """
    try:
        logger.info("ğŸ”„ [PREPARE] å¼€å§‹å‡†å¤‡çŸ¥è¯†åº“æ•°æ®...")

        # å‡†å¤‡æ–‡æ¡£æ•°æ®
        documents: List[str] = []
        metadatas: List[Mapping[str, str | int | float | bool | None]] = []
        ids: List[str] = []

        doc_id = 0
        for category, docs in knowledge_base.items():
            for doc in docs:
                documents.append(doc)
                metadatas.append({"category": category, "doc_id": doc_id})
                ids.append(f"{category}_{doc_id}")
                doc_id += 1

        logger.info(f"ğŸ“Š [PREPARE] å‡†å¤‡å‘é‡åŒ– {len(documents)} ä¸ªæ–‡æ¡£...")

        # ä½¿ç”¨SentenceTransformerè®¡ç®—å‘é‡åµŒå…¥
        logger.info("ğŸ”„ [PREPARE] è®¡ç®—æ–‡æ¡£å‘é‡åµŒå…¥...")
        embeddings = embedding_model.encode(documents)

        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼ˆChromaDBè¦æ±‚ï¼‰
        embeddings_list = embeddings.tolist()

        logger.success(f"âœ… [PREPARE] æˆåŠŸå‡†å¤‡ {len(documents)} ä¸ªæ–‡æ¡£çš„åµŒå…¥æ•°æ®")

        return embeddings_list, documents, metadatas, ids

    except Exception as e:
        logger.error(f"âŒ [PREPARE] å‡†å¤‡çŸ¥è¯†åº“æ•°æ®å¤±è´¥: {e}\n{traceback.format_exc()}")
        return [], [], [], []


############################################################################################################
def load_character_private_knowledge(
    character_name: str,
    knowledge_list: List[str],
    embedding_model: SentenceTransformer,
    collection: Collection,
) -> bool:
    """
    ä¸ºå•ä¸ªè§’è‰²åŠ è½½ç§æœ‰çŸ¥è¯†ï¼ˆåœ¨è§’è‰²åˆ›å»ºæ—¶è°ƒç”¨ï¼‰

    è¿™æ˜¯åŠ¨æ€åŠ è½½æ–¹å¼ï¼Œåœ¨è§’è‰²åˆå§‹åŒ–æ—¶è°ƒç”¨ï¼ŒåªåŠ è½½å½“å‰è§’è‰²çš„çŸ¥è¯†

    Args:
        character_name: è§’è‰²åç§°ï¼ˆå¦‚ "è§’è‰².æ³•å¸ˆ.å¥¥éœ²å¨œ"ï¼‰
        knowledge_list: è¯¥è§’è‰²çš„ç§æœ‰çŸ¥è¯†åˆ—è¡¨
        embedding_model: SentenceTransformer åµŒå…¥æ¨¡å‹å®ä¾‹
        collection: ChromaDB Collection å®ä¾‹

    Returns:
        bool: åŠ è½½æ˜¯å¦æˆåŠŸ

    Example:
        # åœ¨åˆ›å»ºè§’è‰²å®ä½“æ—¶è°ƒç”¨
        knowledge = ["æˆ‘æ˜¯æ³•å¸ˆå¥¥éœ²å¨œ", "æˆ‘åœ¨æ˜Ÿè¾‰å­¦é™¢å­¦ä¹ "]
        load_character_private_knowledge(
            "è§’è‰².æ³•å¸ˆ.å¥¥éœ²å¨œ", knowledge, model, collection
        )
    """
    try:
        if not knowledge_list:
            logger.warning(f"âš ï¸  [CHAR] è§’è‰² {character_name} æ²¡æœ‰ç§æœ‰çŸ¥è¯†ï¼Œè·³è¿‡åŠ è½½")
            return True

        logger.info(
            f"ğŸ” [CHAR] ä¸º {character_name} åŠ è½½ {len(knowledge_list)} æ¡ç§æœ‰çŸ¥è¯†..."
        )

        # å‡†å¤‡æ•°æ®
        documents: List[str] = []
        metadatas: List[Mapping[str, str | int | float | bool | None]] = []
        ids: List[str] = []

        for i, knowledge in enumerate(knowledge_list):
            documents.append(knowledge)
            metadatas.append(
                {
                    "character_name": character_name,  # è§’è‰²éš”ç¦»æ ‡è®°
                    "type": "private",
                    "doc_id": i,
                }
            )
            ids.append(f"{character_name}_private_{i}")

        # è®¡ç®—å‘é‡åµŒå…¥
        embeddings = embedding_model.encode(documents)
        embeddings_list = embeddings.tolist()

        # æ·»åŠ åˆ° ChromaDB
        collection.add(
            embeddings=embeddings_list,
            documents=documents,
            metadatas=metadatas,  # type: ignore[arg-type]
            ids=ids,
        )

        logger.success(f"âœ… [CHAR] {character_name} ç§æœ‰çŸ¥è¯†åŠ è½½å®Œæˆ")
        return True

    except Exception as e:
        logger.error(
            f"âŒ [CHAR] {character_name} ç§æœ‰çŸ¥è¯†åŠ è½½å¤±è´¥: {e}\n{traceback.format_exc()}"
        )
        return False


############################################################################################################
def load_knowledge_base_to_vector_db(
    knowledge_base: Dict[str, List[str]],
    embedding_model: SentenceTransformer,
    collection: Collection,
) -> bool:
    """
    åˆå§‹åŒ–RAGç³»ç»Ÿ

    åŠŸèƒ½ï¼š
    1. å°†çŸ¥è¯†åº“æ•°æ®å‘é‡åŒ–å¹¶å­˜å‚¨
    2. éªŒè¯ç³»ç»Ÿå°±ç»ªçŠ¶æ€

    Args:
        knowledge_base: è¦åŠ è½½çš„çŸ¥è¯†åº“æ•°æ®
        embedding_model: SentenceTransformer åµŒå…¥æ¨¡å‹å®ä¾‹
        collection: ChromaDB Collection å®ä¾‹

    Returns:
        bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    """
    logger.info("ğŸš€ [INIT] å¼€å§‹åˆå§‹åŒ–RAGç³»ç»Ÿ...")

    try:
        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦åŠ è½½çŸ¥è¯†åº“æ•°æ®
        if collection and collection.count() == 0:
            logger.info("ğŸ“š [INIT] é›†åˆä¸ºç©ºï¼Œå¼€å§‹åŠ è½½çŸ¥è¯†åº“æ•°æ®...")

            # 3. å±•å¼€çŸ¥è¯†åº“åŠ è½½é€»è¾‘ï¼ˆåŸ load_knowledge_base æ–¹æ³•çš„å†…å®¹ï¼‰
            try:
                logger.info("ğŸ“š [CHROMADB] å¼€å§‹åŠ è½½çŸ¥è¯†åº“æ•°æ®...")

                if not collection:
                    logger.error("âŒ [CHROMADB] é›†åˆæœªåˆå§‹åŒ–")
                    return False

                # ä½¿ç”¨ä¼ å…¥çš„åµŒå…¥æ¨¡å‹å‡†å¤‡çŸ¥è¯†åº“æ•°æ®
                embeddings_list, documents, metadatas, ids = (
                    _prepare_documents_for_vector_storage(
                        knowledge_base, embedding_model
                    )
                )

                # æ£€æŸ¥å‡†å¤‡ç»“æœ
                if not embeddings_list or not documents:
                    logger.error("âŒ [CHROMADB] çŸ¥è¯†åº“æ•°æ®å‡†å¤‡å¤±è´¥")
                    return False

                # æ‰¹é‡æ·»åŠ åˆ°ChromaDB
                logger.info("ğŸ’¾ [CHROMADB] å­˜å‚¨å‘é‡åˆ°æ•°æ®åº“...")
                collection.add(
                    embeddings=embeddings_list,
                    documents=documents,
                    metadatas=metadatas,  # type: ignore[arg-type]
                    ids=ids,
                )

                logger.success(
                    f"âœ… [CHROMADB] æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“"
                )

                # éªŒè¯æ•°æ®åŠ è½½
                count = collection.count()
                logger.info(f"ğŸ“Š [CHROMADB] æ•°æ®åº“ä¸­ç°æœ‰æ–‡æ¡£æ•°é‡: {count}")

            except Exception as e:
                logger.error(
                    f"âŒ [CHROMADB] çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}\n{traceback.format_exc()}"
                )
                return False

        logger.success("ğŸ‰ [INIT] RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        return True

    except Exception as e:
        logger.error(f"âŒ [INIT] åˆå§‹åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}")
        logger.warning("âš ï¸ [INIT] ç³»ç»Ÿå°†å›é€€åˆ°å…³é”®è¯åŒ¹é…æ¨¡å¼")
        return False


############################################################################################################
def search_private_knowledge(
    query: str,
    character_name: str,
    collection: Collection,
    embedding_model: SentenceTransformer,
    top_k: int = 3,
) -> Tuple[List[str], List[float]]:
    """
    æŸ¥è¯¢è§’è‰²çš„ç§æœ‰çŸ¥è¯†ï¼ˆå¸¦è§’è‰²è¿‡æ»¤ï¼‰

    ä¸ search_similar_documents çš„åŒºåˆ«ï¼š
    - ä½¿ç”¨ where è¿‡æ»¤ï¼Œåªè¿”å›æŒ‡å®šè§’è‰²çš„ç§æœ‰çŸ¥è¯†
    - é»˜è®¤ top_k=3ï¼ˆç§æœ‰çŸ¥è¯†é€šå¸¸è¾ƒå°‘ï¼‰

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        character_name: è§’è‰²åç§°ï¼ˆå¦‚ "è§’è‰².æ³•å¸ˆ.å¥¥éœ²å¨œ"ï¼‰
        collection: ChromaDB Collection å®ä¾‹ï¼ˆåº”ä¸º private_knowledge_collectionï¼‰
        embedding_model: SentenceTransformer åµŒå…¥æ¨¡å‹å®ä¾‹
        top_k: è¿”å›æœ€ç›¸ä¼¼çš„æ–‡æ¡£æ•°é‡

    Returns:
        tuple: (æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨, ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨)

    Example:
        docs, scores = search_private_knowledge(
            query="æˆ‘çš„ç ”ç©¶è¿›å±•å¦‚ä½•",
            character_name="è§’è‰².æ³•å¸ˆ.å¥¥éœ²å¨œ",
            collection=get_private_knowledge_collection(),
            embedding_model=multilingual_model,
        )
    """
    try:
        if not collection:
            logger.error("âŒ [PRIVATE] é›†åˆæœªåˆå§‹åŒ–")
            return [], []

        logger.info(f"ğŸ” [PRIVATE] æŸ¥è¯¢ {character_name} çš„ç§æœ‰çŸ¥è¯†: '{query}'")

        # è®¡ç®—æŸ¥è¯¢å‘é‡
        query_embedding = embedding_model.encode([query])

        # æ‰§è¡Œå‘é‡æœç´¢ï¼Œä½¿ç”¨ where è¿‡æ»¤è§’è‰²
        results = collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=top_k,
            where={"character_name": character_name},  # â† å…³é”®ï¼šè¿‡æ»¤è§’è‰²
            include=["documents", "distances", "metadatas"],
        )

        # æå–ç»“æœ
        documents = results["documents"][0] if results["documents"] else []
        distances = results["distances"][0] if results["distances"] else []

        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
        if distances:
            max_distance = max(distances) if distances else 1.0
            similarity_scores = [
                max(0, 1 - (dist / max_distance)) for dist in distances
            ]
        else:
            similarity_scores = []

        logger.info(f"âœ… [PRIVATE] æ‰¾åˆ° {len(documents)} æ¡ç§æœ‰çŸ¥è¯†")

        return documents, similarity_scores

    except Exception as e:
        logger.error(f"âŒ [PRIVATE] ç§æœ‰çŸ¥è¯†æŸ¥è¯¢å¤±è´¥: {e}\n{traceback.format_exc()}")
        return [], []


############################################################################################################
############################################################################################################
def search_similar_documents(
    query: str,
    collection: Collection,
    embedding_model: SentenceTransformer,
    top_k: int = 5,
) -> Tuple[List[str], List[float]]:
    """
    æ‰§è¡Œè¯­ä¹‰æœç´¢

    åŠŸèƒ½ï¼š
    1. è®¡ç®—æŸ¥è¯¢å‘é‡
    2. æ‰§è¡Œå‘é‡æœç´¢
    3. è¿”å›æœç´¢ç»“æœ

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
        collection: ChromaDB Collection å®ä¾‹
        embedding_model: SentenceTransformer åµŒå…¥æ¨¡å‹å®ä¾‹
        top_k: è¿”å›æœ€ç›¸ä¼¼çš„æ–‡æ¡£æ•°é‡

    Returns:
        tuple: (æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨, ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨)
    """
    try:
        # 1. éªŒè¯é›†åˆçŠ¶æ€
        if not collection:
            logger.error("âŒ [CHROMADB] é›†åˆæœªåˆå§‹åŒ–")
            return [], []

        logger.info(f"ğŸ” [CHROMADB] æ‰§è¡Œè¯­ä¹‰æœç´¢: '{query}'")

        # 2. è®¡ç®—æŸ¥è¯¢å‘é‡
        query_embedding = embedding_model.encode([query])

        # 3. åœ¨ChromaDBä¸­æ‰§è¡Œå‘é‡æœç´¢
        results = collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=top_k,
            include=["documents", "distances", "metadatas"],
        )

        # 4. æå–ç»“æœ
        documents = results["documents"][0] if results["documents"] else []
        distances = results["distances"][0] if results["distances"] else []
        metadatas = results["metadatas"][0] if results["metadatas"] else []

        # 5. å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
        # ç›¸ä¼¼åº¦ = 1 - æ ‡å‡†åŒ–è·ç¦»
        if distances:
            max_distance = max(distances) if distances else 1.0
            similarity_scores = [
                max(0, 1 - (dist / max_distance)) for dist in distances
            ]
        else:
            similarity_scores = []

        logger.info(f"âœ… [CHROMADB] æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(documents)} ä¸ªç›¸å…³æ–‡æ¡£")

        # 6. æ‰“å°æœç´¢ç»“æœè¯¦æƒ…ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        for i, (doc, score, metadata) in enumerate(
            zip(documents, similarity_scores, metadatas)
        ):
            logger.debug(
                f"  ğŸ“„ [{i+1}] ç›¸ä¼¼åº¦: {score:.3f}, ç±»åˆ«: {metadata.get('category', 'unknown')}, å†…å®¹: {doc[:50]}..."
            )

        return documents, similarity_scores

    except Exception as e:
        logger.error(f"âŒ [CHROMADB] è¯­ä¹‰æœç´¢å¤±è´¥: {e}\n{traceback.format_exc()}")
        return [], []


############################################################################################################
